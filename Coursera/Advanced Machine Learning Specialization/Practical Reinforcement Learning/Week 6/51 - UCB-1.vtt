WEBVTT

1
00:00:00.000 --> 00:00:03.832
[MUSIC]

2
00:00:03.832 --> 00:00:06.290
There are, as it turns out,
multiple ways to do so.

3
00:00:06.290 --> 00:00:09.800
The first one is specific to this UCB.

4
00:00:09.800 --> 00:00:12.710
First, in general, you don't need
to get the whole distribution.

5
00:00:12.710 --> 00:00:14.210
You only need to know it's percentile.

6
00:00:14.210 --> 00:00:19.090
And you might have to compromise
a little bit in the way that you don't

7
00:00:19.090 --> 00:00:22.740
know the exact value, but
you only know it for some inequality.

8
00:00:22.740 --> 00:00:25.538
Turns out, in statistics, there is more
than one way you can compute that.

9
00:00:25.538 --> 00:00:27.888
There are inequalities like
the counting inequality,

10
00:00:27.888 --> 00:00:29.920
also known as Chernoff inequality.

11
00:00:29.920 --> 00:00:33.783
Or or there's going to be
like five more of them.

12
00:00:33.783 --> 00:00:38.500
That all compute something like the
previnsi of some particular value being

13
00:00:38.500 --> 00:00:41.430
more than some particular threshold.

14
00:00:41.430 --> 00:00:44.469
The case that this particular rate
regardless of the distribution.

15
00:00:44.469 --> 00:00:49.641
Or what as in the housing case
regardless of a distribution shape

16
00:00:49.641 --> 00:00:55.410
as long as the possible value of this
action q value is between 0 and 1.

17
00:00:55.410 --> 00:00:58.740
In this case the formula on the slide is
a simplified version of the Hoeffding

18
00:00:58.740 --> 00:00:59.640
inequality here.

19
00:00:59.640 --> 00:01:03.384
You can easily find the full
version if you just Wikipedia it.

20
00:01:03.384 --> 00:01:08.220
But the essence here is that the
probability of your action value, q-value,

21
00:01:08.220 --> 00:01:13.740
being larger than the average q-value
you've measured so far by more than t.

22
00:01:13.740 --> 00:01:16.210
Which is a value of say plus 5.

23
00:01:16.210 --> 00:01:21.775
Would decay as exponent to the power
of -2 times number of samples,

24
00:01:21.775 --> 00:01:25.455
number of times you've measured
this q-value, times t squared.

25
00:01:25.455 --> 00:01:28.605
So if your t is equal to 5,
and say your q-value,

26
00:01:28.605 --> 00:01:31.909
your average q-value is 10,
and t is equal to 5.

27
00:01:31.909 --> 00:01:36.725
The [INAUDIBLE] of your q-value
being larger than 15 is

28
00:01:36.725 --> 00:01:39.907
exponent of -2 times n times 25.

29
00:01:39.907 --> 00:01:41.760
And n might be some 1,000.

30
00:01:41.760 --> 00:01:47.329
Which is kind of really, really small
number but they are non 01 nevertheless.

31
00:01:47.329 --> 00:01:51.049
What you want to do with this inequality
is you want to solve it not for

32
00:01:51.049 --> 00:01:53.940
the probability, but for
t, for this offset here.

33
00:01:53.940 --> 00:01:58.190
You want to find such an offset, such
a difference between expected value and

34
00:01:58.190 --> 00:01:59.960
your action value, q-value.

35
00:01:59.960 --> 00:02:05.845
Such that the probability of being
above this offset is greater,

36
00:02:05.845 --> 00:02:08.738
okay lesser or equal than 5%.

37
00:02:08.738 --> 00:02:13.460
Or another chance probability of being
within this offset, so less or equal,

38
00:02:13.460 --> 00:02:14.710
is at least 95%.

39
00:02:14.710 --> 00:02:18.312
This would be some estimate
of the percentile wanted,

40
00:02:18.312 --> 00:02:22.025
all by it is an inequality so
it might be a less efficient one.

41
00:02:22.025 --> 00:02:26.854
If you solved this thing for t, plugging
in some probablilty that you want,

42
00:02:26.854 --> 00:02:30.711
say you want to be 99% sure
that you are within this range.

43
00:02:30.711 --> 00:02:33.800
Then your solution is going
to look something like this.

44
00:02:33.800 --> 00:02:37.214
Of course there can be a coefficient
here between the square root.

45
00:02:37.214 --> 00:02:40.868
Which depends on the probability,
the certainty you want to get.

46
00:02:40.868 --> 00:02:44.902
And if you want to be 90% it
would be less than 1 here, and

47
00:02:44.902 --> 00:02:51.940
if you want to be 9.99999% sure it will
be, say, maybe 10 times, 100 times more.

48
00:02:51.940 --> 00:02:54.330
But the general idea looks like this.

49
00:02:54.330 --> 00:02:57.952
You take the amount of times you've
picked this action in a state.

50
00:02:57.952 --> 00:03:01.596
And you take the amount of times
you've ever been to the state and

51
00:03:01.596 --> 00:03:05.120
picked any action,
regardless of which one.

52
00:03:05.120 --> 00:03:08.460
And then you plug them in
this square root thing here.

53
00:03:08.460 --> 00:03:11.090
So you take the logarithm over time,
over a number of times,

54
00:03:11.090 --> 00:03:12.430
you've been to the state.

55
00:03:12.430 --> 00:03:14.930
Divided by times you've picked
this action in the state,

56
00:03:14.930 --> 00:03:17.955
multiplied by two square root,
you know all that stuff.

57
00:03:17.955 --> 00:03:20.895
And this is how far you get
from the expected value.

58
00:03:20.895 --> 00:03:26.695
So the final and if priority of action
is a sum of this exponent value and

59
00:03:26.695 --> 00:03:29.765
the addition from the UCB,
from the upper confidence bound.

60
00:03:31.215 --> 00:03:33.175
Now, let's see how this formula works.

61
00:03:33.175 --> 00:03:34.840
Let's plug in some numbers.

62
00:03:34.840 --> 00:03:37.205
For starters lets say that we
have never picked an action.

63
00:03:37.205 --> 00:03:39.340
There's new action that we have not yet
picked.

64
00:03:39.340 --> 00:03:42.270
And I want you to tell me how
inched are we in this action.

65
00:03:42.270 --> 00:03:46.280
What's the odds that
we're going to pick it.

66
00:03:46.280 --> 00:03:47.910
Yes, we're actually really interested.

67
00:03:47.910 --> 00:03:52.320
And unless there is some other action
we should also pick zero times.

68
00:03:52.320 --> 00:03:55.580
The action which has not yet
been picked will be the top priority.

69
00:03:55.580 --> 00:04:01.642
Because if na is equal to 0 the number
times it picked this action,

70
00:04:01.642 --> 00:04:07.288
then the priority of this v-hat
kind of gets set to infinity.

71
00:04:07.288 --> 00:04:10.290
And it means that we are dead
sure when we pick this action.

72
00:04:10.290 --> 00:04:12.440
It might be optimal so
we might just well try it now.

73
00:04:13.640 --> 00:04:15.787
Again, this is kind of
reasonable to expect,

74
00:04:15.787 --> 00:04:17.779
we want to try all
the extras at least once.

75
00:04:17.779 --> 00:04:22.280
And then figure out which of them
do we want to continue trying.

76
00:04:22.280 --> 00:04:25.360
But let's see what happens as we
convert to a larger number of na and N.

77
00:04:25.360 --> 00:04:29.006
Let's say we have one state and
three actions.

78
00:04:29.006 --> 00:04:33.343
And for this state we've been
there say three million times.

79
00:04:33.343 --> 00:04:38.300
And each action we've been picking,
we've picked one million times, exactly.

80
00:04:38.300 --> 00:04:40.050
So N equals 1 million.

81
00:04:40.050 --> 00:04:41.510
Okay, sorry, 3 million.

82
00:04:41.510 --> 00:04:43.620
And na equals 1 million.

83
00:04:43.620 --> 00:04:46.400
What's going to be the v-hat here?

84
00:04:48.250 --> 00:04:53.225
Well yes, it turns out the v-hat is
going to be very close to the expectation,

85
00:04:53.225 --> 00:04:58.304
and it's going to get even closer as the N
and na increase towards the infinity.

86
00:04:58.304 --> 00:05:02.740
The infinity it will get, exactly, it will
convert exactly into the expected value.

87
00:05:02.740 --> 00:05:07.213
Because algorithm of some value
divided by this value itself, or

88
00:05:07.213 --> 00:05:11.455
something proportional to it,
it's going to convert to zero.

89
00:05:11.455 --> 00:05:15.240
Okay, so
this is how it's going to be explained.

90
00:05:15.240 --> 00:05:19.128
And again, it makes some sense because
after you've explored everything countless

91
00:05:19.128 --> 00:05:20.917
times, it doesn't really matter,.

92
00:05:20.917 --> 00:05:22.780
The exploration value
doesn't really matter.

93
00:05:22.780 --> 00:05:24.000
You know everything perfectly.

94
00:05:24.000 --> 00:05:25.800
So you can just as well exploit it.

95
00:05:26.850 --> 00:05:31.430
This is the kind of approach
to computing the upper bound.

96
00:05:31.430 --> 00:05:35.190
This actually practically means that you
have to store for each state and for

97
00:05:35.190 --> 00:05:37.961
each action how many times
have you picked this action.

98
00:05:37.961 --> 00:05:40.360
And how many times have
you been to this state.

99
00:05:40.360 --> 00:05:45.157
And it's, well, just three times as
many parameters if you are using 3 times

100
00:05:45.157 --> 00:05:50.210
plus 2 times plus 1, many parameters
compared to standard q learning.

101
00:05:50.210 --> 00:05:53.510
And it's kind of bearable
in a terrible case.

102
00:05:53.510 --> 00:05:55.850
If you're not using a table, if you're
using some kind of approximations.

103
00:05:55.850 --> 00:05:59.268
You'll also have to approximate
the densities of the state and

104
00:05:59.268 --> 00:06:03.460
the action being picked in the state for
some parametric functions.

105
00:06:03.460 --> 00:06:06.050
But that's going to be covered in
a reading section in much more detail.

106
00:06:07.220 --> 00:06:11.279
So this is of course one thing
we've derived from [INAUDIBLE] or

107
00:06:11.279 --> 00:06:15.540
turn off inequality, but
you can find your own modified formula.

108
00:06:15.540 --> 00:06:16.740
Which would work for

109
00:06:16.740 --> 00:06:20.065
any other inequality of your preference,
and it might be better.

110
00:06:20.065 --> 00:06:22.500
[INAUDIBLE] hears that
those are all inequalities,

111
00:06:22.500 --> 00:06:25.480
so they are upper bounds
of how we are interested.

112
00:06:25.480 --> 00:06:26.150
Okay, sorry.

113
00:06:26.150 --> 00:06:27.960
Lower bounds of how we're interested.

114
00:06:27.960 --> 00:06:31.975
So if something says to you, if UCB-1
says to you that you should explore,

115
00:06:31.975 --> 00:06:34.127
then it might be that you really should.

116
00:06:34.127 --> 00:06:37.594
But it might be that just overestimate
the value of this action.

117
00:06:37.594 --> 00:06:40.979
Because It doesn't know anything
about the distribution beforehand.

118
00:06:40.979 --> 00:06:46.058
And again for this particular
inequality we assume that it is over-

119
00:06:46.058 --> 00:06:56.058
[MUSIC]