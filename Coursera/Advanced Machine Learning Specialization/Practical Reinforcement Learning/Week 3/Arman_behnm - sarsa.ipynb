{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPAUL0rX9Jg_"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAzWHP2H9JhI",
        "outputId": "d3685b1a-6f95-467a-91f5-e9b7bc8f2bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145480 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gG7Zinw9JhJ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XM6s9Rb9JhK"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g81FJBk9JhL"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        #If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = max([self.get_qvalue(state,action) for action in possible_actions])\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        #agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        qvalue_target = reward+gamma*self.get_value(next_state)\n",
        "        qvalue = learning_rate*qvalue_target+(1-learning_rate)*self.get_qvalue(state,action)\n",
        "        \n",
        "        self.set_qvalue(state, action, qvalue)\n",
        "\n",
        "    \n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        #If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        action_value_dict = {action: self.get_qvalue(state, action) for action in possible_actions}\n",
        "        best_action = sorted(action_value_dict, key=lambda x:action_value_dict[x], reverse=True)[0]\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "        \n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        #If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        #agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "        exploration = random.random()\n",
        "        if exploration<epsilon:\n",
        "            chosen_action = np.random.choice(possible_actions)\n",
        "        else:\n",
        "            chosen_action = self.get_best_action(state)\n",
        "        \n",
        "        return chosen_action"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYHMeqtS9JhM"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFkM1u_9JhM"
      },
      "source": [
        "#from qlearning import QLearningAgent\n",
        "\n",
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "    \n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "          \n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        #If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        \n",
        "        state_value = 0\n",
        "        for action in possible_actions:\n",
        "            if action == self.get_best_action(state):\n",
        "                state_value += ((1-epsilon)+epsilon/len(possible_actions))*self.get_qvalue(state,action)\n",
        "            else:\n",
        "                state_value += epsilon/len(possible_actions)*self.get_qvalue(state,action)\n",
        "        \n",
        "        return state_value"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJVr9xj9JhN"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_-twJyB9JhN",
        "outputId": "138d1acb-433b-4c31-f008-476996402aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Fbjifh9JhN",
        "outputId": "11909dcb-267c-4ce0-d36e-6f021a25466f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMReUPdQ9JhO"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkVTHHJd9JhO"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UZkrrR49JhO",
        "outputId": "da0d7245-a2cb-4429-bb86-033ae62117a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -30.89\n",
            "QLEARNING mean reward = -76.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4E8HHsU9JhO"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqiyKKYN9JhP"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98R6Q3LA9JhP",
        "outputId": "b3641afc-659f-4754-b60f-3a7d3f769407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " >  v  v  >  v  v  v  v  v  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnbdPIwn9JhP"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNtJtX-F9JhP",
        "outputId": "62a1cf71-8928-4633-94bd-aefe044c0f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, 'Armanbehnam1996@gmail.com', 'ilINOkuaKKVEyDzp')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAuyhTAz9JhQ"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVDEJx9e-zjl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}