WEBVTT

1
00:00:00.000 --> 00:00:03.866
[MUSIC]

2
00:00:03.866 --> 00:00:08.775
Data analysis in particle physics
can be much more sophisticated than

3
00:00:08.775 --> 00:00:10.910
we looked before.

4
00:00:10.910 --> 00:00:15.200
And we'll talk about it at
the third lecture in more details.

5
00:00:15.200 --> 00:00:20.038
But for the moment, we have to
keep in mind that all measurements

6
00:00:20.038 --> 00:00:24.084
physicists do come with
an uncertainty estimation.

7
00:00:24.084 --> 00:00:29.553
For example, tracking algorithm that
finds muon from previous exercise

8
00:00:29.553 --> 00:00:35.350
should be evaluated somehow before
we can pass some data through it.

9
00:00:35.350 --> 00:00:40.600
And thanks to standard model we
can simulate very precise image

10
00:00:40.600 --> 00:00:44.110
of particles flying around the detector.

11
00:00:44.110 --> 00:00:51.350
At this slide, you'll see
the second half of data analysis.

12
00:00:51.350 --> 00:00:55.252
So to access processing time and

13
00:00:55.252 --> 00:01:00.312
amount of information that is audacity of

14
00:01:00.312 --> 00:01:06.960
information that is available
on the single object and

15
00:01:06.960 --> 00:01:13.192
there is a bottom of this
plot that shows a raw data.

16
00:01:13.192 --> 00:01:18.609
And if you follow parabola to the right,
you follow the path that we

17
00:01:18.609 --> 00:01:25.193
described previously from raw information
that the detector records we collect,

18
00:01:25.193 --> 00:01:31.100
reconstructed points then tracks segments,
then track candidates and

19
00:01:31.100 --> 00:01:35.910
vertices and
then the whole decays of certain kind.

20
00:01:35.910 --> 00:01:41.040
But at the same time,
there are very strong

21
00:01:41.040 --> 00:01:45.560
software and
modules that can be used to simulate every

22
00:01:45.560 --> 00:01:50.100
step that happens on the detector
level and subatomic level.

23
00:01:50.100 --> 00:01:54.731
Actually, there are event
generators that

24
00:01:54.731 --> 00:02:00.150
produce signal like patterns and

25
00:02:00.150 --> 00:02:06.520
then you can estimate what kind of
response you can get from the detector.

26
00:02:06.520 --> 00:02:13.609
What would be energy deposition if
you see something like the signal,

27
00:02:13.609 --> 00:02:19.015
and then you can go down
the level of abstraction until

28
00:02:19.015 --> 00:02:25.743
the raw data ideally the representation
of the simulated event and

29
00:02:25.743 --> 00:02:30.812
representation of real
event should be the same.

30
00:02:30.812 --> 00:02:36.534
Of course it is not the case
like by 100% because

31
00:02:36.534 --> 00:02:41.991
some processes are very
difficult to estimate and

32
00:02:41.991 --> 00:02:46.650
simulate but still the picture shows that

33
00:02:46.650 --> 00:02:51.175
there is a very great deal of software and

34
00:02:51.175 --> 00:02:56.260
efforts put into
simulation of the physics.

35
00:02:57.660 --> 00:03:01.140
So, all of the algorithms,
for example, tracking or

36
00:03:01.140 --> 00:03:06.400
triggers are evaluated
on the simulated data.

37
00:03:06.400 --> 00:03:11.540
And it is very important problem,
efficiently, and

38
00:03:11.540 --> 00:03:15.890
accurately simulate physical process.

39
00:03:15.890 --> 00:03:20.720
At the moment,
it takes roughly 80% of computational

40
00:03:20.720 --> 00:03:26.750
power of computational greed that CERN
uses for data processing.

41
00:03:26.750 --> 00:03:33.070
And roughly it is proportional to the
amount of data you're going to collect.

42
00:03:33.070 --> 00:03:38.438
There is a big problem when
LHC is going to switch into

43
00:03:38.438 --> 00:03:45.763
high luminosity mode when generation
of data will be tens much larger.

44
00:03:45.763 --> 00:03:52.534
At this slide, I've just presented
traditional packages that are used for

45
00:03:52.534 --> 00:03:57.509
simulation of various aspects
of particle interaction

46
00:03:57.509 --> 00:04:02.060
like Nutrena interaction,
generic simulator for

47
00:04:02.060 --> 00:04:06.397
processes called Pythia and
Geant that is used for

48
00:04:06.397 --> 00:04:11.090
simulation of particles
interacting with matter.

49
00:04:11.090 --> 00:04:12.650
It's not only used for

50
00:04:12.650 --> 00:04:17.790
particle physics but it is applied
to variety of different cases.

51
00:04:17.790 --> 00:04:23.550
But at the link below you can find
much more examples of such software.

52
00:04:24.880 --> 00:04:26.680
And with this regard,

53
00:04:26.680 --> 00:04:31.340
I would like to mention two
more additional challenges that

54
00:04:31.340 --> 00:04:36.570
are relevant from the perspective of our
course that focuses on machine learning.

55
00:04:36.570 --> 00:04:43.030
So the first one is speed-up
of simulation that can

56
00:04:43.030 --> 00:04:48.350
take advantage of generative models based
on for example neural networks that can

57
00:04:48.350 --> 00:04:54.690
work much,
much faster than traditional simulators.

58
00:04:54.690 --> 00:04:59.280
And tuning of simulator parameters to

59
00:04:59.280 --> 00:05:04.910
find the best combination of
parameters that makes simulator

60
00:05:04.910 --> 00:05:09.130
produce the most accurate and
realistic pictures.

61
00:05:11.590 --> 00:05:17.004
So those simulators are being
used outside of CERN already,

62
00:05:17.004 --> 00:05:21.569
for example in medicine and
space technologies and

63
00:05:21.569 --> 00:05:26.454
there are plenitude of other
technologies that has been

64
00:05:26.454 --> 00:05:30.506
produced as a byproduct
of research at CERN.

65
00:05:30.506 --> 00:05:36.756
Those cover of course internet and
World Wide Web, Muono-graphy,

66
00:05:36.756 --> 00:05:41.821
aerospace, and
cryogenics ultra vacuum techniques,

67
00:05:41.821 --> 00:05:47.870
medicine of course based on ion
radiotherapy and Hadron therapy.

68
00:05:48.960 --> 00:05:56.720
So, there's a whole side that is dedicated
to technologies that has been born at CERN and

69
00:05:56.720 --> 00:06:03.860
are now being applied to our
everyday life of humanity.

70
00:06:03.860 --> 00:06:06.190
I'd like to conclude this lecture and

71
00:06:06.190 --> 00:06:11.730
to stress once again what is
important from our perspective here.

72
00:06:11.730 --> 00:06:18.710
The first thing is LHC is a massive
sub-elementary scale microscope.

73
00:06:18.710 --> 00:06:23.180
And it allows to look into
our fascinating research area

74
00:06:23.180 --> 00:06:26.908
that no other tool can give access to.

75
00:06:26.908 --> 00:06:30.150
There is a substantial,
theoretical foundation

76
00:06:30.150 --> 00:06:34.690
that offers pretty good explanation
of what we have seen so

77
00:06:34.690 --> 00:06:40.696
far on particle-level physics,
but it is not complete yet.

78
00:06:40.696 --> 00:06:45.640
Some pretty fascinating
phenomena are awaiting for

79
00:06:45.640 --> 00:06:50.140
clarification and LHC allows to probe for

80
00:06:50.140 --> 00:06:56.890
theory extensions and to see which theory
gives better explanation for those.

81
00:06:56.890 --> 00:07:01.410
At the same time, there are plenty of
machine learning challenges that include

82
00:07:01.410 --> 00:07:06.820
data analysis, surrogate model
optimization and experiment design

83
00:07:06.820 --> 00:07:11.540
that are waiting for minds and
talents of data scientists to be solved.

84
00:07:12.840 --> 00:07:17.551
I hope that homework and
challenges that are prepared for

85
00:07:17.551 --> 00:07:23.011
this course will keep you engaged and
allow you to get the feeling

86
00:07:23.011 --> 00:07:29.133
how machine learning can improve
things at fundamental research.

87
00:07:29.133 --> 00:07:35.295
[MUSIC]