WEBVTT

1
00:00:00.000 --> 00:00:03.369
[MUSIC]

2
00:00:03.369 --> 00:00:07.440
So we have taken a swift look
at the search strategy.

3
00:00:08.990 --> 00:00:14.050
Training of a classifier on our several
features is not a big deal, usually.

4
00:00:14.050 --> 00:00:19.350
However, let's take a look at
additional constraints that are imposed

5
00:00:19.350 --> 00:00:23.900
on the classifier so that it could
be used for such an analysis.

6
00:00:25.020 --> 00:00:29.630
So there are two considerations
we have to keep in mind.

7
00:00:29.630 --> 00:00:32.130
The first one is called uniformity.

8
00:00:32.130 --> 00:00:35.380
So the correlation between
classifier prediction and

9
00:00:35.380 --> 00:00:40.330
mass can lead to false peaks
which spoil event counting.

10
00:00:41.540 --> 00:00:47.810
So as you see on the picture,
if you have a blue distribution and

11
00:00:47.810 --> 00:00:52.990
then you apply some kind of classifier
that is correlated with a mass,

12
00:00:52.990 --> 00:00:57.430
then you might get
a green distribution that

13
00:00:57.430 --> 00:01:01.560
is roughly the same on the region,
side bend regions.

14
00:01:01.560 --> 00:01:06.194
But at the center where you're
expecting to get a mass of

15
00:01:06.194 --> 00:01:09.059
mother particle, you get a peak.

16
00:01:09.059 --> 00:01:14.242
And sometimes this peak might
be just to the features or

17
00:01:14.242 --> 00:01:22.040
just to internal properties of
a classifier with no physical motivation.

18
00:01:22.040 --> 00:01:26.881
And the second restrictions
that we have to keep

19
00:01:26.881 --> 00:01:31.721
in mind is that training
data set that we used for

20
00:01:31.721 --> 00:01:39.360
a signal is fully represented by
simulated events and background is real.

21
00:01:39.360 --> 00:01:44.764
So when we train a classifier,
signal versus background,

22
00:01:44.764 --> 00:01:48.439
we don't know exactly if the features or

23
00:01:48.439 --> 00:01:53.195
if the classifier has
learned something specific to

24
00:01:53.195 --> 00:01:59.060
signal versus background,
or Monte Carlo versus real.

25
00:01:59.060 --> 00:02:04.790
So those aspects can also
introduce a bias in our counting.

26
00:02:06.390 --> 00:02:10.020
So let's take a uniformity,
take a look at uniformity.

27
00:02:10.020 --> 00:02:14.650
Here you have on the top
right the distribution

28
00:02:14.650 --> 00:02:18.170
of two variables for
example prediction in the mass.

29
00:02:19.240 --> 00:02:22.152
And on the left bottom,

30
00:02:22.152 --> 00:02:27.247
you will have even numbers that represent

31
00:02:27.247 --> 00:02:32.490
the distribution of
the events in the beans

32
00:02:32.490 --> 00:02:37.294
of mass with certain predictions given

33
00:02:37.294 --> 00:02:42.682
global threshold of true positive rate, for

34
00:02:42.682 --> 00:02:48.237
example, 0.1, 0.3, 0.5, etc.

35
00:02:48.237 --> 00:02:54.011
So in case of nonuniform distribution or
nonuniform distribution

36
00:02:54.011 --> 00:02:58.755
of predictions versus mass,
in a joined distribution

37
00:02:58.755 --> 00:03:04.114
picture you see something that
is displayed on the top right,

38
00:03:04.114 --> 00:03:09.090
and you can see it more
distinctly on the levels picture.

39
00:03:09.090 --> 00:03:15.300
So basically when you apply a classifier
that gives true positive rate given

40
00:03:15.300 --> 00:03:20.770
specific number like 0.1,
which is depicted by blue.

41
00:03:20.770 --> 00:03:26.770
And then you see what is the actual
fraction of the dataset that

42
00:03:26.770 --> 00:03:32.530
is selected by this threshold
on a given range on a mass axis.

43
00:03:32.530 --> 00:03:34.180
So when you block those
colorful numbers and

44
00:03:34.180 --> 00:03:38.930
you see there are peaks that correspond
though there is not uniformity.

45
00:03:40.420 --> 00:03:43.500
How can you measure this non-uniformity?

46
00:03:43.500 --> 00:03:49.711
So if you introduce a mass window and
you compare distribution in this

47
00:03:49.711 --> 00:03:54.851
mass window with a global
distribution in your data set,

48
00:03:54.851 --> 00:03:59.259
which is depicted on this
figure by blue points.

49
00:03:59.259 --> 00:04:06.307
You can plot a marginal distribution like
you see on the right side of this picture.

50
00:04:06.307 --> 00:04:09.020
The blue and yellow has histograms.

51
00:04:09.020 --> 00:04:14.580
So since those are pretty much
aligned with each other it means that

52
00:04:14.580 --> 00:04:17.550
the distribution in
the mass window is more or

53
00:04:17.550 --> 00:04:21.290
less the same as distribution of
predictions in the whole data set.

54
00:04:22.390 --> 00:04:26.270
And in case you have some discrepancies

55
00:04:29.240 --> 00:04:32.870
or if you have some correlations
between predictions and

56
00:04:32.870 --> 00:04:36.410
the mass,
those marginal distributions will differ.

57
00:04:38.350 --> 00:04:41.886
So as a measure to non-uniformity,

58
00:04:41.886 --> 00:04:45.992
we can introduce Cramer-von Mises test,

59
00:04:45.992 --> 00:04:52.836
which is an integral characteristic
that integrates the difference in

60
00:04:52.836 --> 00:04:59.694
CDFs into distributions like in
the mass region and the whole data set.

61
00:04:59.694 --> 00:05:05.884
And we compute this formula
over all possible regions or

62
00:05:05.884 --> 00:05:12.350
some set of regions in the mass scale,
in the mass window.

63
00:05:13.690 --> 00:05:19.610
So uniformity check that relies on this
measure can work in the following manner.

64
00:05:19.610 --> 00:05:24.030
So first we confirm that
random predictions and

65
00:05:24.030 --> 00:05:26.690
mass can be considered
independent variables.

66
00:05:26.690 --> 00:05:32.350
And we assume a null-hypothesis,
that mass and predictions are independent.

67
00:05:32.350 --> 00:05:35.660
Then we generate distribution of CvM value

68
00:05:35.660 --> 00:05:40.590
under null-hypothesis by repeating
many times the following steps.

69
00:05:40.590 --> 00:05:45.588
First, we generate random predictions and
we compute CvM value.

70
00:05:45.588 --> 00:05:48.789
And then we can choose a p-value and

71
00:05:48.789 --> 00:05:54.750
compute corresponding value
of Cramer-von Mises test.

72
00:05:54.750 --> 00:05:58.710
So the basic approach that thesis
used to deal with correlation

73
00:05:58.710 --> 00:06:01.900
of predictions of classifier
with the mass is pretty simple.

74
00:06:01.900 --> 00:06:07.680
So we remove the features in the training
sample that introduce such correlation.

75
00:06:07.680 --> 00:06:11.690
We know that momentum, or
if we have several particles,

76
00:06:11.690 --> 00:06:15.295
momenta of those particles
can give us a hint about

77
00:06:15.295 --> 00:06:20.430
the mass of the particle or
mass of those particles.

78
00:06:20.430 --> 00:06:22.380
So we can omit those features.

79
00:06:23.880 --> 00:06:25.610
So it is simple and it works.

80
00:06:25.610 --> 00:06:32.190
But removing those features can
lessen the power of classifier.

81
00:06:32.190 --> 00:06:37.255
So the question is can we modify
machine learning algorithm that

82
00:06:37.255 --> 00:06:42.508
still uses all the features but
provides uniform predictions with

83
00:06:42.508 --> 00:06:48.058
regard to background or with regard
to signal allowing the mass axis.

84
00:06:48.058 --> 00:06:52.320
So let's recap a gradient
boosting algorithm.

85
00:06:52.320 --> 00:06:57.430
So it is an approach that greatly
builds an ensemble of estimators.

86
00:06:58.630 --> 00:07:04.462
So here the small is just a tree and
we have an ensemble

87
00:07:04.462 --> 00:07:09.642
of those trees weighted
by some coefficient.

88
00:07:09.642 --> 00:07:16.520
And this approach minimizes given loss
function, and functions could differ.

89
00:07:16.520 --> 00:07:22.210
For example, Mean Squared Error is
the one you have in the middle,

90
00:07:22.210 --> 00:07:27.860
or AdaLoss, that is used for
AdaBoost, or LogLoss,

91
00:07:27.860 --> 00:07:33.320
which is used in many different cases,
in different classifiers.

92
00:07:33.320 --> 00:07:39.950
Each term in the ensemble approximate
the residuals between true value of

93
00:07:39.950 --> 00:07:45.450
the function that we want to predict and
all preceding terms predicting it.

94
00:07:46.570 --> 00:07:52.480
So one approach is called
uniform boosting or uBoostBDT.

95
00:07:52.480 --> 00:07:55.300
BDT stands for Boosted Decision Trees.

96
00:07:55.300 --> 00:07:59.680
So if we aim to get certain false positive

97
00:07:59.680 --> 00:08:03.570
rate at the region that
equals to a certain constant.

98
00:08:03.570 --> 00:08:05.890
So at first, we fix the target efficiency.

99
00:08:05.890 --> 00:08:10.405
For example, we want to get 30% there and

100
00:08:10.405 --> 00:08:13.745
find corresponding threshold for
the classifier.

101
00:08:13.745 --> 00:08:19.245
Then we train a tree with
its decision function, d(x).

102
00:08:19.245 --> 00:08:25.745
And increase weight for
misclassified items, events.

103
00:08:25.745 --> 00:08:30.665
And then increase weight of
background events in the regions with

104
00:08:30.665 --> 00:08:33.595
high false positive rate,
according to the formula on this line.

105
00:08:34.652 --> 00:08:39.600
So following this procedure,
we achieve the false

106
00:08:39.600 --> 00:08:45.160
positive rate in this region and
we can repeat it for all regions.

107
00:08:45.160 --> 00:08:50.910
So it works but
it is a little bit computationally hungry.

108
00:08:50.910 --> 00:08:55.280
A little simpler approach is
based on gradient boosting.

109
00:08:55.280 --> 00:09:01.299
So why don't we minimize
CvM with gradient descent?

110
00:09:01.299 --> 00:09:05.821
So the problem is that we can't
compute the gradient of this formula.

111
00:09:05.821 --> 00:09:12.356
But we can make an approximation of CvM
according to the formula on the slide and

112
00:09:12.356 --> 00:09:17.600
for this formula we actually
can compute derivative.

113
00:09:17.600 --> 00:09:24.846
And for this we can modify the loss
function according to the formula but

114
00:09:24.846 --> 00:09:32.602
also we add this LFL with some coefficient
to the loss function of Adiboost.

115
00:09:32.602 --> 00:09:35.560
And this actually works pretty nicely.

116
00:09:35.560 --> 00:09:37.921
So you see three examples.

117
00:09:37.921 --> 00:09:46.110
So on the left part of the slide you see
Adiboost and those levels of efficiencies.

118
00:09:46.110 --> 00:09:52.730
And you see that side bands
are inclined pretty heavily.

119
00:09:52.730 --> 00:09:58.150
So don't disregard middle points
because there should be no point,

120
00:09:58.150 --> 00:10:01.050
it goes to zero for no physical reasons.

121
00:10:01.050 --> 00:10:08.610
Just consider the angles at which side
bands levels, go to the central region.

122
00:10:08.610 --> 00:10:12.990
Uboost is a bit better, and

123
00:10:12.990 --> 00:10:19.235
the winner is UGB+FL so,
it's faster, and also it allows for

124
00:10:19.235 --> 00:10:24.030
tradeoff between quality and
uniformity by tuning parameter alpha.

125
00:10:26.055 --> 00:10:30.085
Another approach that you
can take into account for

126
00:10:30.085 --> 00:10:34.494
this problem is based on
adversarial neural networks.

127
00:10:34.494 --> 00:10:40.137
The first one is adversarial
decorrelation introduced by a paper,

128
00:10:40.137 --> 00:10:43.260
Chase Shim and his colleagues.

129
00:10:43.260 --> 00:10:46.410
So the idea is that you
build a classifier.

130
00:10:47.710 --> 00:10:52.361
And on top of this classifier
you introduce another algorithm

131
00:10:52.361 --> 00:10:57.639
adversary network that takes into
account how well it can reconstruct

132
00:10:57.639 --> 00:11:02.755
the dependency between prediction
of their original classifier.

133
00:11:02.755 --> 00:11:06.880
With mass or with other feature
that you want to decorrelate.

134
00:11:07.990 --> 00:11:12.770
So to make it work, they also
added some gradient scaling layer

135
00:11:12.770 --> 00:11:16.890
to increase the gradient passing
through this adversary part.

136
00:11:18.480 --> 00:11:22.760
And signal events are given
zero weight in adversary loss.

137
00:11:22.760 --> 00:11:24.580
So it basically works.

138
00:11:24.580 --> 00:11:29.296
So you see an example
from their presentation,

139
00:11:29.296 --> 00:11:38.070
the red distribution is predictions of
just original traditional neural network.

140
00:11:38.070 --> 00:11:43.116
And the black ones are the distribution
of predictions of the network

141
00:11:43.116 --> 00:11:48.432
that has been trained adversarially
according to the previous scheme.

142
00:11:48.432 --> 00:11:52.801
And the quality of the second
network is roughly the same as

143
00:11:52.801 --> 00:11:56.110
the quality of the original one.

144
00:11:56.110 --> 00:12:01.309
And on this slide you have
a little more generic

145
00:12:01.309 --> 00:12:06.920
scheme that the previous
was just the example of.

146
00:12:06.920 --> 00:12:11.249
In this adversarial part of the network,

147
00:12:11.249 --> 00:12:18.803
they reconstruct parameters of
the distribution that we want to avoid.

148
00:12:18.803 --> 00:12:23.787
And in case we see this distribution
in the output of adversarial part,

149
00:12:23.787 --> 00:12:26.124
we punish the original network.