WEBVTT

1
00:00:03.380 --> 00:00:08.670
In this video, we will talk about Gaussian processes for regression.

2
00:00:08.670 --> 00:00:10.115
In the next video,

3
00:00:10.115 --> 00:00:14.555
we will use Gaussian processes for Bayesian optimization.

4
00:00:14.555 --> 00:00:20.380
Let's start from a regression problem example with a set of observations.

5
00:00:20.380 --> 00:00:25.915
The goal of this example is to learn this function using Gaussian processes.

6
00:00:25.915 --> 00:00:31.230
Suppose that the observations are noisy as it's shown on this slide.

7
00:00:31.230 --> 00:00:34.635
y is a vector of the target observations,

8
00:00:34.635 --> 00:00:38.105
and f is a vector the true function values,

9
00:00:38.105 --> 00:00:41.455
Epsilon is the noise of the distribution.

10
00:00:41.455 --> 00:00:45.900
We also suppose that the noise has normal distribution.

11
00:00:45.900 --> 00:00:49.390
So the vector of the target observations y,

12
00:00:49.390 --> 00:00:53.440
is distributed with a multivariate normal distribution.

13
00:00:53.440 --> 00:00:58.525
Mean of the distribution is a vector of true function values f,

14
00:00:58.525 --> 00:01:04.310
and the covariance matrix is a unit matrix multiplied by a parameter Alpha.

15
00:01:04.310 --> 00:01:07.180
Also, suppose that the vector of

16
00:01:07.180 --> 00:01:11.025
the true function values also has normal distribution with

17
00:01:11.025 --> 00:01:14.055
zero mean and the covariance matrix K.

18
00:01:14.055 --> 00:01:18.450
The matrix K is chosen to express the property that,

19
00:01:18.450 --> 00:01:23.060
for points x_n and x_m that are similar,

20
00:01:23.060 --> 00:01:31.075
the values f(x_n) and f(x_m) will be more strongly correlated than for dissimilar points.

21
00:01:31.075 --> 00:01:34.090
Let's consider this matrix more detailed.

22
00:01:34.090 --> 00:01:37.565
The covariance between two points is based on

23
00:01:37.565 --> 00:01:41.200
the Euclidean distance between these two points,

24
00:01:41.200 --> 00:01:44.960
x_i and x_j as it's shown on the slide,

25
00:01:44.960 --> 00:01:52.785
and this expression expresses the property that for these two points that are similar,

26
00:01:52.785 --> 00:01:59.130
the values of the function will be more strongly correlated than for dissimilar points.

27
00:01:59.130 --> 00:02:02.400
Distributions of the target observations

28
00:02:02.400 --> 00:02:05.745
and the true function values shown on the previous slides,

29
00:02:05.745 --> 00:02:09.030
allow us to calculate distribution of

30
00:02:09.030 --> 00:02:13.440
the observations with zero mean in the following covariance

31
00:02:13.440 --> 00:02:17.040
matrix C. Let's consider how to use

32
00:02:17.040 --> 00:02:21.995
this distribution to estimate the function value for a given point x.

33
00:02:21.995 --> 00:02:29.935
Let's estimate the function value y_N plus 1 for a given point x_N plus 1.

34
00:02:29.935 --> 00:02:36.825
The vector of the target observations with N plus 1 points has a normal distribution,

35
00:02:36.825 --> 00:02:41.760
where mean and covariance matrix have the following structure.

36
00:02:41.760 --> 00:02:48.780
The covariance matrix for the N plus 1 points consists of the covariance matrix for

37
00:02:48.780 --> 00:02:57.310
the previous N points plus one additional row and column as it's shown on the slide.

38
00:02:57.310 --> 00:03:00.890
Mean and covariance for the N points is known.

39
00:03:00.890 --> 00:03:06.030
The conditional distribution of the observation value y_N plus 1 for

40
00:03:06.030 --> 00:03:08.885
a given N previous points has

41
00:03:08.885 --> 00:03:12.850
normal distribution with the following mean and standard deviation values,

42
00:03:12.850 --> 00:03:14.615
as it's shown on the slide.

43
00:03:14.615 --> 00:03:19.335
In this slide, I just would like to remind you one more time

44
00:03:19.335 --> 00:03:24.875
the properties of the conditional distribution for the normal distribution,

45
00:03:24.875 --> 00:03:29.330
and we will use these properties in the next slide.

46
00:03:29.330 --> 00:03:34.670
The conditional distribution properties give us expressions

47
00:03:34.670 --> 00:03:40.440
for the mean and the standard deviation of the observation y_N plus 1,

48
00:03:40.440 --> 00:03:43.720
given N previous points as it's shown on the slide.

49
00:03:43.720 --> 00:03:49.345
Let's plot the mean values for the observation y_N plus 1,

50
00:03:49.345 --> 00:03:51.530
given previous N points.

51
00:03:51.530 --> 00:03:55.475
The mean values are shown as green line in the figure.

52
00:03:55.475 --> 00:04:01.755
This example shows that 10 observations estimates the function very well.

53
00:04:01.755 --> 00:04:05.010
Three Sigma confidence region of

54
00:04:05.010 --> 00:04:09.050
the distribution is shown in the figure as green regions.

55
00:04:09.050 --> 00:04:14.055
In this video, we have learned about Gaussian processes for regression.

56
00:04:14.055 --> 00:04:15.595
In the next video,

57
00:04:15.595 --> 00:04:19.630
we will use them for the Bayesian optimization.