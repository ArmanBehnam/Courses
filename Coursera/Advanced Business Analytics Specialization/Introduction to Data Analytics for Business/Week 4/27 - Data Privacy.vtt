WEBVTT

1
00:00:01.600 --> 00:00:04.970
Information is at the core of just about
everything we do in the world of data

2
00:00:04.970 --> 00:00:06.150
analytics.

3
00:00:06.150 --> 00:00:08.790
And an awful lot of the data we
use is in some way, shape or

4
00:00:08.790 --> 00:00:10.990
form related to real people.

5
00:00:10.990 --> 00:00:14.440
Increasingly concerns are being raised in
the public about the amount of information

6
00:00:14.440 --> 00:00:18.480
that is stored and accessible by both
private organizations and governments.

7
00:00:18.480 --> 00:00:22.180
This includes the risk of identity theft
and other adverse consequences for

8
00:00:22.180 --> 00:00:23.650
consumers and citizen.

9
00:00:23.650 --> 00:00:27.340
Should data that they considered private
somehow be made public or use for

10
00:00:27.340 --> 00:00:30.930
purposes that are unsanctioned
by individuals in question.

11
00:00:30.930 --> 00:00:34.800
In our rules as data analyst, when the
most critical questions we have to ask is

12
00:00:34.800 --> 00:00:38.270
how can we or how should we use data.

13
00:00:38.270 --> 00:00:42.220
In this video we're going to take a broad
look at the idea of the data privacy

14
00:00:42.220 --> 00:00:44.410
by introducing four levels of standards,

15
00:00:44.410 --> 00:00:47.920
the guide how we use data that
might be considered sensitive.

16
00:00:47.920 --> 00:00:52.070
However, we're not going to go into
a lot of detail for a couple of reasons.

17
00:00:52.070 --> 00:00:55.960
First, the set of laws and regulations
that govern data privacy is extensive and

18
00:00:55.960 --> 00:01:00.110
very complex and those regulations
differ depending on where you are.

19
00:01:00.110 --> 00:01:03.640
Secondly, the data privacy landscape
is changing very rapidly and

20
00:01:03.640 --> 00:01:06.340
what's true today might
not be true tomorrow.

21
00:01:06.340 --> 00:01:09.860
Nonetheless, what we will do is give you
a sense for some common definitions and

22
00:01:09.860 --> 00:01:12.180
the types of regulations
that are out there.

23
00:01:12.180 --> 00:01:15.100
Our discussion will be slanted towards
the data privacy environment in

24
00:01:15.100 --> 00:01:18.779
the United States but the same basic
ideas will apply more globally.

25
00:01:19.780 --> 00:01:22.610
Let's outline these four
levels of standards.

26
00:01:22.610 --> 00:01:25.530
The top level is legal standards
which was established by law,

27
00:01:25.530 --> 00:01:29.640
order, or rule to compel treatment
of certain classes of data.

28
00:01:29.640 --> 00:01:33.650
Legal standards must be followed by
any organizations subject to them.

29
00:01:33.650 --> 00:01:35.720
There's not a lot of
choice in the matter and

30
00:01:35.720 --> 00:01:38.750
consequences can be severe if
legal standards are not followed.

31
00:01:38.750 --> 00:01:42.230
The second level is ethical standard.

32
00:01:42.230 --> 00:01:44.090
These standards
are established by industry or

33
00:01:44.090 --> 00:01:47.960
professional organizations which see
to achieve some level of non-legally

34
00:01:47.960 --> 00:01:50.050
binding treatment of information.

35
00:01:50.050 --> 00:01:52.920
There can be consequences for
violating these standards but

36
00:01:52.920 --> 00:01:55.300
they are usually imposed
outside of the courts.

37
00:01:56.380 --> 00:01:59.080
The third level of standards
are policy standards,

38
00:01:59.080 --> 00:02:02.920
which are internal standards established
by an organization to guide its own

39
00:02:02.920 --> 00:02:07.180
treatment of data, usually through
something like a privacy policy.

40
00:02:07.180 --> 00:02:09.700
The company decides how to
enforce these standards.

41
00:02:10.870 --> 00:02:15.150
The last level of standards is simply
what we might call good judgment.

42
00:02:15.150 --> 00:02:19.320
Even if some action is not prohibited
by legal, ethical, or policy standards.

43
00:02:19.320 --> 00:02:23.080
We should always ask ourselves,
is this really a good idea and

44
00:02:23.080 --> 00:02:26.129
what might the consequences of
using data in certain way be?

45
00:02:27.870 --> 00:02:30.660
We're going to go into each of these
areas in a bit more detail but

46
00:02:30.660 --> 00:02:33.450
we'll spend the most time
discussing a few types of data and

47
00:02:33.450 --> 00:02:34.890
the legal standards attached to them.

48
00:02:36.600 --> 00:02:40.200
Let's start with something called
Personally Identifiable Information

49
00:02:40.200 --> 00:02:40.800
or PII.

50
00:02:41.860 --> 00:02:46.880
Like most terms associated with data
privacy, PII has a long definition.

51
00:02:46.880 --> 00:02:52.320
As defined by the US National Institutes
of Standard or NIST, PII includes

52
00:02:52.320 --> 00:02:57.000
any information about an individual
maintained by an agency including.

53
00:02:57.000 --> 00:03:00.520
One, any information that can
be used to distinguish or

54
00:03:00.520 --> 00:03:05.410
trace an individual's identity such
as name, social security number,

55
00:03:05.410 --> 00:03:09.487
date and place of birth,
mother/maiden name or biometric records.

56
00:03:09.487 --> 00:03:14.820
And two, any other information that is
linked or linkable to an individual,

57
00:03:14.820 --> 00:03:19.360
such as medical, educational,
financial, and employment information.

58
00:03:19.360 --> 00:03:21.420
Here are some examples of
what is considered PII.

59
00:03:21.420 --> 00:03:25.740
All or part of someone's name,
including maiden name.

60
00:03:25.740 --> 00:03:27.250
Any identification number,

61
00:03:27.250 --> 00:03:31.760
address information, personal physical
characteristics including images.

62
00:03:31.760 --> 00:03:34.080
And any number of things
that may be linked to one or

63
00:03:34.080 --> 00:03:36.560
more of these definitive identifiers.

64
00:03:36.560 --> 00:03:40.880
The linked data part of the PII
definition is particularly interesting,

65
00:03:40.880 --> 00:03:45.410
as it includes just about anything that I
could conceivably link to an individual.

66
00:03:45.410 --> 00:03:48.150
In the area of Internet connectivity and
big data

67
00:03:48.150 --> 00:03:52.000
the ability to link information across
desperate domains has never been greater.

68
00:03:53.170 --> 00:03:57.990
In fact, both the National Institution of
Standards and the US Office of Management

69
00:03:57.990 --> 00:04:03.490
and Budget, OMB have recognized how easy
it might be to identifying individuals.

70
00:04:03.490 --> 00:04:04.869
Let's read part of their findings.

71
00:04:06.590 --> 00:04:11.190
A common misconception is that PII only
includes data that can be used to directly

72
00:04:11.190 --> 00:04:11.920
identify or

73
00:04:11.920 --> 00:04:16.700
contact an individual or personal
data that is especially sensitive.

74
00:04:16.700 --> 00:04:20.570
The OMB and
NIST definition of PII is broader.

75
00:04:20.570 --> 00:04:24.630
The definition is also dynamic and
can depend on context.

76
00:04:24.630 --> 00:04:29.310
Data elements that may not an identifying
individual directly for example, age,

77
00:04:29.310 --> 00:04:34.150
height, birth date, may nonetheless
constitute PIl if those data

78
00:04:34.150 --> 00:04:39.800
elements can be combined with or without
additional data to identify an individual.

79
00:04:39.800 --> 00:04:41.650
In other words, if the data are linked or

80
00:04:41.650 --> 00:04:45.900
can be linked to the specific
individual it is potentially PII.

81
00:04:47.380 --> 00:04:50.120
Moreover, what can be personally
linked to an individual

82
00:04:50.120 --> 00:04:53.680
may depend on what technology
is available to do so.

83
00:04:53.680 --> 00:04:58.510
As technology advances, computer programs
may scan the Internet with wider scope

84
00:04:58.510 --> 00:05:01.430
to create a mosaic of
information that maybe used to

85
00:05:01.430 --> 00:05:05.990
link information to an individual in
ways that were not previously possible.

86
00:05:05.990 --> 00:05:08.560
This is often referred
to as the mosaic effect.

87
00:05:10.110 --> 00:05:13.520
The implications of this
mosaic effect are significant.

88
00:05:13.520 --> 00:05:15.990
Let's put a really fine point
on this with a little math.

89
00:05:17.120 --> 00:05:21.310
Let's assume that we can find some number
of characteristics on which people differ.

90
00:05:21.310 --> 00:05:25.520
To keep it simple, let's say that each
characteristic can only have two values

91
00:05:25.520 --> 00:05:29.790
like male or female, homeowner or
renter, married or not married, etc.

92
00:05:29.790 --> 00:05:34.280
It turns out that the number of different
types of people I can have with

93
00:05:34.280 --> 00:05:37.970
n attributes of two values
each is two to the n.

94
00:05:37.970 --> 00:05:39.050
So how many people is that?

95
00:05:40.210 --> 00:05:42.170
Let's say that we can
assemble 29 attributes.

96
00:05:43.320 --> 00:05:48.770
With 29 attributes, we can describe up to
just over 500 million types of people,

97
00:05:48.770 --> 00:05:52.380
which is significantly more than the US
population of about 320 million.

98
00:05:53.620 --> 00:05:57.080
What if have just a few more attributes,
say 33?

99
00:05:57.080 --> 00:06:03.140
With 33 attributes, we could describe
eight and a half billion types of people

100
00:06:03.140 --> 00:06:08.000
which is more than the world wide
population of about 7.4 billion people.

101
00:06:08.000 --> 00:06:09.370
Shall we keep going?

102
00:06:09.370 --> 00:06:11.000
Let's do one more.

103
00:06:11.000 --> 00:06:16.910
With 37 attributes we could describe
over 137 billion types of people which

104
00:06:16.910 --> 00:06:21.369
is more than the estimated 108 billion
people that have ever lived on the Earth.

105
00:06:22.450 --> 00:06:27.040
The point is this, it takes a surprisingly
small number of data points to uniquely

106
00:06:27.040 --> 00:06:29.610
identify a very large number of people.

107
00:06:29.610 --> 00:06:32.870
Of course those data points need to
be the right ones but you can see

108
00:06:32.870 --> 00:06:36.379
how this mosaic effect can have a very
real implication on data privacy.

109
00:06:37.750 --> 00:06:40.920
What's really interesting about PII
is that while there are quite a few

110
00:06:40.920 --> 00:06:44.580
legal standards they tend to be narrowly
associated with specific government

111
00:06:44.580 --> 00:06:48.800
agencies or specific use cases
especially in the United States.

112
00:06:48.800 --> 00:06:52.890
International standards are a bit more
stringent but there's surprisingly little

113
00:06:52.890 --> 00:06:56.909
over arching legislation that restricts
how personal information can be used.

114
00:06:58.130 --> 00:07:02.420
Here's a short list of some of the
regulations that do cover PII in some way.

115
00:07:02.420 --> 00:07:05.940
We won't go through them, but you can use
this as a reference point should you need

116
00:07:05.940 --> 00:07:08.060
to understand PII standards more deeply.

117
00:07:10.230 --> 00:07:13.870
The second type of information we'll
discuss is consumer financial information,

118
00:07:13.870 --> 00:07:15.290
or CFI.

119
00:07:15.290 --> 00:07:18.790
CFI is defined in the US by
the Gramm-Leach-Bliley Act,

120
00:07:18.790 --> 00:07:23.440
also known as the Financial Services
Modernization Act of 1999, as follows.

121
00:07:24.550 --> 00:07:28.480
CFI is any information that
is not publicly available.

122
00:07:28.480 --> 00:07:32.200
And that a consumer provides to
a financial institution to obtain

123
00:07:32.200 --> 00:07:35.300
a financial product or
service from the institution.

124
00:07:35.300 --> 00:07:37.810
Results from a transaction
between the consumer and

125
00:07:37.810 --> 00:07:41.540
the institution involving
a financial product or service.

126
00:07:41.540 --> 00:07:45.820
Or that a financial institution otherwise
obtains about a customer in connection

127
00:07:45.820 --> 00:07:47.659
with providing a financial product or
service.

128
00:07:48.850 --> 00:07:53.250
This definition is further incorporated
into a variety of Federal Trade Commission

129
00:07:53.250 --> 00:07:54.020
and Securities and

130
00:07:54.020 --> 00:07:57.750
Exchange Commission guidelines, as well
as into the Fair Credit Reporting Act.

131
00:07:59.580 --> 00:08:03.260
Regulations around CFI are a little
more concrete than those around PII.

132
00:08:03.260 --> 00:08:07.528
Here are some general
information of CFI legislation.

133
00:08:07.528 --> 00:08:10.660
First, it generally applied
to financial institutions and

134
00:08:10.660 --> 00:08:15.600
those who collect nonpublic personal
information from customers, consumers or

135
00:08:15.600 --> 00:08:16.810
financial institutions.

136
00:08:18.130 --> 00:08:21.430
They include a number of specific
provisions and how account numbers and

137
00:08:21.430 --> 00:08:23.679
other specific pieces of
information must be treated.

138
00:08:24.900 --> 00:08:27.840
However, most of the rules
are around disclosure

139
00:08:27.840 --> 00:08:30.620
versus prescription of what's allowed or
not allowed.

140
00:08:30.620 --> 00:08:34.170
This means that they don't so much
restrict what we can do with information,

141
00:08:34.170 --> 00:08:38.020
but rather outline what we need to tell
customers about that information and

142
00:08:38.020 --> 00:08:41.300
what options customers must have to
restrict use of their information.

143
00:08:42.320 --> 00:08:47.170
And important detail here is that these
regulations default when opt-out posture.

144
00:08:47.170 --> 00:08:50.610
Meaning that if customers don't want
information using certain ways,

145
00:08:50.610 --> 00:08:52.990
they must actively
opt-out from those users.

146
00:08:54.070 --> 00:08:56.500
So that's customer financial Information.

147
00:08:56.500 --> 00:08:59.450
Let's move on to another type
of customer information called

148
00:08:59.450 --> 00:09:03.631
customer proprietary network
information or CPNI.

149
00:09:03.631 --> 00:09:08.290
CPNI is collected by telecommunications
companies about a customers

150
00:09:08.290 --> 00:09:09.630
telephone calls.

151
00:09:09.630 --> 00:09:14.410
It includes the time, date, duration and
destination number of each call.

152
00:09:14.410 --> 00:09:16.970
The type of network
a customer subscribes to and

153
00:09:16.970 --> 00:09:20.850
any other information that appears
on the customer's telephone bill.

154
00:09:20.850 --> 00:09:25.210
Importantly, this definition does
not explicitly include non-telephone

155
00:09:25.210 --> 00:09:26.830
activity like web browsing.

156
00:09:26.830 --> 00:09:29.620
Although they were varying legal
opinions on wether this type of

157
00:09:29.620 --> 00:09:32.440
information is covered
under CPNI regulations.

158
00:09:34.340 --> 00:09:40.670
CPNI regulations are generally governed by
the US Telecommunications Act of 1996 and

159
00:09:40.670 --> 00:09:45.540
the 2007 Federal Communications Commission
or FCC CPNI Order.

160
00:09:45.540 --> 00:09:50.070
There are also broader statutes like the
Electronic Communications Privacy Act of

161
00:09:50.070 --> 00:09:53.010
1986 and the Communications Assistance for

162
00:09:53.010 --> 00:09:57.860
Law Enforcement Act of 1994 or
CALEA which speak to the conditions

163
00:09:57.860 --> 00:10:01.140
under which the government can access to
this and other types of electronic data.

164
00:10:02.670 --> 00:10:05.650
Here's some key provisions
of CPNI legislation.

165
00:10:05.650 --> 00:10:09.080
First, it limits the information which
carriers may provide the third-party

166
00:10:09.080 --> 00:10:13.360
marketing firms without first securing the
affirmative consent of their customers.

167
00:10:13.360 --> 00:10:14.480
It also defines when and

168
00:10:14.480 --> 00:10:17.360
how customers service representatives
may share call details.

169
00:10:18.470 --> 00:10:22.470
It establishes notification and reporting
obligations for carriers as well as

170
00:10:22.470 --> 00:10:26.760
identity verification procedures
including a specific requirement.

171
00:10:26.760 --> 00:10:29.610
The verification processes
must include a match

172
00:10:29.610 --> 00:10:33.690
between information provided by a person
and what is shown in a company's systems.

173
00:10:35.520 --> 00:10:37.980
There are a couple of interesting
details to these rules.

174
00:10:37.980 --> 00:10:42.140
For one thing, they do allow a company
to freely share information with

175
00:10:42.140 --> 00:10:46.720
any other communications company which
is a pretty broad set of players.

176
00:10:46.720 --> 00:10:52.450
Secondly, like CFI rules, CPNI regulations
take an opt-out posture by default.

177
00:10:54.340 --> 00:10:58.080
The last type of information we'll talk
about is Protected Health Information or

178
00:10:58.080 --> 00:10:59.550
PHI.

179
00:10:59.550 --> 00:11:03.210
PHI is considered one of the most
sensitive types of information and

180
00:11:03.210 --> 00:11:06.760
consequently it's among those
tightly controlled and regulated.

181
00:11:06.760 --> 00:11:10.750
In the US, PHI is defined under
the Health Insurance Portability and

182
00:11:10.750 --> 00:11:14.110
Accountability Act of 1996 or HIPAA.

183
00:11:14.110 --> 00:11:17.330
The definition is three parts and
reflects the detail involved.

184
00:11:18.410 --> 00:11:22.980
One, PHI is created or received by
a health care provider, health plan,

185
00:11:22.980 --> 00:11:24.944
employer, or health care clearinghouse.

186
00:11:24.944 --> 00:11:29.650
Two, it relates to the past, present or

187
00:11:29.650 --> 00:11:33.370
future physical or mental health or
condition of an individual,

188
00:11:33.370 --> 00:11:37.270
the provision of health care to
an individual or the past, present or

189
00:11:37.270 --> 00:11:40.740
future payment for the provision
of health care to an individual.

190
00:11:40.740 --> 00:11:43.150
And which either identifies
the individual or

191
00:11:43.150 --> 00:11:45.940
with respect to which there is
a reasonable basis to believe

192
00:11:45.940 --> 00:11:48.590
the information can be used
to identify the individual.

193
00:11:49.930 --> 00:11:55.140
And three,
is maintained in electronic media,

194
00:11:55.140 --> 00:11:57.830
or transmitted or
maintained in any other form or medium.

195
00:11:59.460 --> 00:12:02.281
The provisions of HIPAA around
PHI are pretty complex and

196
00:12:02.281 --> 00:12:04.610
we won't get into the details here.

197
00:12:04.610 --> 00:12:07.980
However, there are broadly
covered under our privacy rule

198
00:12:07.980 --> 00:12:12.380
which speaks to the safeguards that must
be taken to protect PHI in any form.

199
00:12:12.380 --> 00:12:16.020
And a security role which provides
additional measures that must be taken

200
00:12:16.020 --> 00:12:17.840
when information is stored electronically.

201
00:12:19.010 --> 00:12:22.060
The rules applied to health care
providers, health plans and

202
00:12:22.060 --> 00:12:23.650
health care clearinghouses.

203
00:12:23.650 --> 00:12:26.930
And they include a lot of specific
provisions around how certain types of

204
00:12:26.930 --> 00:12:31.160
data need to be treated including the
stripping out of identifiable information

205
00:12:31.160 --> 00:12:31.929
in other precaution.

206
00:12:33.430 --> 00:12:36.620
There are a couple of important
exclusions to HIPAA regulations.

207
00:12:36.620 --> 00:12:39.460
First, they exclude
education records covered by

208
00:12:39.460 --> 00:12:42.170
the Family Educational Rights and
Privacy Act.

209
00:12:42.170 --> 00:12:45.980
They also exclude employment records
held by a covered entity in its role

210
00:12:45.980 --> 00:12:46.550
as employer.

211
00:12:48.090 --> 00:12:52.390
Okay, that's a lot of information so
let's recap before we move on.

212
00:12:52.390 --> 00:12:56.730
So far we have defined personally
identifiable information PII,

213
00:12:56.730 --> 00:13:02.430
customer financial information, CFI,
customer proprietary network information,

214
00:13:02.430 --> 00:13:05.270
CPNI and protected heath information PHI.

215
00:13:06.300 --> 00:13:08.800
We've also covered the major
legal standards that apply to

216
00:13:08.800 --> 00:13:11.829
each type of information including
major legislation and provision.

217
00:13:12.960 --> 00:13:16.120
Now let's talk about some of those other
types of standards that influence how we

218
00:13:16.120 --> 00:13:18.820
use data, starting with ethical standards.

219
00:13:18.820 --> 00:13:22.410
Most academic, scientific, legal,
and medical fields have pretty well

220
00:13:22.410 --> 00:13:25.760
established standards making bodies
that hold members accountable for

221
00:13:25.760 --> 00:13:29.910
a broad set of ethical behaviors,
some of which include the use of data.

222
00:13:29.910 --> 00:13:33.920
For example, in the US these might
include State Bar Association,

223
00:13:33.920 --> 00:13:38.490
the American Medical Association, or
other field specific organizations.

224
00:13:38.490 --> 00:13:41.980
For these more formal bodies,
the consequences of violating ethical

225
00:13:41.980 --> 00:13:45.860
standards are usually sanctions or
being kicked out of the organization.

226
00:13:45.860 --> 00:13:48.030
This can sometimes be pretty severe.

227
00:13:48.030 --> 00:13:52.140
For example, a lawyer being disbarred
usually ends or severely limits his or

228
00:13:52.140 --> 00:13:52.700
her career.

229
00:13:54.170 --> 00:13:57.270
In the business world it turns out that
some of the more relevant ethics and

230
00:13:57.270 --> 00:14:00.010
standards bodies operate
in the area of marketing,

231
00:14:00.010 --> 00:14:03.220
which makes sense as we're generally
interacting with customers through some

232
00:14:03.220 --> 00:14:05.960
sort of market activity or interface.

233
00:14:05.960 --> 00:14:08.550
These include the direct
marketing association

234
00:14:08.550 --> 00:14:12.090
which provides broad guidelines on
how to interact with customers.

235
00:14:12.090 --> 00:14:16.120
The digital advertising alliance
which adds guidance on first party

236
00:14:16.120 --> 00:14:17.360
data collection.

237
00:14:17.360 --> 00:14:20.720
And the network advertising initiative
which addresses third-party

238
00:14:20.720 --> 00:14:24.470
data collection and the practice of
sharing data through data exchanges.

239
00:14:24.470 --> 00:14:25.700
However, the ability for

240
00:14:25.700 --> 00:14:29.690
these types of organizations to enforce
their standards is much weaker.

241
00:14:29.690 --> 00:14:33.370
Companies typically comply out of choice,
not out of necessity.

242
00:14:33.370 --> 00:14:36.495
But it's generally good practice to
comply with these guidelines anyway.

243
00:14:38.100 --> 00:14:41.490
In addition to both the legal and ethical
guidelines established by governments and

244
00:14:41.490 --> 00:14:44.850
other external entities,
companies almost always establish their

245
00:14:44.850 --> 00:14:47.880
own internal policies
regarding data privacy.

246
00:14:47.880 --> 00:14:51.230
It's common practice to make these
policies available to customers and

247
00:14:51.230 --> 00:14:54.220
even proactively ensure that
customers read and acknowledge them.

248
00:14:55.760 --> 00:14:59.210
Each company can have different
permissions governing its privacy policy

249
00:14:59.210 --> 00:15:02.550
but generally speaking these policies
outline what data is captured and

250
00:15:02.550 --> 00:15:05.940
shared and usually outline opt out or
opt in procedure.

251
00:15:05.940 --> 00:15:08.870
As a data analyst, it's really up to you

252
00:15:08.870 --> 00:15:12.640
to ensure that you're aware of both the
legal and ethical standards that apply,

253
00:15:12.640 --> 00:15:16.220
as well as your organization's
policies around use of data.

254
00:15:16.220 --> 00:15:19.400
However, there's one final
standard that always applies

255
00:15:19.400 --> 00:15:21.690
regardless of what other rules exist.

256
00:15:21.690 --> 00:15:24.180
That standard is good judgment.

257
00:15:24.180 --> 00:15:26.240
Think about what it is you're about to do.

258
00:15:26.240 --> 00:15:28.980
Even if it's legal,
even if it's ethical and

259
00:15:28.980 --> 00:15:32.670
even if it falls within corporate policy
it still might not be a good idea.

260
00:15:33.830 --> 00:15:38.320
As a general rule if it doesn't feel
right chances are it's not a good idea.

261
00:15:38.320 --> 00:15:41.290
If you think your customers would be
upset if they knew what you were doing

262
00:15:41.290 --> 00:15:43.250
It may not be a good idea.

263
00:15:43.250 --> 00:15:46.450
Here are few things to think as you
develop your own sixth sense for

264
00:15:46.450 --> 00:15:47.350
what's good and what';s not.

265
00:15:48.610 --> 00:15:51.310
The first is the creepiness factor.

266
00:15:51.310 --> 00:15:54.490
We often use data and analytics to
provide the best most customized

267
00:15:54.490 --> 00:15:56.530
offers that we can do our customers but

268
00:15:56.530 --> 00:15:59.780
there is a fine line between
what's relevant and what's creepy.

269
00:15:59.780 --> 00:16:02.560
Especially if the customer sees
things based on information they

270
00:16:02.560 --> 00:16:04.240
don't know you have.

271
00:16:04.240 --> 00:16:07.800
Put yourself in the customers used and
ask yourself how you perceive an action.

272
00:16:09.260 --> 00:16:13.150
Secondly, it's generally a good idea
to stay out of the news especially for

273
00:16:13.150 --> 00:16:14.800
the wrong reasons.

274
00:16:14.800 --> 00:16:18.590
Ask yourself what the consequences would
be if your methods were made public and

275
00:16:18.590 --> 00:16:20.330
everyone could see what you're doing.

276
00:16:20.330 --> 00:16:22.160
Would there be a backlash?

277
00:16:22.160 --> 00:16:25.530
A third thing to think about is what
the unintended consequences of your

278
00:16:25.530 --> 00:16:27.050
actions might be.

279
00:16:27.050 --> 00:16:29.930
You're obviously trying to get
customers to do one thing but

280
00:16:29.930 --> 00:16:32.820
what if they did something else entirely,
how bad would that be?

281
00:16:34.380 --> 00:16:38.480
Even if you were purely focused on
the economics of a decision without regard

282
00:16:38.480 --> 00:16:42.240
to anything else and I'm definitely
not advocating that approach.

283
00:16:42.240 --> 00:16:46.710
One might argue that you should end up
with a good decision almost all the time

284
00:16:46.710 --> 00:16:49.330
if you properly asses the risk.

285
00:16:49.330 --> 00:16:51.850
Most folks who get themselves
in the trouble fail to

286
00:16:51.850 --> 00:16:56.030
accurately asses the huge downsides
associated with bad behavior.

287
00:16:56.030 --> 00:16:59.840
Assume the worst and you're much more
likely to stay on the high road.

288
00:16:59.840 --> 00:17:02.570
So in summary,
where data privacy is concerned,

289
00:17:02.570 --> 00:17:05.750
you have four levels of standards
that can guide your behavior.

290
00:17:05.750 --> 00:17:11.950
Legal standards, ethical standards, policy
standards, and above all, good judgement.

291
00:17:11.950 --> 00:17:15.460
Heed them wisely, and you'll have
a longer and more successful career.