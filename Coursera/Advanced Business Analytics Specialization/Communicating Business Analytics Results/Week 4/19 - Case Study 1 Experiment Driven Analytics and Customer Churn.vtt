WEBVTT

1
00:00:00.550 --> 00:00:03.380
Welcome back,
before bringing the course to a close,

2
00:00:03.380 --> 00:00:06.410
we we want to provide a couple of stories,
or short case studies.

3
00:00:06.410 --> 00:00:09.330
That illustrate in a bit more
detail how analytics are applied in

4
00:00:09.330 --> 00:00:10.920
real business problems.

5
00:00:10.920 --> 00:00:13.890
In this video, we'll walk through
a real example of how experiment

6
00:00:13.890 --> 00:00:16.550
driven analytics revealed
some surprising insights

7
00:00:16.550 --> 00:00:19.700
around the phenomenon of customer
churn in the wireless industry.

8
00:00:19.700 --> 00:00:22.520
Let's jump right in,
in the early days of mobile phones,

9
00:00:22.520 --> 00:00:26.010
wireless carriers had a hard
time attracting new customers.

10
00:00:26.010 --> 00:00:29.970
The phone itself is very expensive and the
mass is simply weren't willing to shell

11
00:00:29.970 --> 00:00:32.230
out a hundreds of dollars
upfront to buy it.

12
00:00:32.230 --> 00:00:35.290
Especially, given that the technology
was new and unfamiliar.

13
00:00:35.290 --> 00:00:36.630
To stimulate adoption and

14
00:00:36.630 --> 00:00:40.720
customer acquisition, most carriers
started providing the phones for free.

15
00:00:40.720 --> 00:00:43.980
With the idea that they could recoup their
investment through somewhat higher monthly

16
00:00:43.980 --> 00:00:45.210
service fees.

17
00:00:45.210 --> 00:00:48.010
This presented a high
business risk to the carrier.

18
00:00:48.010 --> 00:00:49.580
If customers didn't stick around for

19
00:00:49.580 --> 00:00:53.750
long enough, they wouldn't recoup the cost
in the free phones and they lose money.

20
00:00:53.750 --> 00:00:57.770
Here's are really simplified view of
what this looks like analytically.

21
00:00:57.770 --> 00:01:02.400
What we're looking at here is the cashflow
diagram for a typical wireless customer.

22
00:01:02.400 --> 00:01:05.850
It shows the net what the customer
pays less the cost incurred by

23
00:01:05.850 --> 00:01:07.370
the carrier by month.

24
00:01:07.370 --> 00:01:10.660
In this example,
we see a large negative cash flow

25
00:01:10.660 --> 00:01:14.140
of about $600 at the beginning of
the relationship in month zero.

26
00:01:14.140 --> 00:01:16.770
This represents the cost
of the free phone.

27
00:01:16.770 --> 00:01:21.070
Then we see a series of small positive
cash flows of about $30 per month

28
00:01:21.070 --> 00:01:24.090
which represent the month we
service fees paid by the customer

29
00:01:24.090 --> 00:01:26.670
less the cost of providing that service.

30
00:01:26.670 --> 00:01:30.950
With this information we can calculate
the cumulative cash flow overtime.

31
00:01:30.950 --> 00:01:35.250
Note that it takes about 20 months for the
cumulative cash flow to become positive.

32
00:01:35.250 --> 00:01:38.670
And a bit longer for the carrier to
actually make a reasonable profit.

33
00:01:38.670 --> 00:01:42.400
This example is a simplified version of
what we do in customer lifetime value

34
00:01:42.400 --> 00:01:43.430
analysis.

35
00:01:43.430 --> 00:01:46.670
We basically look at the total
profitability of an individual customer

36
00:01:46.670 --> 00:01:49.520
over their lifetime by looking
at the actual revenues and

37
00:01:49.520 --> 00:01:51.770
costs associated with that customer.

38
00:01:51.770 --> 00:01:55.500
By doing this type of analysis,
carriers figured out that customers

39
00:01:55.500 --> 00:01:59.450
really needed to stick around for about
two years on average to be profitable.

40
00:01:59.450 --> 00:02:02.926
So the industry converged relatively
quickly on the two-year contract as

41
00:02:02.926 --> 00:02:04.424
a standard business practice.

42
00:02:14.127 --> 00:02:18.440
The strategy worked well for attracting
new customers, but it created a problem.

43
00:02:18.440 --> 00:02:21.310
Historically, mobile phone service
had some of the lowest customer

44
00:02:21.310 --> 00:02:23.430
satisfaction scores across the board.

45
00:02:23.430 --> 00:02:27.290
And it was particularly poor during this
period as carriers struggled with network

46
00:02:27.290 --> 00:02:29.020
quality and coverage gaps.

47
00:02:29.020 --> 00:02:32.060
At the same time, there wasn't much
structure in place for what to do with

48
00:02:32.060 --> 00:02:35.880
existing customers, especially
when initial contracts were over.

49
00:02:35.880 --> 00:02:37.070
So you can imagine what happened,

50
00:02:37.070 --> 00:02:41.140
we have customers with low satisfaction
whose contracts have expired.

51
00:02:41.140 --> 00:02:44.480
They see a competitor who give
them a new phone if they switched.

52
00:02:44.480 --> 00:02:48.120
The result was a very high degree
of customer turnover called Churn

53
00:02:48.120 --> 00:02:49.410
in the industry.

54
00:02:49.410 --> 00:02:53.530
In fact, it wasn't uncommon to
see Churn rates of up to 3% per

55
00:02:53.530 --> 00:02:56.530
month in the customer base,
think about that.

56
00:02:56.530 --> 00:03:00.910
Annualized that's over a third of
the customer base leading per year.

57
00:03:00.910 --> 00:03:04.620
Obviously, carriers start to realize
this was a significant problem.

58
00:03:04.620 --> 00:03:06.140
Especially as the market matured and

59
00:03:06.140 --> 00:03:09.530
there were fewer and fewer people
who are completely new to wireless.

60
00:03:09.530 --> 00:03:13.370
To continue to grow then we need to
figure out how to retain more customers.

61
00:03:13.370 --> 00:03:17.087
The nice thing about the contract is that
it gave a wireless carrier pretty good

62
00:03:17.087 --> 00:03:19.244
idea of about when
the customer might leave.

63
00:03:19.244 --> 00:03:23.500
It is a really simple analysis to show
what true rating by customers looks like.

64
00:03:23.500 --> 00:03:26.184
In fact, we showed this
example in a separate video.

65
00:03:26.184 --> 00:03:29.709
You can see the large spike in churn
rate that occurs right after the 24

66
00:03:29.709 --> 00:03:30.950
month point.

67
00:03:30.950 --> 00:03:33.610
This response to the expiry
of the contract.

68
00:03:33.610 --> 00:03:35.500
This is where a case study really begins.

69
00:03:36.700 --> 00:03:40.410
A particular wireless carrier wanted to
explore how they might incent customers to

70
00:03:40.410 --> 00:03:41.870
stick around longer.

71
00:03:41.870 --> 00:03:44.660
In particular they wanted to see if
they could get customers to renew their

72
00:03:44.660 --> 00:03:47.900
contracts which would lock
in a longer revenue string.

73
00:03:47.900 --> 00:03:50.064
What they didn't know is
how they should do it?

74
00:03:50.064 --> 00:03:51.708
How should they contact customers?

75
00:03:51.708 --> 00:03:53.315
When should they contact customers?

76
00:03:53.315 --> 00:03:57.150
How much incentive will it take to get
the customer to renew their contract?

77
00:03:57.150 --> 00:04:01.450
Should they renew for another two years or
for a shorter period like one year?

78
00:04:01.450 --> 00:04:04.470
Because the contract renewal
effort had never been attempted.

79
00:04:04.470 --> 00:04:08.110
There is no historical data to
analyze to answer these questions.

80
00:04:08.110 --> 00:04:10.740
So a controlled experiment was
designed to test a number of

81
00:04:10.740 --> 00:04:14.000
factors to see what combination
of things would work best.

82
00:04:14.000 --> 00:04:17.830
You would reach out to customers with
some sort of contract renewal campaign.

83
00:04:17.830 --> 00:04:21.660
And test the number of things they thought
might impact how likely customers would be

84
00:04:21.660 --> 00:04:23.580
to renew their contracts.

85
00:04:23.580 --> 00:04:25.910
Specifically, here's what was tested,

86
00:04:25.910 --> 00:04:28.450
three communication
channels were considered.

87
00:04:28.450 --> 00:04:32.090
A bill insert which is basically just
an additional note that's included with

88
00:04:32.090 --> 00:04:34.180
a bill when it comes in the mail.

89
00:04:34.180 --> 00:04:37.820
A stand-alone direct mail piece and
an outbound call to a customer.

90
00:04:39.020 --> 00:04:41.690
The two paper channels were
directed to customer to a 1-800

91
00:04:41.690 --> 00:04:44.000
number to speak with an agent.

92
00:04:44.000 --> 00:04:47.710
Keep in mind this was before we could
reliably use electronic channels like

93
00:04:47.710 --> 00:04:49.290
emails and text messaging.

94
00:04:49.290 --> 00:04:50.590
From a timing perspective,

95
00:04:50.590 --> 00:04:54.380
customers would be contacted two
months before the contract expiry.

96
00:04:54.380 --> 00:04:58.068
One month prior to contract expiry and
just after the contract expired.

97
00:04:58.068 --> 00:05:05.290
Three levels of incentives would
be included, $50, $100 and $150.

98
00:05:05.290 --> 00:05:09.530
Finally, both two renewal and
one renewal options will be tested.

99
00:05:10.950 --> 00:05:14.580
One nice thing about wireless carriers
is that they have a lot of customers.

100
00:05:14.580 --> 00:05:17.800
Most of the major carriers at that
time is between 50 millions and

101
00:05:17.800 --> 00:05:19.370
80 millions customers each.

102
00:05:19.370 --> 00:05:22.570
So it's pretty easy to isolate a large
group of customers who are nearly

103
00:05:22.570 --> 00:05:23.960
contract expiring.

104
00:05:23.960 --> 00:05:28.250
And was possible to run what we called
fully factorial experiment which

105
00:05:28.250 --> 00:05:32.700
basically means that all combinations
of all levels of factors were tested.

106
00:05:32.700 --> 00:05:37.140
In this case that meant that they were
three channels, by three time points,

107
00:05:37.140 --> 00:05:43.050
by three incentive levels, by two contract
types, or 54 total test combinations.

108
00:05:43.050 --> 00:05:46.710
Plus a single control group
that was not contacted at all.

109
00:05:46.710 --> 00:05:50.640
Sample sizes for the group were chosen
using statistical methods to ensure

110
00:05:50.640 --> 00:05:54.190
differences between them could be
detective with high degree and precision.

111
00:05:54.190 --> 00:05:58.190
And the group itself were chosen at
random, because small changes in customer

112
00:05:58.190 --> 00:06:00.860
behaviors tend to have
large financial impacts.

113
00:06:00.860 --> 00:06:04.670
The group sizes were large
about 10,000 in each group.

114
00:06:04.670 --> 00:06:08.710
But even at that size, less than
600,000 subscribers were needed for

115
00:06:08.710 --> 00:06:09.760
the experiment.

116
00:06:09.760 --> 00:06:11.130
To put that in perspective,

117
00:06:11.130 --> 00:06:14.700
it was less than one month's worth
of expiring contract customers.

118
00:06:14.700 --> 00:06:18.510
While the direct marketing aspects of
the experiment were being operationalized,

119
00:06:18.510 --> 00:06:22.280
an analytic plan for
analyzing the results was put in place.

120
00:06:22.280 --> 00:06:24.800
The basic measure they wanted to
know is how many people renew their

121
00:06:24.800 --> 00:06:26.230
contracts, right?

122
00:06:26.230 --> 00:06:29.910
Well, that's true, but for a really robust
analysis, they knew that they needed to

123
00:06:29.910 --> 00:06:34.620
account for unanticipated changes to other
aspects of a customer's behavior as well.

124
00:06:34.620 --> 00:06:38.100
For example, do the customer change their
service plan to something with a different

125
00:06:38.100 --> 00:06:39.160
monthly charge?

126
00:06:39.160 --> 00:06:41.880
Did they change their usage behavior
in any way that would affect

127
00:06:41.880 --> 00:06:43.790
the cost of service to the carrier?

128
00:06:43.790 --> 00:06:47.000
Did they use more or
less customer care resource?

129
00:06:47.000 --> 00:06:50.290
They also knew they needed to consider
both the behavior of customers who did

130
00:06:50.290 --> 00:06:55.340
take an offer to renew a contract, as well
as customers who did not take the offer.

131
00:06:55.340 --> 00:06:57.470
To make sure all
the measures were available,

132
00:06:57.470 --> 00:07:00.620
the analytic plan identified
the right sources of data.

133
00:07:00.620 --> 00:07:04.070
Information from the billing system would
be used to identify the contract status of

134
00:07:04.070 --> 00:07:05.010
a customer.

135
00:07:05.010 --> 00:07:09.190
Whether they had cancelled it or not, and
the actual amount of revenue received.

136
00:07:09.190 --> 00:07:13.040
Information from usage tracking systems
will be use to capture the cost

137
00:07:13.040 --> 00:07:14.060
changes in consumption.

138
00:07:15.200 --> 00:07:18.800
Information from the customer care system
will be use to do the same thing for

139
00:07:18.800 --> 00:07:20.670
changes in calling behavior.

140
00:07:20.670 --> 00:07:23.850
And spreadsheet-based financials
around the marketing campaign itself

141
00:07:23.850 --> 00:07:27.309
will be incorporated the cost of
the contact itself from the incentive.

142
00:07:28.470 --> 00:07:32.260
With the full set of data around customer
behaviors and their financial impacts,

143
00:07:32.260 --> 00:07:36.010
each test group could be compared with
the control group and to each other.

144
00:07:36.010 --> 00:07:39.570
Incremental impact of the contract
renewal after could be calculated and

145
00:07:39.570 --> 00:07:42.810
they could determine what combination
of factors could work best

146
00:07:42.810 --> 00:07:45.320
in a full-scale rollout of the program.

147
00:07:45.320 --> 00:07:48.439
With the planning complete, experimental
campaign was watched in the market.

148
00:07:49.760 --> 00:07:51.190
So, what happened?

149
00:07:51.190 --> 00:07:54.920
Well, before we look at the actual
results, I want to know what you think.

150
00:07:54.920 --> 00:07:58.230
Think about the factors and
levels that were tested in the experiment.

151
00:07:58.230 --> 00:08:02.352
Which combination of factors do you think
produced the most favorable results?

152
00:08:02.352 --> 00:08:06.244
Did the bill insert, standalone direct
mail piece, or outbound call work best for

153
00:08:06.244 --> 00:08:07.225
customer contact?

154
00:08:07.225 --> 00:08:12.130
What's the best time to contact customers
two months before contract expire,

155
00:08:12.130 --> 00:08:16.660
one month before the contract expire or
just after the contract expired?

156
00:08:16.660 --> 00:08:22.427
How large an incentive was required,
$50, or $100 or $150?

157
00:08:22.427 --> 00:08:25.720
Or customers more incline to take
an one year or two year contract?

158
00:08:27.970 --> 00:08:31.010
Take a moment and
think about how you came to your choice.

159
00:08:31.010 --> 00:08:34.165
What considerations or
behaviours led you to pick each item?

160
00:08:37.158 --> 00:08:39.470
This is were things get interesting.

161
00:08:39.470 --> 00:08:42.700
I'm not going to get into the details
of how the calculations worked out or

162
00:08:42.700 --> 00:08:43.870
show you a bunch of charts and

163
00:08:43.870 --> 00:08:48.170
graphs that outline the analysis
because the outcome was really simple.

164
00:08:48.170 --> 00:08:51.340
It turns out that the control
group won every time.

165
00:08:51.340 --> 00:08:54.770
No matter what combination of factors
were applied, the simple act of

166
00:08:54.770 --> 00:08:58.750
reaching out to customers actually
stimulated higher turn rates.

167
00:08:58.750 --> 00:09:02.350
They caused more customers to cancel
by making them an offer to renew

168
00:09:02.350 --> 00:09:03.760
the contract.

169
00:09:03.760 --> 00:09:07.270
A bunch of customers did take the offer
to renew their contracts, but

170
00:09:07.270 --> 00:09:10.305
they apparently are the ones
that were going to stay anyway.

171
00:09:10.305 --> 00:09:13.810
Eventhough we understand a lot more
about customer turn behavior today,

172
00:09:13.810 --> 00:09:17.840
you can imagine how shock the carrier
was at the time to see these results.

173
00:09:17.840 --> 00:09:20.440
The initial reaction was that,
the data had to be wrong or

174
00:09:20.440 --> 00:09:22.180
that the experiment was flawed.

175
00:09:22.180 --> 00:09:26.820
A ton of additional analysis was applied
to revalidate each aspect to the work.

176
00:09:26.820 --> 00:09:31.000
Including retesting some of the same
things which produce the same results.

177
00:09:31.000 --> 00:09:33.620
Additional market research
including focus groups and

178
00:09:33.620 --> 00:09:37.150
customer surveys started to
reveal as really going on.

179
00:09:37.150 --> 00:09:39.970
It turns out that a lot of customers
simply weren't aware of that there

180
00:09:39.970 --> 00:09:44.780
contracts were expiring or just in a low
state of motivation to make a change.

181
00:09:44.780 --> 00:09:49.430
By stimulating that group, they carry
reminded customers about contract and

182
00:09:49.430 --> 00:09:52.090
activated what we call shopping behavior.

183
00:09:52.090 --> 00:09:55.060
When presented in option we tend to
want to know what alternatives are out

184
00:09:55.060 --> 00:09:56.080
there as well.

185
00:09:56.080 --> 00:09:58.660
This means were much more likely
to find a better option and

186
00:09:58.660 --> 00:10:01.870
make a change than we would
be if simply left alone.

187
00:10:01.870 --> 00:10:05.430
In this case, the carrier had
basically kicked the sleeping giant.

188
00:10:05.430 --> 00:10:08.550
Overtime, this carrier and
the wireless industry as a whole,

189
00:10:08.550 --> 00:10:11.370
learned how to better execute
contract renewal efforts.

190
00:10:11.370 --> 00:10:14.000
Much of the improvement was
achieved through experimentation in

191
00:10:14.000 --> 00:10:17.150
the application of more
sophisticated modeling techniques.

192
00:10:17.150 --> 00:10:21.350
First, it was eventually discovered that
customers needed to be contacted well and

193
00:10:21.350 --> 00:10:23.630
advance on their contract expiry dates.

194
00:10:23.630 --> 00:10:26.340
More like six months
versus one to two months,

195
00:10:26.340 --> 00:10:29.720
this avoided shopping behavior since
there was really no option to weave.

196
00:10:29.720 --> 00:10:33.290
And the decision was simply to take
the offer or not take the offer and

197
00:10:33.290 --> 00:10:34.810
wait another six months.

198
00:10:34.810 --> 00:10:37.840
At which point the customer had time
to forget about the contract or

199
00:10:37.840 --> 00:10:39.920
become complacent once again.

200
00:10:39.920 --> 00:10:42.800
Secondly, the offers needed to get richer,

201
00:10:42.800 --> 00:10:46.300
especially when customers were asked
to renew their contracts early.

202
00:10:46.300 --> 00:10:49.890
Eventually the same arms race
dominated new customer acquisition

203
00:10:49.890 --> 00:10:52.210
made its way to customer
retention efforts.

204
00:10:52.210 --> 00:10:56.420
And a phone upgrade became the standard
incentive in contract renewal efforts.

205
00:10:56.420 --> 00:10:59.420
Finally and
most importantly carriers got much better

206
00:10:59.420 --> 00:11:03.840
using predictive analytics to identify
what customers where high risk of turn.

207
00:11:03.840 --> 00:11:06.950
And even which customers in that group
were likely to respond to different

208
00:11:06.950 --> 00:11:08.240
types of offers.

209
00:11:08.240 --> 00:11:11.340
This allowed only high risk
customers to be targeted or

210
00:11:11.340 --> 00:11:12.780
targeted with the richest offers.

211
00:11:13.890 --> 00:11:17.520
There are lot of reasons why I really
like this case than the analytics.

212
00:11:17.520 --> 00:11:20.250
First it really happen,
it's one of the most interesting and

213
00:11:20.250 --> 00:11:23.530
surprising analytic fun except
I experience on my career.

214
00:11:23.530 --> 00:11:26.520
And it underscores the need to
constantly build context and

215
00:11:26.520 --> 00:11:29.600
learn about behaviors that
underpin our analytic efforts.

216
00:11:29.600 --> 00:11:32.540
It's also a great example of
how controlled experimentation

217
00:11:32.540 --> 00:11:36.920
can be used at a large scale to
generate meaningful data for analysis.

218
00:11:36.920 --> 00:11:39.800
And it underscores the importance
of having a control group

219
00:11:39.800 --> 00:11:43.370
looking at a broad set of behaviors
to capture unintended effects.

220
00:11:43.370 --> 00:11:46.580
And examining the impact on both
those that took an offer and

221
00:11:46.580 --> 00:11:48.220
those that did not take an offer.

222
00:11:48.220 --> 00:11:52.250
Finally, it illustrates how a variety of
analytic methods are applied together in

223
00:11:52.250 --> 00:11:53.890
the pursuit of one outcome.

224
00:11:53.890 --> 00:11:58.250
In this case, we saw customer lifetime
value analysis, statistical analysis and

225
00:11:58.250 --> 00:12:02.880
experimental design, campaign analytics,
financial analytics and

226
00:12:02.880 --> 00:12:04.760
predictive and prescriptive analytics.

227
00:12:04.760 --> 00:12:08.480
All applied in an attempt to keep
customers from cancelling their service.

228
00:12:08.480 --> 00:12:10.960
As you encounter problems
in your organization

229
00:12:10.960 --> 00:12:14.750
you may consider how experiments maybe
used in conjunctions with other methods.

230
00:12:14.750 --> 00:12:19.049
To reveal insights, grow your knowledge
in contacts and achieve business results.