WEBVTT

1
00:00:00.005 --> 00:00:03.540
Welcome back, we've spent quite
a bit of time talking about how our

2
00:00:03.540 --> 00:00:07.030
analysis are meant to drive towards
some eventual action in the market.

3
00:00:07.030 --> 00:00:10.510
But sometimes, our analysis actually
reveals that there are more questions we

4
00:00:10.510 --> 00:00:12.670
need to answer before we can move forward.

5
00:00:12.670 --> 00:00:15.958
In this short video, we're going to talk
about one way in which we launch a new

6
00:00:15.958 --> 00:00:18.330
wave of analysis using experimentation.

7
00:00:18.330 --> 00:00:21.120
Let's say that we're a wireless company
and we've done a predictive analysis to

8
00:00:21.120 --> 00:00:24.120
understand who is most likely
to cancel their service.

9
00:00:24.120 --> 00:00:27.580
Those of you who have taken earlier
courses should recognize this example.

10
00:00:27.580 --> 00:00:31.240
We actually want to do something with that
analysis but we're not exactly sure what.

11
00:00:31.240 --> 00:00:34.870
We have a lot of ideas about how we
might reach out to those customers and

12
00:00:34.870 --> 00:00:38.350
get them to stick around, but
we don't know which ideas will work best.

13
00:00:38.350 --> 00:00:41.580
We also know that if we get it wrong,
we can cause a lot of damage.

14
00:00:41.580 --> 00:00:45.300
In this case, it makes sense to do some
sort of small scale test before we roll

15
00:00:45.300 --> 00:00:47.220
out these ideas to our
larger customer base.

16
00:00:47.220 --> 00:00:50.670
Now there's an awful lot of material
available on how to run and

17
00:00:50.670 --> 00:00:52.400
measure controlled experiments and

18
00:00:52.400 --> 00:00:56.760
on the statistics that underpin both the
design and execution of those experiments.

19
00:00:56.760 --> 00:00:59.380
I fully encourage you to take
a full blown statistics and

20
00:00:59.380 --> 00:01:02.250
experimental design course
at some point if you can.

21
00:01:02.250 --> 00:01:04.400
But we won't get into those details here.

22
00:01:04.400 --> 00:01:07.780
Rather, we're just going to focus on
a couple of general principles and

23
00:01:07.780 --> 00:01:10.350
a few examples of how things
happen in the real world.

24
00:01:10.350 --> 00:01:13.420
As you might imagine, some of
the things aren't necessarily ideal.

25
00:01:13.420 --> 00:01:16.280
the basic idea behind
a controlled market experiment

26
00:01:16.280 --> 00:01:18.530
is that they do something
to a set of customers.

27
00:01:18.530 --> 00:01:21.260
We call this applying a treatment
to those customers, and

28
00:01:21.260 --> 00:01:25.000
I compare what happens to those customers
with another set of similar customers that

29
00:01:25.000 --> 00:01:28.050
didn't get the treatment,
we call this a control.

30
00:01:28.050 --> 00:01:31.670
If I do this in the right way, I can
attribute differences in the behavior

31
00:01:31.670 --> 00:01:35.240
between the treatment group and
the control group to the treatment itself.

32
00:01:35.240 --> 00:01:39.000
In an ideal world with a stable
population and predictable behavior,

33
00:01:39.000 --> 00:01:42.870
we can assemble a treatment group and a
control group by randomly selecting people

34
00:01:42.870 --> 00:01:46.550
from the population and
randomly assigning them to each group.

35
00:01:46.550 --> 00:01:50.190
If we do this correctly and our sample
are large enough then we can pretty easily

36
00:01:50.190 --> 00:01:53.430
measure what happens after we apply
the treatment to the treatment group.

37
00:01:53.430 --> 00:01:55.560
Here's an illustration of that scenario.

38
00:01:55.560 --> 00:01:59.580
Let's say we were measuring some outcome
with the value shown on the y axis.

39
00:01:59.580 --> 00:02:02.190
If our treatment and
control groups are truly random and

40
00:02:02.190 --> 00:02:06.290
our treatment has an effect, we should see
identical behavior in the groups before

41
00:02:06.290 --> 00:02:10.400
a treatment is applied and different
behavior after the treatment is applied.

42
00:02:10.400 --> 00:02:12.355
This is what you see here.

43
00:02:12.355 --> 00:02:16.130
It's almost always best that this kind of
controlled experiment can be achieved.

44
00:02:16.130 --> 00:02:19.846
However in the real world, it's sometimes
the case we can't actually execute

45
00:02:19.846 --> 00:02:22.760
experiments with such tightly
defined control groups.

46
00:02:22.760 --> 00:02:27.014
For example, let's say that the test
required some sort of mass advertising or

47
00:02:27.014 --> 00:02:27.719
promotion.

48
00:02:27.719 --> 00:02:32.294
It would be difficult if not impossible to
ensure that only a randomly selected set

49
00:02:32.294 --> 00:02:36.530
of people in a population saw a TV
commercial or heard a radio spot.

50
00:02:36.530 --> 00:02:39.140
In this case,
the best that we can do is try to find

51
00:02:39.140 --> 00:02:42.610
two different geographic markets
that are as similar as possible.

52
00:02:42.610 --> 00:02:45.550
Apply the treatment to one and
compare it to the other.

53
00:02:45.550 --> 00:02:47.539
Here's an illustration of
what this might look like.

54
00:02:49.080 --> 00:02:52.940
In this case, the groups are not quite
the same prior to the treatment, but

55
00:02:52.940 --> 00:02:55.400
they appear to be similar in performance.

56
00:02:55.400 --> 00:02:58.630
We can look at the relative differences
between the groups before and

57
00:02:58.630 --> 00:03:01.550
after the treatment,
to measure the effects of the treatment.

58
00:03:01.550 --> 00:03:04.170
This approach can work,
but it presents some risk.

59
00:03:04.170 --> 00:03:07.780
It's entirely possible that something else
may have happened during the experiment

60
00:03:07.780 --> 00:03:09.920
that impacted the two markets differently.

61
00:03:09.920 --> 00:03:12.760
Say for example, there was some
severe weather in one market, and

62
00:03:12.760 --> 00:03:14.390
fair weather in the other.

63
00:03:14.390 --> 00:03:18.670
In this case, our measurement might have
some unknown error which skews the result.

64
00:03:18.670 --> 00:03:22.780
Nonetheless, it's quite common to see this
approach applied in business experiments.

65
00:03:22.780 --> 00:03:26.420
In the worst case scenario there's no way
to establish a separate control group to

66
00:03:26.420 --> 00:03:28.270
compare against our treatment group.

67
00:03:28.270 --> 00:03:32.380
And the only option we have is to try and
compare the treatment group against itself

68
00:03:32.380 --> 00:03:35.230
before and
after the treatment was applied.

69
00:03:35.230 --> 00:03:38.800
This obviously requires us to make some
assumptions about what that single group

70
00:03:38.800 --> 00:03:41.750
would have done had
the treatment not been applied.

71
00:03:41.750 --> 00:03:44.080
Unlike the ideal in
market to market cases,

72
00:03:44.080 --> 00:03:46.100
we don't have a proxy
that helps us account for

73
00:03:46.100 --> 00:03:49.930
what else might have been going on in
the market as a whole at that time.

74
00:03:49.930 --> 00:03:53.380
It goes without saying that this
approach is the riskiest of the three.

75
00:03:53.380 --> 00:03:56.820
If anything other than the treatment
impacted the group during the experiment,

76
00:03:56.820 --> 00:03:58.890
we'd have no way of accounting for
it explicitly.

77
00:03:58.890 --> 00:04:02.365
Now the way we've introduced
experimentation here implies a purposeful

78
00:04:02.365 --> 00:04:05.760
planning and execution process for
the experiment itself.

79
00:04:05.760 --> 00:04:09.317
It turns out that's not the only kind of
experiment we might try to analyze as our

80
00:04:09.317 --> 00:04:10.600
role of data analysts.

81
00:04:10.600 --> 00:04:13.860
It can also be the case that we're trying
to gain some insights, by looking at

82
00:04:13.860 --> 00:04:18.020
things that have naturally occurred in
the past that have some aspect of a test.

83
00:04:18.020 --> 00:04:20.320
We call these natural experiments.

84
00:04:20.320 --> 00:04:23.665
One example might be looking at how
a specific store was impacted when

85
00:04:23.665 --> 00:04:26.300
a competitor opened up across the street.

86
00:04:26.300 --> 00:04:30.070
Another might be assessing whether a local
customer care activity was influenced by

87
00:04:30.070 --> 00:04:32.410
a severe weather event in one market.

88
00:04:32.410 --> 00:04:35.800
Natural experiments almost never
have well defined control groups.

89
00:04:35.800 --> 00:04:38.680
After all, we're looking at things that
just sort of happened versus those

90
00:04:38.680 --> 00:04:39.940
that were planned.

91
00:04:39.940 --> 00:04:44.210
As a consequence, we're usually forced
to use the less ideal group to group, or

92
00:04:44.210 --> 00:04:46.780
self comparison methods
we outlined earlier.

93
00:04:46.780 --> 00:04:50.444
Whether we're looking at planned or
natural experiments, as data analysts,

94
00:04:50.444 --> 00:04:52.530
the task of measurement
usually falls to us.

95
00:04:52.530 --> 00:04:56.287
Generally we're looking for differences
and we apply classical statistical methods

96
00:04:56.287 --> 00:04:59.273
to characterize whether those
differences are significant or not,

97
00:04:59.273 --> 00:05:02.617
based on the magnitude of the difference,
the variance in the measures, and

98
00:05:02.617 --> 00:05:04.902
the number of data points
we have in the experiment.

99
00:05:04.902 --> 00:05:07.398
Much of analysis is
pretty straight forward.

100
00:05:07.398 --> 00:05:10.823
However there are some common traps we
can fall into if we're not careful.

101
00:05:10.823 --> 00:05:13.737
Let's take just a minute and
talk about a couple of them.

102
00:05:13.737 --> 00:05:17.710
Usually our experiment involves
trying to get people to do something.

103
00:05:17.710 --> 00:05:18.300
For example,

104
00:05:18.300 --> 00:05:22.160
we may make an offer to a customer with
the hopes that they will take that offer.

105
00:05:22.160 --> 00:05:24.990
It's tempting to want to look at
only the results of the people who

106
00:05:24.990 --> 00:05:26.650
actually took the offer,

107
00:05:26.650 --> 00:05:31.640
a common mistake is to assess results by
comparing the takers to the control group.

108
00:05:31.640 --> 00:05:33.400
This is a big mistake.

109
00:05:33.400 --> 00:05:35.680
What about the people who
didn't take the offer?

110
00:05:35.680 --> 00:05:39.010
How do we know we didn't have an impact,
especially an adverse impact,

111
00:05:39.010 --> 00:05:40.350
on those customers?

112
00:05:40.350 --> 00:05:43.520
The rule here is to always compare
the whole treatment group to

113
00:05:43.520 --> 00:05:45.000
the control group.

114
00:05:45.000 --> 00:05:47.070
It's okay to break
the measures into those for

115
00:05:47.070 --> 00:05:51.130
takers and non-takers, but
the non-takers always need to be included.

116
00:05:51.130 --> 00:05:54.280
The other mistake we tend to make is
looking too narrowly at the impacts of

117
00:05:54.280 --> 00:05:55.660
the experiment.

118
00:05:55.660 --> 00:05:58.560
Let's circle back to our
customer cancellation example.

119
00:05:58.560 --> 00:06:01.040
Suppose wanted to keep customers
from canceling their service.

120
00:06:01.040 --> 00:06:05.140
It would seem to make sense to simply look
at the difference in cancellation rates

121
00:06:05.140 --> 00:06:06.060
between our treatment and

122
00:06:06.060 --> 00:06:09.390
control groups in assessing
the financial impact of the effort.

123
00:06:09.390 --> 00:06:11.950
However, there are a lot of
other things the customer might

124
00:06:11.950 --> 00:06:14.315
do in response to our communication.

125
00:06:14.315 --> 00:06:17.830
Did they change their calling plans
perhaps changing monthly revenue?

126
00:06:17.830 --> 00:06:19.190
Do we stimulate usage or

127
00:06:19.190 --> 00:06:23.010
additional calls to customer care,
perhaps changing the cost to serve.

128
00:06:23.010 --> 00:06:25.900
These other impacts can have
a dramatic impact on the overall

129
00:06:25.900 --> 00:06:28.740
success of the campaign and
should be included.

130
00:06:28.740 --> 00:06:32.360
The way to avoid this problem is to really
think about all the things that a customer

131
00:06:32.360 --> 00:06:35.080
might do in response to an experiment, and

132
00:06:35.080 --> 00:06:37.800
plan in advance to measure
them as part of the analysis.

133
00:06:39.440 --> 00:06:42.575
So that's a quick spin through
the high points of experimentation.

134
00:06:42.575 --> 00:06:46.515
Again this isn't meant to be a complete
course on the topic, but in line with our

135
00:06:46.515 --> 00:06:49.795
theme of real world analytics, we thought
it would be valuable to point out

136
00:06:49.795 --> 00:06:53.892
a few ways in which compromises to
theory emerge in the work that we do and

137
00:06:53.892 --> 00:06:57.162
to highlight a couple of common
pitfalls that we seek to avoid.

138
00:06:57.162 --> 00:06:59.962
Keep this in mind is you consider
how you can use experiments as

139
00:06:59.962 --> 00:07:02.002
actions in your analytic process.

140
00:07:02.002 --> 00:07:02.502
See you next time.