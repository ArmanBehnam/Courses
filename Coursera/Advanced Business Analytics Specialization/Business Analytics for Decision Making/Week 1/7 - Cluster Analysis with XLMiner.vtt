WEBVTT

1
00:00:00.340 --> 00:00:05.130
In the last video we show how the problem
of dividing a set of observations

2
00:00:05.130 --> 00:00:09.290
into clusters can be formulated
as an optimization model.

3
00:00:09.290 --> 00:00:13.143
Finding an optimum solution to
the problem is complicated and

4
00:00:13.143 --> 00:00:16.120
requires quite a bit of
computational effort.

5
00:00:16.120 --> 00:00:20.040
Think about this, in the example that
we introduced in the previous video,

6
00:00:20.040 --> 00:00:24.930
we had data on 300 customers
of an online retailer.

7
00:00:24.930 --> 00:00:28.340
The full optimization problem
would amount to searching for

8
00:00:28.340 --> 00:00:34.060
the best way of partitioning 300
objects into 3 none-empty subsets.

9
00:00:34.060 --> 00:00:36.640
The number of choices is astronomical.

10
00:00:36.640 --> 00:00:38.570
So, instead of solving that problem,

11
00:00:38.570 --> 00:00:42.940
we simplify it by reducing
the number of decisions to three.

12
00:00:42.940 --> 00:00:45.690
In this reviews model we
just needed to search for

13
00:00:45.690 --> 00:00:49.875
three customers that were used
as the centers of the clusters.

14
00:00:49.875 --> 00:00:52.990
Even with this simplification the number
of choices is over 4.4 million.

15
00:00:54.380 --> 00:00:58.400
This is quite large for a problem
with relatively few observations.

16
00:00:58.400 --> 00:01:02.700
The bottom line is that the optimization
approach has some severe limitations for

17
00:01:02.700 --> 00:01:04.550
large datasets.

18
00:01:04.550 --> 00:01:09.655
And this is why approximation methods
such as hierarchical clustering and

19
00:01:09.655 --> 00:01:14.300
K-means have become the most common
procedures for cluster analysis.

20
00:01:14.300 --> 00:01:17.220
XLMiner includes both of these methods.

21
00:01:17.220 --> 00:01:20.100
If you are working toward
the completion of this Introduction to

22
00:01:20.100 --> 00:01:22.390
Business Analytics Specialization,

23
00:01:22.390 --> 00:01:26.090
you have already used XLMiner
in the second course and

24
00:01:26.090 --> 00:01:30.570
you should be fairly familiar with
either the Windows or the cloud version.

25
00:01:30.570 --> 00:01:34.720
If for some reason you have not used
XLMiner then you should first watch

26
00:01:34.720 --> 00:01:39.000
the video Introduction to
the Analytic Solver Platform.

27
00:01:39.000 --> 00:01:43.732
In that video you will learn how to
access the cloud version of the ASP,

28
00:01:43.732 --> 00:01:46.990
that's the Analytic Solver Platform, or

29
00:01:46.990 --> 00:01:49.980
to download the Excel
version onto your computer.

30
00:01:49.980 --> 00:01:54.960
So comeback here when you're ready to
learn how to use XLMiner for clustering.

31
00:01:54.960 --> 00:02:00.100
Let's start by opening the Excel
file Market Segmentation- XLMiner.

32
00:02:00.100 --> 00:02:04.510
The file contains the same data
that we used in the previous video.

33
00:02:04.510 --> 00:02:09.125
Recall that the data consists of
demographic and purchasing metrics for

34
00:02:09.125 --> 00:02:11.670
300 clients for an online retailer.

35
00:02:11.670 --> 00:02:16.900
The retailer wants to use cluster analysis
to identify three market segments.

36
00:02:16.900 --> 00:02:22.410
Highlight the data table which
is in the range from A3 to E303,

37
00:02:22.410 --> 00:02:27.120
click on the XLMiner tab and
go to the Data Analysis group of tools.

38
00:02:27.120 --> 00:02:31.080
Click on Cluster and
then choose K-Means Clustering.

39
00:02:31.080 --> 00:02:36.929
The data range box should
show the range A3 to E303.

40
00:02:36.929 --> 00:02:41.950
The number of rows should be 300 and
the number of columns should be 5.

41
00:02:41.950 --> 00:02:47.300
Note that since we highlighted row three
which contains the names of the variables,

42
00:02:47.300 --> 00:02:51.070
the first row contains header
box should be checked.

43
00:02:51.070 --> 00:02:56.690
The variables in the input data box should
list all the variables in our dataset.

44
00:02:56.690 --> 00:03:00.030
Let's highlight all the variables
except customer and

45
00:03:00.030 --> 00:03:03.120
click on the arrow in
the middle of the window.

46
00:03:03.120 --> 00:03:08.190
This action transfers the variables
to the selected variables box.

47
00:03:08.190 --> 00:03:10.480
We now click on Next.

48
00:03:10.480 --> 00:03:15.090
XLMiner offers a few choices to
execute the K-mean algorithm.

49
00:03:15.090 --> 00:03:18.940
First we can select whether or
not to use normalized values.

50
00:03:18.940 --> 00:03:22.180
We have already discussed
the advantage of normalized values

51
00:03:22.180 --> 00:03:23.940
in order to interpret results.

52
00:03:23.940 --> 00:03:27.110
So we will check
the Normalize Input data box.

53
00:03:28.370 --> 00:03:31.260
Next we need to choose
the number of clusters.

54
00:03:31.260 --> 00:03:35.290
In this case, we want to find
a solution with 3 clusters.

55
00:03:35.290 --> 00:03:37.940
The number of iterations relates to

56
00:03:37.940 --> 00:03:42.400
the number of times that the procedure
is going to adjust this entrance.

57
00:03:42.400 --> 00:03:45.220
We will use the default value of 10.

58
00:03:45.220 --> 00:03:51.099
In the options area, XLMiner allows you
to restart the K-Means procedure multiple

59
00:03:51.099 --> 00:03:56.167
times, and we can also adjust the seed for
the random number generator.

60
00:03:56.167 --> 00:03:59.053
We will leave the default values,

61
00:03:59.053 --> 00:04:03.839
that is we will use a Fixed start and
a seed of 12345.

62
00:04:04.880 --> 00:04:08.710
Click on Next and
move to the Output Options.

63
00:04:08.710 --> 00:04:13.000
We will leave both boxes checked and
click on Finish.

64
00:04:13.000 --> 00:04:17.440
XLMiner creates two worksheets,
one named KMC_Output and

65
00:04:17.440 --> 00:04:20.130
another one named KMC_Clusters.

66
00:04:20.130 --> 00:04:22.800
Let us start by examining
the output worksheet.

67
00:04:22.800 --> 00:04:25.930
We scroll down to
the cluster center section.

68
00:04:25.930 --> 00:04:29.350
The original coordinates and
the normalized coordinate tables,

69
00:04:29.350 --> 00:04:34.430
show the centroids of the three clusters
that the K-means procedure found.

70
00:04:34.430 --> 00:04:37.090
To compare to what we found
in the previous video

71
00:04:37.090 --> 00:04:39.870
let's take a look at
the normalized centroids.

72
00:04:39.870 --> 00:04:44.760
We can see that the first cluster seems to
be the one that we previously identified

73
00:04:44.760 --> 00:04:50.570
as families, with normalized values around
0 except for the Number of Dependents.

74
00:04:50.570 --> 00:04:54.380
The second cluster is the one that
we identified as professionals.

75
00:04:54.380 --> 00:04:58.820
The group members have fairly high income,
they purchase frequently, and

76
00:04:58.820 --> 00:05:01.090
they spend more money than the average.

77
00:05:01.090 --> 00:05:05.460
The last cluster is the one that we
labeled as students, because the group

78
00:05:05.460 --> 00:05:10.240
is at least one standard should
below the average in all attributes.

79
00:05:10.240 --> 00:05:14.540
The results obtained by running
the K-Means method on XLMiner match

80
00:05:14.540 --> 00:05:18.480
what we generated by solving
the optimization model using Solver.

81
00:05:18.480 --> 00:05:23.338
The clusters are not exactly the same,
but they lead to the same conclusions.

82
00:05:23.338 --> 00:05:28.580
The KMC_Cluster worksheet contains
the assignment of customers to clusters,

83
00:05:28.580 --> 00:05:32.330
and the distances from
customers to each cluster.

84
00:05:32.330 --> 00:05:37.015
This information could be used to
compare the membership of each cluster

85
00:05:37.015 --> 00:05:41.852
between the solution that we found with
the Solver in the previous video and

86
00:05:41.852 --> 00:05:45.104
the solution that we just
found with the XLMiner.

87
00:05:45.104 --> 00:05:49.930
If we run the hierarchical clustering
tool, we obtain similar results.

88
00:05:49.930 --> 00:05:52.320
You might want to try this on your own.

89
00:05:52.320 --> 00:05:55.980
However, I must warn you that
the hierarchical clustering tool

90
00:05:55.980 --> 00:06:00.020
in the XLMiner does not report
the centroids of the clusters.

91
00:06:00.020 --> 00:06:03.060
They had to be calculated
from the cluster assignments.

92
00:06:03.060 --> 00:06:08.040
So comparing the K-Means solutions with
the hierarchical clustering solution

93
00:06:08.040 --> 00:06:10.150
requires a little bit of extra work.

94
00:06:11.330 --> 00:06:15.820
As you can see finding clusters using
the XLMiner is straight forward.

95
00:06:15.820 --> 00:06:20.657
However, before we go we need to address
the question of how many clusters to

96
00:06:20.657 --> 00:06:22.406
use in a cluster analysis.

97
00:06:22.406 --> 00:06:26.980
There is basically no theory about how
to find the right number of clusters.

98
00:06:26.980 --> 00:06:31.923
In fact in some settings it might not be
completely clear what the right number

99
00:06:31.923 --> 00:06:33.240
of cluster means.

100
00:06:33.240 --> 00:06:37.850
We know that the two streams are to
either put every observation

101
00:06:37.850 --> 00:06:43.080
in its own cluster or to put all
observations in a single cluster.

102
00:06:43.080 --> 00:06:46.340
The first option we have
no predictive power,

103
00:06:46.340 --> 00:06:50.800
because we will not have a cluster
where to put a new observation.

104
00:06:50.800 --> 00:06:53.690
The second option results
in a trivial amount

105
00:06:53.690 --> 00:06:57.510
that tells us nothing
about new observations.

106
00:06:57.510 --> 00:07:03.240
Most analysts would that agree with
applying parsimony to cluster analysis.

107
00:07:03.240 --> 00:07:07.660
Under this principle,
we choose the smallest number of clusters

108
00:07:07.660 --> 00:07:11.290
that generalize best to a new observation.

109
00:07:11.290 --> 00:07:15.340
There are a few ways in which
generalization could be measured.

110
00:07:15.340 --> 00:07:19.625
For instance, we could measure how
much the centroids will move if we

111
00:07:19.625 --> 00:07:23.900
re-run the clustering method
with the addition of new data.

112
00:07:23.900 --> 00:07:27.420
We could also measure how
much the cluster assignments

113
00:07:27.420 --> 00:07:29.860
would change in the presence of new data.

114
00:07:29.860 --> 00:07:34.790
Or, we could also check how much
the total sum of squares would

115
00:07:34.790 --> 00:07:37.860
change when assigning new
data to the existing cluster.

116
00:07:37.860 --> 00:07:41.580
In addition to these measures,
we can also use a procedure where

117
00:07:41.580 --> 00:07:46.230
we start with a small number of clusters
and then we add one cluster at a time.

118
00:07:46.230 --> 00:07:50.560
After each addition, we decide
whether the new clusters have a more

119
00:07:50.560 --> 00:07:55.200
meaningful interpretation than
the clusters in the previous iteration.

120
00:07:55.200 --> 00:07:58.740
Let's try this approach on
our online retailer example.

121
00:07:58.740 --> 00:08:02.130
At the moment we have
a solution with three clusters.

122
00:08:02.130 --> 00:08:05.386
We have interpreted three clusters and
determined that there

123
00:08:05.386 --> 00:08:10.890
are three identifiable markets, namely
families, professionals and students.

124
00:08:10.890 --> 00:08:15.445
If we use XLMiner to re-run K-means to
find a solution with four clusters,

125
00:08:15.445 --> 00:08:19.430
we find the normalized
centroids shown in this table.

126
00:08:19.430 --> 00:08:22.790
The first cluster is the one
corresponding to families,

127
00:08:22.790 --> 00:08:26.820
the second cluster corresponds to
what we labeled as professionals.

128
00:08:26.820 --> 00:08:31.340
So far nothing new has emerged compared
to our solution with three clusters.

129
00:08:31.340 --> 00:08:35.810
In fact, the centers for
clusters 1 and 2 in this solution

130
00:08:35.810 --> 00:08:41.400
are identical to the centers of cluster
1 and 2 in the solution with 3 clusters.

131
00:08:41.400 --> 00:08:43.290
Now we examine clusters 3 and

132
00:08:43.290 --> 00:08:47.440
4 and we observe that they
are nearly identical to each other.

133
00:08:47.440 --> 00:08:51.720
We compare the data summary tables for
the solution with three clusters and

134
00:08:51.720 --> 00:08:53.640
the solution with four clusters.

135
00:08:53.640 --> 00:08:56.400
We can now clearly see what has happened.

136
00:08:56.400 --> 00:08:59.020
Because we want a solution
with four clusters,

137
00:08:59.020 --> 00:09:03.240
we forced the third cluster in the
solution with three clusters to be split.

138
00:09:03.240 --> 00:09:07.140
The 100 observations in this
cluster were split into 49 and

139
00:09:07.140 --> 00:09:12.350
51 when we asked K-means to produce
a solution with four cluster.

140
00:09:12.350 --> 00:09:15.850
For this analysis it
seems clear that the data

141
00:09:15.850 --> 00:09:20.800
do not support the hypothesis of
the existence of a fourth market.

142
00:09:20.800 --> 00:09:24.360
The right number of clusters in
this case seems to be three.

143
00:09:24.360 --> 00:09:28.920
The goal of this module was to provide
you with that good understanding of what

144
00:09:28.920 --> 00:09:33.710
cluster analysis is,
how this analysis is used in business and

145
00:09:33.710 --> 00:09:36.110
how the analysis is performed.

146
00:09:36.110 --> 00:09:40.260
You're now ready to apply this knowledge
and the tools that we have discussed.

147
00:09:40.260 --> 00:09:44.645
The assignment at the end of this module
is a good as starting point to put cluster

148
00:09:44.645 --> 00:09:45.963
analysis into action.