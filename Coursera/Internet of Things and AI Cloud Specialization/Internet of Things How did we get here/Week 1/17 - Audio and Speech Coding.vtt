WEBVTT

1
00:00:04.770 --> 00:00:11.215
What's the big deal about
going into the digital domain?

2
00:00:11.215 --> 00:00:16.900
Of course you could compress the data,
in order to make better,

3
00:00:16.900 --> 00:00:22.660
more efficient use of the data plane,
but that requires for

4
00:00:22.660 --> 00:00:28.890
us to develop a deep understanding of
the signals that we are dealing with.

5
00:00:28.890 --> 00:00:33.630
Harvey Fletcher was another
brilliant scientist at Bell Labs and

6
00:00:33.630 --> 00:00:40.190
in the 1930s he contributed to
the theory of articulation index.

7
00:00:40.190 --> 00:00:45.110
It's a measure of how
intelligible the speech is so

8
00:00:45.110 --> 00:00:51.140
that they could have automated
tests on measuring how clear

9
00:00:51.140 --> 00:00:57.730
the speech was when they were transmitting
over local lines and long distance lines.

10
00:00:57.730 --> 00:01:03.600
And later on this technology found
many users in hearing aids and

11
00:01:03.600 --> 00:01:08.400
other fields, but
AT&T is credited with having

12
00:01:08.400 --> 00:01:13.390
one of the best sound qualities
in the public telephone systems.

13
00:01:14.440 --> 00:01:21.106
He also did painstaking lab
work using cadavers and

14
00:01:21.106 --> 00:01:29.330
pigs to find out what sounds we
actually hear at what loudness.

15
00:01:30.560 --> 00:01:36.230
It turns out that we are very
nicely tuned to some frequencies,

16
00:01:36.230 --> 00:01:38.510
but not some other frequencies.

17
00:01:38.510 --> 00:01:42.490
So what you're seeing here in
this particular graph are called

18
00:01:43.740 --> 00:01:46.230
equal loudness curves.

19
00:01:46.230 --> 00:01:50.690
Each of the lines there
you would have to have,

20
00:01:50.690 --> 00:01:55.810
if you look at the signals around 4 kHz,
they're very very,

21
00:01:55.810 --> 00:01:59.490
the ear, the cochlea is very,
very sensitive to those sounds.

22
00:01:59.490 --> 00:02:03.620
They need to be very,
very faint before you pick it up.

23
00:02:03.620 --> 00:02:08.190
But the signal at one kHz or

24
00:02:08.190 --> 00:02:12.650
100 hertz to create the same
loudness sensation,

25
00:02:12.650 --> 00:02:16.420
it has to be much bigger than this.

26
00:02:16.420 --> 00:02:20.340
In this particular example,
it's almost 40 dB

27
00:02:22.900 --> 00:02:28.690
higher before you can perceive
them as the same loudness.

28
00:02:28.690 --> 00:02:35.250
And this, of course, varies depending on
the intensity of the sound dem cells.

29
00:02:35.250 --> 00:02:41.150
So this was a real insight and
very useful lab

30
00:02:41.150 --> 00:02:46.210
data for a whole bunch of
technologies that came later on.

31
00:02:47.240 --> 00:02:55.330
The next thing that he did was he
gave the concept of critical bands.

32
00:02:55.330 --> 00:02:58.150
The ear, inside the ear you have

33
00:03:00.270 --> 00:03:05.500
the cochlea which works
as a spectrum analyzer,

34
00:03:05.500 --> 00:03:09.696
the signals that are sensed
by the tympanum,

35
00:03:09.696 --> 00:03:13.180
and it does not have equal bandwidths.

36
00:03:13.180 --> 00:03:18.060
But the signals in
the 100-1000 hertz range,

37
00:03:18.060 --> 00:03:20.110
they have about 100 hertz bandwidth.

38
00:03:20.110 --> 00:03:23.460
And as you can see in this graph,

39
00:03:23.460 --> 00:03:28.925
once you go above one
kilohertz they have bandwidths

40
00:03:28.925 --> 00:03:33.520
increasing at the logarithmic skip, and so

41
00:03:33.520 --> 00:03:40.599
the spectral processing of the cochlear
is on a logarithmic scale,

42
00:03:40.599 --> 00:03:48.710
and what this leads to is something
called the masking effect in our hearing.

43
00:03:48.710 --> 00:03:53.430
The masking effect here is,
if you have a tone at 250 hertz

44
00:03:54.430 --> 00:03:59.970
in this picture,
it essentially makes the tone at 150 hertz

45
00:03:59.970 --> 00:04:05.080
completely inaudible because they're
in the two neighboring critical bands.

46
00:04:05.080 --> 00:04:08.840
The guy at 250 hertz completely masters.

47
00:04:08.840 --> 00:04:14.280
So what this means is if
you're trying to send the data

48
00:04:14.280 --> 00:04:16.900
over the telephone network or

49
00:04:16.900 --> 00:04:22.670
saving this in an iPod, for
instance, to be played back later,

50
00:04:22.670 --> 00:04:27.230
you don't need to represent the 150
hertz signal in this example.

51
00:04:28.630 --> 00:04:31.130
This is called simultaneous masking.

52
00:04:31.130 --> 00:04:38.380
That is, these two tones are present at
the same time in two different bands.

53
00:04:38.380 --> 00:04:41.850
This also happens across time domain.

54
00:04:41.850 --> 00:04:46.140
It's called pre-masking and post-masking.

55
00:04:46.140 --> 00:04:49.980
For example, when you hear a loud drum or
an explosion or

56
00:04:49.980 --> 00:04:54.710
cymbals, the ear goes deaf for a few

57
00:04:54.710 --> 00:05:00.410
tenths of milliseconds before
you can get your sensation back.

58
00:05:00.410 --> 00:05:06.290
And any data that is presenting this
signal at that particular time, even if

59
00:05:06.290 --> 00:05:12.440
you don't represent it in your coding, the
people on the other side would not hear.

60
00:05:12.440 --> 00:05:16.530
This is called transparent coding and

61
00:05:16.530 --> 00:05:21.690
this whole technology is
called perceptual coders, and

62
00:05:21.690 --> 00:05:27.539
this work was done in the labs and
flown off to other labs around the world.

63
00:05:29.370 --> 00:05:34.990
This is the perceptual audio
coder which is used in MP3, AAZ,

64
00:05:34.990 --> 00:05:42.120
your iPods and content, the audio
track of Netflix, so on and so forth.

65
00:05:44.120 --> 00:05:45.310
Busy graph, again,

66
00:05:45.310 --> 00:05:51.440
I just want you to focus on the block
with a red circle around it.

67
00:05:51.440 --> 00:05:54.469
This is the perceptual model.

68
00:05:54.469 --> 00:06:00.830
Based on Fletcher's and
Munson's work in audio coding,

69
00:06:00.830 --> 00:06:06.390
you would have a separate processor that
would, for each 20 millisecond audio or

70
00:06:06.390 --> 00:06:11.550
40 millisecond audio, you would actually
compute what parts you would actually

71
00:06:11.550 --> 00:06:15.650
hear and what you would not hear and
doesn't code.

72
00:06:15.650 --> 00:06:22.450
So this gives them a saving of one
to eight, one to 12 in the bit rate,

73
00:06:22.450 --> 00:06:28.480
and you still would not hear any
difference between the CD music and

74
00:06:28.480 --> 00:06:33.185
what you would hear from
the same content on your iPod.

75
00:06:33.185 --> 00:06:39.280
AT&T was also looking
at speech signals for

76
00:06:39.280 --> 00:06:44.090
compressing speech signals it is
not based on speech perception, but

77
00:06:44.090 --> 00:06:47.730
it is more based on speech production.

78
00:06:47.730 --> 00:06:51.035
And, the speech production
model was used by

79
00:06:51.035 --> 00:06:56.200
AT&T engineer

80
00:06:56.200 --> 00:07:00.690
Bishnu Atal to develop
linear predictive coding.

81
00:07:00.690 --> 00:07:07.280
Again, using this technique,
the analog tel quality can be

82
00:07:08.360 --> 00:07:12.826
obtained at one to two bits per sample,

83
00:07:12.826 --> 00:07:17.270
and using data compression.

84
00:07:17.270 --> 00:07:24.350
So, as you can see, the sampling theorem
led to a lot of further innovations in

85
00:07:24.350 --> 00:07:29.650
our understanding of how we
perceive speech and music,

86
00:07:29.650 --> 00:07:35.370
how we produce speech,
and also how we interpret,

87
00:07:35.370 --> 00:07:41.715
or perceive, visual data and images.