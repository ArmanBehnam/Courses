WEBVTT

1
00:00:00.400 --> 00:00:01.695
Good to see you again.

2
00:00:01.695 --> 00:00:04.860
In this video, you're going to
learn about cosine similarity,

3
00:00:04.860 --> 00:00:07.660
which is another type
of similarity function.

4
00:00:07.660 --> 00:00:11.700
It's basically makes use of the cosine
of the angle between two vectors.

5
00:00:11.700 --> 00:00:16.390
And based off that, it tells you
whether two vectors are close or not.

6
00:00:16.390 --> 00:00:20.100
In this section, you will see
the problem of using euclidean distance,

7
00:00:20.100 --> 00:00:24.460
especially when comparing vector
representations of documents or corpora,

8
00:00:24.460 --> 00:00:29.125
and how the cosine similarity metric
could help you overcome that problem.

9
00:00:29.125 --> 00:00:32.545
To illustrate how the euclidean
distance might be problematic,

10
00:00:32.545 --> 00:00:34.305
let's take the following example.

11
00:00:34.305 --> 00:00:38.355
Suppose that you are in a vector space
where the corpora are represented by

12
00:00:38.355 --> 00:00:41.845
the occurrence of the words disease and
eggs.

13
00:00:41.845 --> 00:00:44.865
Here is the representation
of a Food corpus and

14
00:00:44.865 --> 00:00:48.970
Agriculture corpus and the History corpus.

15
00:00:48.970 --> 00:00:52.600
Each one of these corpora have
text related to that subject.

16
00:00:52.600 --> 00:00:56.940
But you know that the word totals in
the corpora differ from one another.

17
00:00:56.940 --> 00:01:02.560
In fact, the agriculture and the history
corpus have a similar number of words,

18
00:01:02.560 --> 00:01:06.490
while the Food corpus has
a relatively small number.

19
00:01:06.490 --> 00:01:09.830
Let's define the euclidean
distance between the food and

20
00:01:09.830 --> 00:01:11.500
the Agriculture corpus as d1.

21
00:01:11.500 --> 00:01:18.570
And let the euclidean distance between the
agriculture and the History corpus be d2.

22
00:01:18.570 --> 00:01:21.680
As you can see, the distance d2
is smaller than the distance d1,

23
00:01:21.680 --> 00:01:25.140
which would suggest that
the agriculture and

24
00:01:25.140 --> 00:01:30.100
history corpora are more similar than
the agriculture and food corpora.

25
00:01:30.100 --> 00:01:33.950
Another common method for
determining the similarity between vectors

26
00:01:33.950 --> 00:01:37.430
is computing the cosine
of their inner angle.

27
00:01:37.430 --> 00:01:40.730
If the angle is small,
the cosine would be close to one.

28
00:01:40.730 --> 00:01:45.620
And as the angle approaches 90 degrees,
the cosine approaches zero.

29
00:01:45.620 --> 00:01:49.440
As you can see here,
the angle alpha between food and

30
00:01:49.440 --> 00:01:55.460
agriculture is smaller than the angle
beta between agriculture and history.

31
00:01:55.460 --> 00:01:57.130
In this particular case,

32
00:01:57.130 --> 00:02:01.620
the cosine of those angles is a better
proxy of similarity between these

33
00:02:01.620 --> 00:02:04.660
vector representations than
their euclidean distance.

34
00:02:06.050 --> 00:02:09.330
Now, you're familiar with
the main intuition behind the use

35
00:02:09.330 --> 00:02:14.128
of the cosine similarity as a metric to
compare the similarity between two vector

36
00:02:14.128 --> 00:02:15.450
representations.

37
00:02:15.450 --> 00:02:19.870
Remember that the main advantage of
this metric over the euclidean distance

38
00:02:19.870 --> 00:02:24.610
is that it isn't biased by the size
difference between the representations.

39
00:02:24.610 --> 00:02:27.560
Soon, you'll get the chance to
actually calculate this metric.