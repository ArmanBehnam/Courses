WEBVTT

1
00:00:00.270 --> 00:00:01.140
Good to see you again.

2
00:00:02.530 --> 00:00:06.610
One key operation needed to find
a matching word in the previous video

3
00:00:06.610 --> 00:00:08.800
was finding the K-nearest
neighbors of a vector.

4
00:00:09.870 --> 00:00:13.030
We will focus on this operation
in the next few videos

5
00:00:13.030 --> 00:00:16.570
as it's a basic building block for
many NLP techniques.

6
00:00:16.570 --> 00:00:21.670
>> Notice that it transformed word vector
after the transformation of its embedding

7
00:00:21.670 --> 00:00:26.220
through an R matrix would be in
the French word vector space.

8
00:00:26.220 --> 00:00:29.650
But it is not going to be
necessarily identical to

9
00:00:29.650 --> 00:00:33.390
any of the word vectors in
the French word vector space.

10
00:00:33.390 --> 00:00:38.440
You need to search through the actual
French word vectors to find a French word

11
00:00:38.440 --> 00:00:42.120
that is similar to the one that you
created from the transformation.

12
00:00:42.120 --> 00:00:44.807
You may find words such as salut or

13
00:00:44.807 --> 00:00:49.710
bonjour, which you can return as
the French translation of the word hello.

14
00:00:49.710 --> 00:00:54.150
So the question is,
how do you find similar word vectors?

15
00:00:54.150 --> 00:00:59.380
To understand how to find similar word
vectors, let's look at a related question.

16
00:00:59.380 --> 00:01:02.570
How do you find your friends
who are living nearby?

17
00:01:02.570 --> 00:01:07.520
Let's pretend that you are visiting
San Francisco in the United States and

18
00:01:07.520 --> 00:01:10.200
you're visiting your dear friend Andrew.

19
00:01:10.200 --> 00:01:13.420
You also want to visit your
other friends over the weekend,

20
00:01:13.420 --> 00:01:15.810
preferably those who live nearby.

21
00:01:15.810 --> 00:01:19.520
One way to do this is to go
through your address book and for

22
00:01:19.520 --> 00:01:25.230
each friend get their address, calculate
how far they are from San Francisco.

23
00:01:25.230 --> 00:01:29.885
So one friend is in Shanghai,
the other friend is in Bangalore, and

24
00:01:29.885 --> 00:01:32.160
another friend is in Los Angeles.

25
00:01:32.160 --> 00:01:35.630
You can sort your friends by
their distances to San Francisco,

26
00:01:35.630 --> 00:01:38.240
then rank them by how close they are.

27
00:01:38.240 --> 00:01:40.620
Notice that if you have a lot of friends,

28
00:01:40.620 --> 00:01:45.210
which I'm sure you do,
this is a very time intensive process.

29
00:01:45.210 --> 00:01:47.870
Is there a more efficient way to do this?

30
00:01:47.870 --> 00:01:51.480
Notice that two of these friends
live in another continent,

31
00:01:51.480 --> 00:01:54.160
while the third friend
lives in the United States.

32
00:01:54.160 --> 00:01:59.950
Could you have just searched for a subset
of friends who live in the United States?

33
00:01:59.950 --> 00:02:03.920
You might have realized that it may not
have been necessary to go through all of

34
00:02:03.920 --> 00:02:08.800
your friends in your address in order
to find the ones closest to you.

35
00:02:08.800 --> 00:02:13.040
You might have imagined if you somehow
could filter on which friends were all

36
00:02:13.040 --> 00:02:14.670
in a general region,

37
00:02:14.670 --> 00:02:19.460
such as North America, then you could just
search within that sub group of friends.

38
00:02:19.460 --> 00:02:24.260
If there is a way to slice up
the geographic space into regions,

39
00:02:24.260 --> 00:02:27.020
you could search just
within those regions.

40
00:02:27.020 --> 00:02:31.430
When you think about organizing
subsets of a dataset efficiently,

41
00:02:31.430 --> 00:02:35.620
you may think about placing
your data into buckets.

42
00:02:35.620 --> 00:02:37.430
If you think about buckets,

43
00:02:37.430 --> 00:02:40.710
then you'll definitely want
to think about hash tables.

44
00:02:40.710 --> 00:02:45.710
Hash tables are useful tools for
any kind of work involving data, and

45
00:02:45.710 --> 00:02:48.390
you'll learn about hash tables next.

46
00:02:48.390 --> 00:02:49.220
In this video,

47
00:02:49.220 --> 00:02:54.020
I showed you how using K-nearest neighbors
you could translate a word even if it's

48
00:02:54.020 --> 00:02:58.408
transformation doesn't exactly match the
word embedding in the desired language.

49
00:02:58.408 --> 00:03:01.410
And I introudced you to hash tables,

50
00:03:01.410 --> 00:03:05.160
a useful data structure that you
will learn about in the next video.