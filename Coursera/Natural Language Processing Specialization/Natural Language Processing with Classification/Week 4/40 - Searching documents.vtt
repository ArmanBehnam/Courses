WEBVTT

1
00:00:00.000 --> 00:00:02.340
I will finish this
week by showing you

2
00:00:02.340 --> 00:00:04.815
how you can use fast
k-nearest neighbor

3
00:00:04.815 --> 00:00:07.170
to search for pieces
of text related to

4
00:00:07.170 --> 00:00:09.930
a query in a large
collection of documents.

5
00:00:09.930 --> 00:00:11.670
You simply create vectors for

6
00:00:11.670 --> 00:00:14.250
both and find the
nearest neighbors.

7
00:00:14.250 --> 00:00:18.000
To get ready to perform
document search, first,

8
00:00:18.000 --> 00:00:20.340
think about how to
represent documents as

9
00:00:20.340 --> 00:00:23.805
vectors instead of
just words as vectors.

10
00:00:23.805 --> 00:00:25.830
Let's say you have this documents

11
00:00:25.830 --> 00:00:27.255
composed of three words.

12
00:00:27.255 --> 00:00:29.840
I love learning. How can you

13
00:00:29.840 --> 00:00:32.855
represent this entire
documents as a vector?

14
00:00:32.855 --> 00:00:34.640
Well, you can find

15
00:00:34.640 --> 00:00:37.250
the word vectors for
each individual word.

16
00:00:37.250 --> 00:00:41.070
I love learning.

17
00:00:41.070 --> 00:00:43.040
Then just add them together,

18
00:00:43.040 --> 00:00:45.020
so the sum of all
these words vectors

19
00:00:45.020 --> 00:00:47.000
becomes a documents vector,

20
00:00:47.000 --> 00:00:49.610
where the same dimension
as the word vectors,

21
00:00:49.610 --> 00:00:52.415
in this case, three-dimensions.

22
00:00:52.415 --> 00:00:55.430
You can then apply
document search by using

23
00:00:55.430 --> 00:00:59.795
k-nearest neighbors.
Let's go this up.

24
00:00:59.795 --> 00:01:03.214
Create a mini dictionary
for word embeddings.

25
00:01:03.214 --> 00:01:06.350
Here's the list of what's
contained in the document.

26
00:01:06.350 --> 00:01:08.510
You're going to
initialize the documents

27
00:01:08.510 --> 00:01:11.105
embedding as an array of zeros.

28
00:01:11.105 --> 00:01:13.430
Now for each word in a document,

29
00:01:13.430 --> 00:01:15.890
you'll get the word
vector if the word exists

30
00:01:15.890 --> 00:01:18.600
in the dictionary else zero.

31
00:01:18.600 --> 00:01:22.715
You add these all up and return
the documents embedding.

32
00:01:22.715 --> 00:01:24.705
Please try it out.

33
00:01:24.705 --> 00:01:27.440
You learned in this
video an example of

34
00:01:27.440 --> 00:01:29.690
a very general method that text

35
00:01:29.690 --> 00:01:31.775
can be embedded into
vector space so that

36
00:01:31.775 --> 00:01:34.760
nearest neighbors refer to
text with similar meaning.

37
00:01:34.760 --> 00:01:38.330
Well, you will learn more
advanced ways to embed text.

38
00:01:38.330 --> 00:01:40.940
This basic structure
will reappear again and

39
00:01:40.940 --> 00:01:44.370
again as it's used
throughout modern NLP.