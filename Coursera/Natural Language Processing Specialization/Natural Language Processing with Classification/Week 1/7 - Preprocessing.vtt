WEBVTT

1
00:00:00.000 --> 00:00:02.190
Hello, you will now learn about

2
00:00:02.190 --> 00:00:04.440
two major concepts
of preprocessing.

3
00:00:04.440 --> 00:00:07.230
The first thing you'll learn
about is called stemming and

4
00:00:07.230 --> 00:00:08.250
the second thing you will learn

5
00:00:08.250 --> 00:00:09.960
about is called stop words,

6
00:00:09.960 --> 00:00:12.090
and specifically you
will learn how to use

7
00:00:12.090 --> 00:00:15.360
stemming and stop words
to preprocess your texts.

8
00:00:15.360 --> 00:00:17.805
Let's take a look at
how you can do this.

9
00:00:17.805 --> 00:00:19.755
Let's process this tweet.

10
00:00:19.755 --> 00:00:21.900
First, I remove
all the words that

11
00:00:21.900 --> 00:00:24.330
don't add significant
meaning to the tweets,

12
00:00:24.330 --> 00:00:27.925
aka stop words and
punctuation marks.

13
00:00:27.925 --> 00:00:29.810
In practice, you would have to

14
00:00:29.810 --> 00:00:31.925
compare your tweet
against two lists.

15
00:00:31.925 --> 00:00:33.260
One with stop words in

16
00:00:33.260 --> 00:00:35.930
English and another
with punctuation.

17
00:00:35.930 --> 00:00:38.285
These lists are
usually much larger,

18
00:00:38.285 --> 00:00:40.100
but for the purpose
of this example,

19
00:00:40.100 --> 00:00:41.495
they will do just fine.

20
00:00:41.495 --> 00:00:43.970
Every word from the tweet
that also appears on

21
00:00:43.970 --> 00:00:46.760
the list of stop words
should be eliminated.

22
00:00:46.760 --> 00:00:49.685
So you'd have to
eliminate the word and,

23
00:00:49.685 --> 00:00:53.425
the word are, the word a,

24
00:00:53.425 --> 00:00:55.290
and the word at.

25
00:00:55.290 --> 00:00:58.230
The tweet without stop
words looks like this.

26
00:00:58.230 --> 00:01:00.740
Note that the overall meaning of

27
00:01:00.740 --> 00:01:03.985
the sentence could be
inferred without any effort.

28
00:01:03.985 --> 00:01:07.050
Now, let's eliminate
every punctuation mark.

29
00:01:07.050 --> 00:01:10.235
In this example, there are
only exclamation points.

30
00:01:10.235 --> 00:01:11.885
The tweet without stop words

31
00:01:11.885 --> 00:01:13.970
and punctuation looks like this.

32
00:01:13.970 --> 00:01:15.950
However, note that in

33
00:01:15.950 --> 00:01:18.935
some contexts you won't have
to eliminate punctuation.

34
00:01:18.935 --> 00:01:20.825
So you should think carefully

35
00:01:20.825 --> 00:01:22.340
about whether punctuation adds

36
00:01:22.340 --> 00:01:26.425
important information to your
specific NLP task or not.

37
00:01:26.425 --> 00:01:28.580
Tweets and other types of texts

38
00:01:28.580 --> 00:01:30.710
often have handles and URLs,

39
00:01:30.710 --> 00:01:32.540
but these don't add any value for

40
00:01:32.540 --> 00:01:34.519
the task of sentiment analysis.

41
00:01:34.519 --> 00:01:38.205
Let's eliminate these two
handles and this URL.

42
00:01:38.205 --> 00:01:39.830
At the end of this process,

43
00:01:39.830 --> 00:01:41.255
the resulting tweets contains

44
00:01:41.255 --> 00:01:45.280
all the important information
related to its sentiment.

45
00:01:45.280 --> 00:01:48.815
Tuning GREAT AI model is clearly

46
00:01:48.815 --> 00:01:50.570
a positive tweet and

47
00:01:50.570 --> 00:01:53.780
a sufficiently good model
should be able to classify it.

48
00:01:53.780 --> 00:01:55.940
Now that the tweet
from the example

49
00:01:55.940 --> 00:01:58.265
has only the necessary
information,

50
00:01:58.265 --> 00:02:01.165
I will perform stemming
for every word.

51
00:02:01.165 --> 00:02:03.590
Stemming in NLP is simply

52
00:02:03.590 --> 00:02:06.395
transforming any word
to its base stem,

53
00:02:06.395 --> 00:02:09.230
which you could define as the
set of characters that are

54
00:02:09.230 --> 00:02:12.200
used to construct the
word and its derivatives.

55
00:02:12.200 --> 00:02:15.220
Let's take the first
word from the example.

56
00:02:15.220 --> 00:02:17.205
Its stem is done,

57
00:02:17.205 --> 00:02:19.300
because adding the letter e,

58
00:02:19.300 --> 00:02:21.395
it forms the word tune.

59
00:02:21.395 --> 00:02:23.450
Adding the suffix ed,

60
00:02:23.450 --> 00:02:25.700
forms the word tuned,

61
00:02:25.700 --> 00:02:27.950
and adding the suffix ing,

62
00:02:27.950 --> 00:02:30.185
it forms the word tuning.

63
00:02:30.185 --> 00:02:32.840
After you perform
stemming on your corpus,

64
00:02:32.840 --> 00:02:35.210
the word tune, tuned,

65
00:02:35.210 --> 00:02:38.780
and tuning will be
reduced to the stem tun.

66
00:02:38.780 --> 00:02:41.360
So your vocabulary would
be significantly reduced

67
00:02:41.360 --> 00:02:42.620
when you perform this process

68
00:02:42.620 --> 00:02:44.570
for every word in the corpus.

69
00:02:44.570 --> 00:02:46.730
To reduce your vocabulary even

70
00:02:46.730 --> 00:02:49.730
further without losing
valuable information,

71
00:02:49.730 --> 00:02:52.955
you'd have to lowercase
every one of your words.

72
00:02:52.955 --> 00:02:54.750
So the word GREAT,

73
00:02:54.750 --> 00:03:00.035
Great and great would be
treated as the same exact word.

74
00:03:00.035 --> 00:03:05.880
This is the final preprocess
tweet as a list of words.

75
00:03:06.440 --> 00:03:10.190
Now that you're familiar with
stemming and stop words,

76
00:03:10.190 --> 00:03:12.635
you know the basics
of texts processing.

77
00:03:12.635 --> 00:03:13.970
In the next video,

78
00:03:13.970 --> 00:03:16.145
you can use your
process suite function

79
00:03:16.145 --> 00:03:18.290
to extract a matrix x,

80
00:03:18.290 --> 00:03:22.230
which represents all the
tweets in your data set.