WEBVTT

1
00:00:00.000 --> 00:00:01.980
In this video, I will teach you

2
00:00:01.980 --> 00:00:04.635
the exact math behind LSTMs.

3
00:00:04.635 --> 00:00:06.000
It's a bit complex,

4
00:00:06.000 --> 00:00:08.260
so don't worry if it seems
a little overwhelming

5
00:00:08.260 --> 00:00:11.115
in the beginning. Let's dive in.

6
00:00:11.115 --> 00:00:13.560
As you might recall from earlier,

7
00:00:13.560 --> 00:00:15.780
a typical LSTM consists

8
00:00:15.780 --> 00:00:17.970
of a cell state and
a hidden state,

9
00:00:17.970 --> 00:00:20.130
which holds the
outputs from the cell.

10
00:00:20.130 --> 00:00:23.055
You can think of the cell as
the memory of your network

11
00:00:23.055 --> 00:00:26.685
carrying all the relevant
information down the sequence.

12
00:00:26.685 --> 00:00:28.709
As the cell travels,

13
00:00:28.709 --> 00:00:30.420
each gate adds or

14
00:00:30.420 --> 00:00:32.820
removes information
from the cell state.

15
00:00:32.820 --> 00:00:36.090
The gates make up the
hidden states of your LSTM.

16
00:00:36.090 --> 00:00:38.205
They contain activation functions

17
00:00:38.205 --> 00:00:40.255
and element-wise operations.

18
00:00:40.255 --> 00:00:44.045
LSTMs typically have three
gates: the forget gate,

19
00:00:44.045 --> 00:00:46.400
the input gate, and
the output gate.

20
00:00:46.400 --> 00:00:49.745
Let's discuss how each
one works in detail.

21
00:00:49.745 --> 00:00:52.220
The first gate is
the forget gate,

22
00:00:52.220 --> 00:00:53.570
which as you may have guessed,

23
00:00:53.570 --> 00:00:55.580
decides which information from

24
00:00:55.580 --> 00:00:56.870
the previous cell state and

25
00:00:56.870 --> 00:00:59.950
current input should
be kept or tossed out.

26
00:00:59.950 --> 00:01:02.280
It does this with a
sigmoid function,

27
00:01:02.280 --> 00:01:04.320
which squeezes each value

28
00:01:04.320 --> 00:01:06.705
from the cell states
between zero and one.

29
00:01:06.705 --> 00:01:08.960
In this case, a value closer to

30
00:01:08.960 --> 00:01:11.960
zero indicates it
should be thrown away,

31
00:01:11.960 --> 00:01:16.115
and a value closer to one
indicates it should be kept.

32
00:01:16.115 --> 00:01:17.720
Now that you have the values

33
00:01:17.720 --> 00:01:20.405
indicating what to keep
and what to throw out,

34
00:01:20.405 --> 00:01:22.660
you need to update
the cell states.

35
00:01:22.660 --> 00:01:25.070
This is where the
input gate comes in.

36
00:01:25.070 --> 00:01:27.845
The input gate is
actually two layers,

37
00:01:27.845 --> 00:01:31.150
a sigmoid layer and a tanh layer.

38
00:01:31.150 --> 00:01:34.045
The sigmoid takes the
previous hidden states

39
00:01:34.045 --> 00:01:35.480
and current inputs and

40
00:01:35.480 --> 00:01:37.325
chooses which values to update

41
00:01:37.325 --> 00:01:40.430
by assigning zero or
one to each value.

42
00:01:40.430 --> 00:01:43.535
The closer to one, the
higher its importance.

43
00:01:43.535 --> 00:01:46.730
The tanh layer also takes
the hidden states and

44
00:01:46.730 --> 00:01:48.350
current inputs and squeezes

45
00:01:48.350 --> 00:01:50.990
the values between
negative one and one.

46
00:01:50.990 --> 00:01:52.985
This helps to regulate

47
00:01:52.985 --> 00:01:56.135
the flow of information
in your network.

48
00:01:56.135 --> 00:01:58.400
Then the outputs of

49
00:01:58.400 --> 00:02:01.190
this sigmoid and tanh
layers are multiplied.

50
00:02:01.190 --> 00:02:03.200
Now your model has
what it needs to

51
00:02:03.200 --> 00:02:05.350
calculate a new cell state.

52
00:02:05.350 --> 00:02:08.735
Now, you can recalculate the
values in the cell states.

53
00:02:08.735 --> 00:02:10.520
For this step, take the values

54
00:02:10.520 --> 00:02:12.740
provided by the forget gate and

55
00:02:12.740 --> 00:02:14.540
multiply them element-wise by

56
00:02:14.540 --> 00:02:16.580
the values in the cell state.

57
00:02:16.580 --> 00:02:17.990
Then take that result and do

58
00:02:17.990 --> 00:02:19.910
an element-wise addition with

59
00:02:19.910 --> 00:02:22.265
the values provided
by the input gate.

60
00:02:22.265 --> 00:02:25.510
That's it. You've updated
your cell states.

61
00:02:25.510 --> 00:02:28.200
Onward to the third
and final gate.

62
00:02:28.200 --> 00:02:30.380
Now that you've updated
your cell states,

63
00:02:30.380 --> 00:02:31.850
the output gate will decide

64
00:02:31.850 --> 00:02:34.010
what your next hidden
state should be.

65
00:02:34.010 --> 00:02:37.245
Remember that your cell
state acts as the memory,

66
00:02:37.245 --> 00:02:40.054
and the hidden state is
what makes predictions.

67
00:02:40.054 --> 00:02:42.185
To arrive at a new hidden state,

68
00:02:42.185 --> 00:02:45.170
the output gate takes the
previous hidden state and

69
00:02:45.170 --> 00:02:46.970
the current input and

70
00:02:46.970 --> 00:02:49.025
passes them through
a sigmoid layer.

71
00:02:49.025 --> 00:02:51.605
Then your freshly
updated cell state

72
00:02:51.605 --> 00:02:53.990
is passed through
a tanh function.

73
00:02:53.990 --> 00:02:56.105
Similarly to the input gate,

74
00:02:56.105 --> 00:02:58.730
the outputs from the
sigmoid layer are

75
00:02:58.730 --> 00:03:01.775
multiplied by the
tanh layer's output,

76
00:03:01.775 --> 00:03:03.710
and this makes the final decision

77
00:03:03.710 --> 00:03:05.915
on what will be
included in the output.

78
00:03:05.915 --> 00:03:08.000
Now you have an
updated cell state,

79
00:03:08.000 --> 00:03:09.380
an updated hidden state,

80
00:03:09.380 --> 00:03:11.330
and one completed timestep.

81
00:03:11.330 --> 00:03:14.110
Your model can move on
to the next timestep.

82
00:03:14.110 --> 00:03:17.575
Let's recap everything
I just covered.

83
00:03:17.575 --> 00:03:19.550
An LSTM has three gates to

84
00:03:19.550 --> 00:03:21.860
decide which information
it's going to keep.

85
00:03:21.860 --> 00:03:24.310
The forget gate
decides what to keep.

86
00:03:24.310 --> 00:03:26.670
The input gate
decides what to add.

87
00:03:26.670 --> 00:03:28.250
The output gate decides

88
00:03:28.250 --> 00:03:30.020
what the next hidden
state will be.

89
00:03:30.020 --> 00:03:32.090
After each of these
gates performs

90
00:03:32.090 --> 00:03:34.175
its function and the
states are updated,

91
00:03:34.175 --> 00:03:36.785
you will have completed
one timestep.

92
00:03:36.785 --> 00:03:40.160
You now understand the
math behind LSTMs.

93
00:03:40.160 --> 00:03:42.335
In the coding exercise
of this week,

94
00:03:42.335 --> 00:03:44.885
you will implement
LSTMs on your own.

95
00:03:44.885 --> 00:03:46.355
In the next video,

96
00:03:46.355 --> 00:03:48.200
I will show you how to use LSTMs

97
00:03:48.200 --> 00:03:50.345
to solve a real NLP task.

98
00:03:50.345 --> 00:03:52.890
Let's go to the next video.