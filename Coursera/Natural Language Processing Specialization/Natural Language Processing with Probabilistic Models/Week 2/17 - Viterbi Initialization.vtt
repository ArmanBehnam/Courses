WEBVTT

1
00:00:00.000 --> 00:00:03.360
Hello. I'll now show you
how you can initialize

2
00:00:03.360 --> 00:00:04.770
a matrix that can tell you

3
00:00:04.770 --> 00:00:06.855
the parts of speech
side of every word.

4
00:00:06.855 --> 00:00:09.900
This matrix will tell
you the probability that

5
00:00:09.900 --> 00:00:13.170
every word belongs to a
certain part of speech.

6
00:00:13.170 --> 00:00:15.555
Let me show you how
you can do this.

7
00:00:15.555 --> 00:00:18.870
As you just saw, the
initialization step is

8
00:00:18.870 --> 00:00:22.320
one of three steps to populate
the auxiliary matrices,

9
00:00:22.320 --> 00:00:25.545
C and D. In the
initialization step,

10
00:00:25.545 --> 00:00:27.990
the first column of
each of our matrices,

11
00:00:27.990 --> 00:00:30.330
C and D is populated.

12
00:00:30.330 --> 00:00:32.640
The first column of C represents

13
00:00:32.640 --> 00:00:35.070
probability of the
transitions from

14
00:00:35.070 --> 00:00:37.590
the start states
by in the graph to

15
00:00:37.590 --> 00:00:41.665
the first tag ti and word W1,

16
00:00:41.665 --> 00:00:46.910
meaning we're trying to go
from tag 1 to the word W1.

17
00:00:46.910 --> 00:00:48.860
This is shown here
for a model with

18
00:00:48.860 --> 00:00:51.640
three hidden states for
the sake of clarity.

19
00:00:51.640 --> 00:00:53.815
So the first column entries,

20
00:00:53.815 --> 00:00:58.205
ci,1 are the products of the
transition probabilities

21
00:00:58.205 --> 00:00:59.930
of the initial states and

22
00:00:59.930 --> 00:01:02.690
the respective emission
probabilities.

23
00:01:02.690 --> 00:01:05.420
As your initial probabilities
are contained in

24
00:01:05.420 --> 00:01:08.405
the first row of the
transition matrix a,

25
00:01:08.405 --> 00:01:11.505
this is the same as a1,i

26
00:01:11.505 --> 00:01:15.155
times the corresponding
emission probability b.

27
00:01:15.155 --> 00:01:18.080
B and C index function
simply returns

28
00:01:18.080 --> 00:01:20.810
the column index and the matrix B

29
00:01:20.810 --> 00:01:24.005
for the given word here, W1.

30
00:01:24.005 --> 00:01:25.755
In the D matrix,

31
00:01:25.755 --> 00:01:27.690
you store the labels
that represent

32
00:01:27.690 --> 00:01:29.950
the different states
you're traversing when

33
00:01:29.950 --> 00:01:32.680
finding the most likely
sequence of parts of

34
00:01:32.680 --> 00:01:35.725
speech tags for the
given sequence of words,

35
00:01:35.725 --> 00:01:38.450
W1 all the way to Wk.

36
00:01:38.450 --> 00:01:42.330
In the first column, you simply
set all entries to zero,

37
00:01:42.330 --> 00:01:44.230
as there are no
proceeding parts of

38
00:01:44.230 --> 00:01:46.240
speech tags we have traversed.

39
00:01:46.240 --> 00:01:48.035
That's it for step one.

40
00:01:48.035 --> 00:01:50.890
You now know how to
initialize your matrices.

41
00:01:50.890 --> 00:01:52.900
In the next video, you're
going to learn how to

42
00:01:52.900 --> 00:01:55.315
continue populating
your matrices,

43
00:01:55.315 --> 00:01:57.340
and you can use that to decode

44
00:01:57.340 --> 00:01:59.949
the parts of speech of
a certain sentence.

45
00:01:59.949 --> 00:02:02.320
You will learn about
the Viterbi algorithm,

46
00:02:02.320 --> 00:02:04.150
which you can use
for part of speech

47
00:02:04.150 --> 00:02:07.460
tagging and also
speech recognition.