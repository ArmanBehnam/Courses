WEBVTT

1
00:00:00.520 --> 00:00:04.722
By now, you have used the intrinsic
evaluation, your first method for

2
00:00:04.722 --> 00:00:09.066
evaluating word embeddings based on
how well they capture the semantic or

3
00:00:09.066 --> 00:00:11.815
syntactic relationships between the words.

4
00:00:11.815 --> 00:00:15.245
To evaluate word embeddings
with extrinsic evaluation,

5
00:00:15.245 --> 00:00:20.215
you use the word embeddings to perform an
external task, which is typically the real

6
00:00:20.215 --> 00:00:23.938
world task that you initially
needed the word embeddings for.

7
00:00:23.938 --> 00:00:28.053
Then, use the performance metric
of this task as a proxy for

8
00:00:28.053 --> 00:00:31.290
the quality of the word embeddings.

9
00:00:31.290 --> 00:00:35.975
Examples of useful word level tasks
include named entity recognition or

10
00:00:35.975 --> 00:00:38.080
parts-of-speech tagging.

11
00:00:38.080 --> 00:00:42.000
A named entity is something that can
be referred to by a proper name.

12
00:00:42.000 --> 00:00:46.740
For example, in the sentence
Andrew works at deeplearning.ai,

13
00:00:46.740 --> 00:00:52.588
the word Andrew is a named entity and
is categorized as a person.

14
00:00:52.588 --> 00:00:57.100
The word deeplearning.ai is
another named entity, and

15
00:00:57.100 --> 00:00:59.950
is categorized as an organization.

16
00:00:59.950 --> 00:01:04.095
A useful task may be to train a model
that can help you identify and

17
00:01:04.095 --> 00:01:07.335
categorize named entities in a sentence.

18
00:01:07.335 --> 00:01:11.455
You could then evaluate this classifier
on the test set with some selected

19
00:01:11.455 --> 00:01:16.055
evaluation metric,
such as accuracy or the F1 score.

20
00:01:16.055 --> 00:01:20.065
The classifier's performance on
the evaluation metric represents

21
00:01:20.065 --> 00:01:25.480
the combined performance of both
the embedding and classification tasks.

22
00:01:25.480 --> 00:01:28.420
Extrinsic evaluation methods
are the ultimate test to

23
00:01:28.420 --> 00:01:31.590
ensure that word embeddings
are actually useful.

24
00:01:31.590 --> 00:01:36.002
However, their main drawbacks are,
that the evaluation will be more

25
00:01:36.002 --> 00:01:39.570
time-consuming than
an intrinsic evaluation.

26
00:01:39.570 --> 00:01:43.740
And that if the performance is poor,
then the performance metrics provides no

27
00:01:43.740 --> 00:01:49.430
information as to which specific parts of
the end to end process is responsible.

28
00:01:49.430 --> 00:01:53.690
The word embeddings themselves
are the external tasks used to test them.

29
00:01:53.690 --> 00:01:57.010
So far, you've evaluated word
embeddings using intrinsic and

30
00:01:57.010 --> 00:02:00.840
extrinsic evaluation methods,
that's very nice.

31
00:02:00.840 --> 00:02:04.740
If you want to dive deeper into this
topic, I've included the reference to

32
00:02:04.740 --> 00:02:09.810
a comprehensive and very readable
paper on evaluating word embeddings.

33
00:02:09.810 --> 00:02:14.040
You've just acquired quite a few new
skills, it's a good time to review.

34
00:02:14.040 --> 00:02:14.970
So that's up next.