WEBVTT

1
00:00:00.000 --> 00:00:01.890
Using a BERT can get you state of

2
00:00:01.890 --> 00:00:04.515
the art results on many
tasks or problems.

3
00:00:04.515 --> 00:00:06.120
In this video, I'm
going to show you

4
00:00:06.120 --> 00:00:07.800
how you can fine-tune this model,

5
00:00:07.800 --> 00:00:10.620
so that you can get it to
work on your own data sets.

6
00:00:10.620 --> 00:00:12.855
Let's take a look at
how you can do this.

7
00:00:12.855 --> 00:00:16.425
Right now you're going to
see how you fine-tune BERT.

8
00:00:16.425 --> 00:00:18.450
During pre-training,
remember, you

9
00:00:18.450 --> 00:00:20.550
had sentence A and sentence B,

10
00:00:20.550 --> 00:00:22.890
and then you use next
sentence prediction

11
00:00:22.890 --> 00:00:24.540
and use mask tokens to

12
00:00:24.540 --> 00:00:26.670
predict the mask tokens
that you mask from

13
00:00:26.670 --> 00:00:29.234
each sentence, that's
in pre-training.

14
00:00:29.234 --> 00:00:31.620
Now, if you want to go on to

15
00:00:31.620 --> 00:00:35.145
MNLI or like hypothesis
premise scenario,

16
00:00:35.145 --> 00:00:37.825
then instead of having
sentence A and sentence B,

17
00:00:37.825 --> 00:00:41.090
you're going to feed in
the hypothesis over here,

18
00:00:41.090 --> 00:00:43.120
and the premise over here.

19
00:00:43.120 --> 00:00:47.895
For NER you're going to feed
the sentence A over here,

20
00:00:47.895 --> 00:00:51.235
and then the corresponding
tags over here.

21
00:00:51.235 --> 00:00:54.960
For question answering,
you'll have SQUAD.

22
00:00:54.960 --> 00:00:57.080
For example, you'll
have your question over

23
00:00:57.080 --> 00:01:01.050
here and then your
answer over here.

24
00:01:01.970 --> 00:01:04.770
Visually, what does
this look like?

25
00:01:04.770 --> 00:01:08.220
Remember this image
from the BERT's paper,

26
00:01:08.220 --> 00:01:10.160
this is what ends up happening

27
00:01:10.160 --> 00:01:11.900
over here you have the question.

28
00:01:11.900 --> 00:01:14.330
Over here, you'll have the
paragraph and this will give

29
00:01:14.330 --> 00:01:16.505
you like your answer.

30
00:01:16.505 --> 00:01:18.575
This starts in the
end of the answer.

31
00:01:18.575 --> 00:01:20.570
Then for NER, again,

32
00:01:20.570 --> 00:01:22.100
you'll have the sentence

33
00:01:22.100 --> 00:01:24.140
and the corresponding
named entities.

34
00:01:24.140 --> 00:01:25.700
For MNLI, you will have

35
00:01:25.700 --> 00:01:28.945
the hypothesis and then
the premise and so forth.

36
00:01:28.945 --> 00:01:31.260
In summary given the place

37
00:01:31.260 --> 00:01:32.915
of sentence A and
sentence census B,

38
00:01:32.915 --> 00:01:35.060
you can fill it with a text

39
00:01:35.060 --> 00:01:37.790
and parts for sentence
A and then say

40
00:01:37.790 --> 00:01:39.230
like an all symbol

41
00:01:39.230 --> 00:01:42.950
to say that you're trying
to classify the text,

42
00:01:42.950 --> 00:01:46.055
whether it's for
sentiment analysis,

43
00:01:46.055 --> 00:01:47.520
like happy or sad,

44
00:01:47.520 --> 00:01:48.860
so that's one way to do it.

45
00:01:48.860 --> 00:01:51.429
Question passage for
question answering,

46
00:01:51.429 --> 00:01:54.570
you could have hypothesis
premise for MNLI.

47
00:01:54.570 --> 00:01:58.205
You could have sentence with
the named entities for NER.

48
00:01:58.205 --> 00:02:01.535
You can have a sentence and a
paraphrase of the sentence.

49
00:02:01.535 --> 00:02:03.260
You could have an article,

50
00:02:03.260 --> 00:02:05.695
the summary and so forth.

51
00:02:05.695 --> 00:02:09.555
This is just the inputs
into your BERT's model.

52
00:02:09.555 --> 00:02:12.290
Now that you know how to
fine-tune your model on

53
00:02:12.290 --> 00:02:14.480
classification tasks,
question answering,

54
00:02:14.480 --> 00:02:17.090
summarization and
more, we'll take it to

55
00:02:17.090 --> 00:02:18.860
the next level and
introduce you to

56
00:02:18.860 --> 00:02:21.020
a new model known as T5.

57
00:02:21.020 --> 00:02:22.340
Please go onto the next video

58
00:02:22.340 --> 00:02:24.930
to learn about the T5 model.