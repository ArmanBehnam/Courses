WEBVTT

1
00:00:02.710 --> 00:00:06.925
Now we know what grayscale digital images is.

2
00:00:06.925 --> 00:00:14.205
The next question. How can we obtain and represent color images. What is color?

3
00:00:14.205 --> 00:00:17.580
Color is a psychological property of

4
00:00:17.580 --> 00:00:21.405
our visual experience when we look at objects and lights,

5
00:00:21.405 --> 00:00:25.620
and it is not a physical property of those objects and lights.

6
00:00:25.620 --> 00:00:28.170
Color is the result of interaction between

7
00:00:28.170 --> 00:00:32.325
physical light in the environment and our human visual system.

8
00:00:32.325 --> 00:00:36.550
Visible light is an electromagnetic radiation in the range

9
00:00:36.550 --> 00:00:40.775
from 380 nanometers to 780 nanometers.

10
00:00:40.775 --> 00:00:44.790
Our eyes are sensitive to electromagnetic radiation in this range

11
00:00:44.790 --> 00:00:49.465
and are insensitive to look for magnetic radiation outside this range.

12
00:00:49.465 --> 00:00:54.340
The reason why it has happened so probably lies in the fact that almost half of

13
00:00:54.340 --> 00:00:59.550
the solar energy that reaches Earth is transferred by light in this range.

14
00:00:59.550 --> 00:01:02.975
Almost the same amount falls to the infrared light,

15
00:01:02.975 --> 00:01:06.875
and the rest falls to ultraviolet radiation.

16
00:01:06.875 --> 00:01:09.035
To describe the source of light,

17
00:01:09.035 --> 00:01:10.590
we need to build that spectrum.

18
00:01:10.590 --> 00:01:14.060
To do it, we need at each wavelength in the range of

19
00:01:14.060 --> 00:01:18.615
visible light to measure the amount of metered energy per time unit.

20
00:01:18.615 --> 00:01:21.905
The amount of metered energy can be measured for example

21
00:01:21.905 --> 00:01:26.125
in number of photons emitted per millisecond.

22
00:01:26.125 --> 00:01:28.325
When light reaches the eye,

23
00:01:28.325 --> 00:01:31.740
photoreceptor cells in the retina reacts to it.

24
00:01:31.740 --> 00:01:35.630
Each rod and cone acts as a filter on the spectrum.

25
00:01:35.630 --> 00:01:38.500
To get the output of this filter we multiply

26
00:01:38.500 --> 00:01:42.770
its response curve by the spectrum and integrate over all wavelengths.

27
00:01:42.770 --> 00:01:46.880
Each photoreceptor cell yields one number.

28
00:01:46.880 --> 00:01:53.235
There are three types of cones with different responses.

29
00:01:53.235 --> 00:01:58.005
They can be described by the modes of their responses as long,

30
00:01:58.005 --> 00:02:00.540
medium, and short cones.

31
00:02:00.540 --> 00:02:06.735
So in our eyes they represent spectrum with three numbers from three types of cones.

32
00:02:06.735 --> 00:02:10.990
How can you represent a full spectrum with only three numbers?

33
00:02:10.990 --> 00:02:15.490
Of course we can't, and most information in the signal is lost.

34
00:02:15.490 --> 00:02:20.150
So two very different spectra may appear indistinguishable to a human observer.

35
00:02:20.150 --> 00:02:24.050
On the slide, I give two examples of such spectrums,

36
00:02:24.050 --> 00:02:26.455
which look like a purple color.

37
00:02:26.455 --> 00:02:29.270
You can see from the curves that they are vastly different.

38
00:02:29.270 --> 00:02:33.435
One curve is very smooth and one has a lot of peaks.

39
00:02:33.435 --> 00:02:35.280
But to the human observer,

40
00:02:35.280 --> 00:02:39.770
these two very different light sources produce the same color sensation.

41
00:02:39.770 --> 00:02:44.785
Such spectra that produce the same color spectra are called metamers,

42
00:02:44.785 --> 00:02:48.530
though these two examples are two metamers of purple color.

43
00:02:48.530 --> 00:02:52.660
Let's select three primary colors P1, P2, P3.

44
00:02:52.660 --> 00:02:58.265
We can try to represent all other colors with linear combination of these primary colors.

45
00:02:58.265 --> 00:03:00.885
Such primary colors are called primaries.

46
00:03:00.885 --> 00:03:04.680
And the weights that they used to represent other colors can

47
00:03:04.680 --> 00:03:08.530
be color coordinates in this color model on color coordinate system.

48
00:03:08.530 --> 00:03:13.130
There is a theory called trichromatic color theory that says that we can

49
00:03:13.130 --> 00:03:18.310
go get all visible colors by combining just those three primaries.

50
00:03:18.310 --> 00:03:19.920
To verify this theory,

51
00:03:19.920 --> 00:03:22.530
you can make color matching experiments.

52
00:03:22.530 --> 00:03:24.895
In these color matching experiments,

53
00:03:24.895 --> 00:03:29.220
the human observer is presented these different lights.

54
00:03:29.220 --> 00:03:31.305
On one part of the screen,

55
00:03:31.305 --> 00:03:33.855
you see a light spot from the test light.

56
00:03:33.855 --> 00:03:35.650
On the other part of the screen,

57
00:03:35.650 --> 00:03:40.800
you see a spot that is combined by three primary light sources.

58
00:03:40.800 --> 00:03:45.585
Human observer can change their relative power of these power sources.

59
00:03:45.585 --> 00:03:47.470
The goal of the observer is,

60
00:03:47.470 --> 00:03:49.345
by changing relative powers,

61
00:03:49.345 --> 00:03:55.010
to match the colors of test light to the color of the combination of primary lights.

62
00:03:55.010 --> 00:04:00.610
We can do the same experiments again and again with different observers and compare

63
00:04:00.610 --> 00:04:06.475
the powers that are used by different subjects to match the same test light,

64
00:04:06.475 --> 00:04:10.555
and then we can average the results of them.

65
00:04:10.555 --> 00:04:15.935
Based on these color matching experiments a set of heuristic laws,

66
00:04:15.935 --> 00:04:18.715
which are called the Grassman laws, are derived.

67
00:04:18.715 --> 00:04:23.535
The basic idea behind the Grassman laws is that color matching appears to be linear.

68
00:04:23.535 --> 00:04:28.075
The following properties of color matching are violet.

69
00:04:28.075 --> 00:04:32.460
If two test lights can be matched with the same set of weights,

70
00:04:32.460 --> 00:04:37.910
then these two test lights can match each other. The second property.

71
00:04:37.910 --> 00:04:39.840
If we mix two test lights,

72
00:04:39.840 --> 00:04:45.065
then mixing the matches will result in matching the result of mixing two test lights.

73
00:04:45.065 --> 00:04:47.665
And if we scale the test lights,

74
00:04:47.665 --> 00:04:51.135
then the matches gets scaled by the same amount.

75
00:04:51.135 --> 00:04:53.065
Based on these laws,

76
00:04:53.065 --> 00:04:56.350
we can obtain different linear color models.

77
00:04:56.350 --> 00:04:59.125
It's enough to select three primary sources,

78
00:04:59.125 --> 00:05:04.755
and then we can obtain all other colors by mixing these primary sources.

79
00:05:04.755 --> 00:05:09.425
For example we can select cone perception modes as primaries.

80
00:05:09.425 --> 00:05:11.660
These modes correspond to red,

81
00:05:11.660 --> 00:05:13.250
green and blue colors.

82
00:05:13.250 --> 00:05:15.915
So such model will be called RGB model.

83
00:05:15.915 --> 00:05:23.995
In 1931, International Commission of illumination proposed an CIE RGB 1931 color model.

84
00:05:23.995 --> 00:05:27.595
In this model, primaries are three monochromatic lights.

85
00:05:27.595 --> 00:05:31.115
If you want to use this model in computer display,

86
00:05:31.115 --> 00:05:35.080
they will correspond to the three types of phosphors in the computer display.

87
00:05:35.080 --> 00:05:38.420
We can visualize all colors that can be represented by

88
00:05:38.420 --> 00:05:41.825
RGB model with a 3D cube aligned to this coordinate system.

89
00:05:41.825 --> 00:05:43.830
The origin 0, 0,

90
00:05:43.830 --> 00:05:45.940
0 corresponds to black color.

91
00:05:45.940 --> 00:05:51.825
The primaries are located on the three corners of the cube along the coordinate axis.

92
00:05:51.825 --> 00:05:54.870
The corner which is opposite to black with coordinates 1,

93
00:05:54.870 --> 00:05:56.885
1, 1 corresponds to white color.

94
00:05:56.885 --> 00:06:03.850
Three other corners, correspond to a combination of just two primary colors,

95
00:06:03.850 --> 00:06:05.780
and they look like blue,

96
00:06:05.780 --> 00:06:08.250
magenta, and yellow colors.

97
00:06:08.250 --> 00:06:10.115
The next question is,

98
00:06:10.115 --> 00:06:14.985
can these RGB model represent all colors that are visible to a human observer.

99
00:06:14.985 --> 00:06:19.125
To verify this, we can continue color matching experiments to match

100
00:06:19.125 --> 00:06:23.995
RGB primaries to single-wavelength light sources in the range of visible light.

101
00:06:23.995 --> 00:06:29.115
The weights from these experiments will provide us matching functions.

102
00:06:29.115 --> 00:06:32.625
For each wavelength, we can get

103
00:06:32.625 --> 00:06:37.090
three weights that are used to match the single-wavelength light.

104
00:06:37.090 --> 00:06:41.550
We average the result of the matching functions of many observers,

105
00:06:41.550 --> 00:06:45.245
and during this experiment we will find that

106
00:06:45.245 --> 00:06:50.065
sometimes it's impossible to match test color with available primaries.

107
00:06:50.065 --> 00:06:55.175
To solve this problem, the primary color needed to be added to the test source,

108
00:06:55.175 --> 00:06:58.340
rather, to the basic primaries.

109
00:06:58.340 --> 00:07:00.885
To match color in this example,

110
00:07:00.885 --> 00:07:06.245
we need to add some amount of P2 primary to the test color side.

111
00:07:06.245 --> 00:07:09.465
This correspond to the negative weight.

112
00:07:09.465 --> 00:07:12.965
If you need to add some primary color to the test source,

113
00:07:12.965 --> 00:07:16.680
then we'll write this down as negative coordinate of

114
00:07:16.680 --> 00:07:20.840
this primary in color matching functions.

115
00:07:20.840 --> 00:07:27.065
So, the result of this experiment is that RGB model can't represent all visible colors.

116
00:07:27.065 --> 00:07:31.055
Substractive matching is required for some wavelengths.

117
00:07:31.055 --> 00:07:35.910
The other problem is RGB model that it is not very intuitive.

118
00:07:35.910 --> 00:07:39.160
Intuitively, we can describe visible light usually

119
00:07:39.160 --> 00:07:43.150
using intensity of light or brightness as a measure of strength of the light,

120
00:07:43.150 --> 00:07:45.700
and color or chromaticity.

121
00:07:45.700 --> 00:07:50.545
Sometimes, chromaticity can we break down to the hue and saturation factor.

122
00:07:50.545 --> 00:07:52.360
And in RGB model,

123
00:07:52.360 --> 00:07:54.865
we have no specific chromaticity information,

124
00:07:54.865 --> 00:07:57.360
we have only weights of the primary colors,

125
00:07:57.360 --> 00:08:00.100
and there is no brightness information.

126
00:08:00.100 --> 00:08:02.860
To solve this problem, in 1931,

127
00:08:02.860 --> 00:08:05.085
together with standard RGB model,

128
00:08:05.085 --> 00:08:08.450
another model, which is called XYZ was proposed.

129
00:08:08.450 --> 00:08:11.005
The goal was to get a linear additive model

130
00:08:11.005 --> 00:08:15.495
XYZ where component Y correspond to perceived brightness.

131
00:08:15.495 --> 00:08:18.635
This model should cover all visible colors,

132
00:08:18.635 --> 00:08:21.980
and all matching function should be everywhere positive.

133
00:08:21.980 --> 00:08:27.775
So, there is no such thing for XYZ model as substractive matching.

134
00:08:27.775 --> 00:08:33.005
X and Z components in this model capture chromaticity component of light.

135
00:08:33.005 --> 00:08:37.290
And points (zero, zero, one),

136
00:08:37.290 --> 00:08:39.530
(zero, one, zero), and (one,

137
00:08:39.530 --> 00:08:42.330
zero, zero) will be imaginary primaries.

138
00:08:42.330 --> 00:08:44.210
All values of X, Y,

139
00:08:44.210 --> 00:08:46.810
and Z are from zero to infinity.

140
00:08:46.810 --> 00:08:50.445
Dimension theorems for XYZ are shown in this slide.

141
00:08:50.445 --> 00:08:54.160
To visualize all possible colors using XYZ model,

142
00:08:54.160 --> 00:08:57.080
we will use normalized values X and Y,

143
00:08:57.080 --> 00:09:02.320
where X is ratio of X to the sum of XYZ,

144
00:09:02.320 --> 00:09:08.530
and Y is ratio of capital Y to the sum of XYZ.

145
00:09:08.530 --> 00:09:12.925
By varying X and Y in the range from zero to one,

146
00:09:12.925 --> 00:09:17.370
we can build color diagram or called color gumut.

147
00:09:17.370 --> 00:09:19.585
From this color gumut,

148
00:09:19.585 --> 00:09:21.515
we can make several observations.

149
00:09:21.515 --> 00:09:25.470
First observation is that single wavelength light sources

150
00:09:25.470 --> 00:09:28.345
are placed on the bounding curve of this gumut.

151
00:09:28.345 --> 00:09:31.570
Bottom line segment of purple colors correspond to

152
00:09:31.570 --> 00:09:35.345
colors that are unachievable by single wavelength light sources.

153
00:09:35.345 --> 00:09:39.180
So there are some colors that human can only see you if

154
00:09:39.180 --> 00:09:43.975
they're produced by a light source,

155
00:09:43.975 --> 00:09:50.100
not a laser but some range wavelengths.

156
00:09:50.100 --> 00:09:54.490
And from the shape of the gumut,

157
00:09:54.490 --> 00:09:58.735
we can see that no three real primaries can cover all visible colors.

158
00:09:58.735 --> 00:10:02.220
So, all linear models will either have

159
00:10:02.220 --> 00:10:08.020
imaginary primaries or they will not cover all possibly visible colors.

160
00:10:08.020 --> 00:10:12.230
On the slide, I display several variants of RGB model.

161
00:10:12.230 --> 00:10:16.165
The main difference between the models is the selection of primaries.

162
00:10:16.165 --> 00:10:20.135
You can see the difference in color presentation between different models.

163
00:10:20.135 --> 00:10:22.635
Depending on the selected primaries,

164
00:10:22.635 --> 00:10:26.820
the model cover different areas in color gumut.

165
00:10:26.820 --> 00:10:30.970
There is also one additional important property of light perception.

166
00:10:30.970 --> 00:10:34.345
It is non-uniformity of intensity perception.

167
00:10:34.345 --> 00:10:37.320
On the slide, there are two samples.

168
00:10:37.320 --> 00:10:40.575
First, is physically uniform brightness samples,

169
00:10:40.575 --> 00:10:44.290
and the second is perceptually uniform brightness samples.

170
00:10:44.290 --> 00:10:47.260
For the physically uniform brightness samples,

171
00:10:47.260 --> 00:10:49.805
you can see that the difference between

172
00:10:49.805 --> 00:10:54.805
black and dark gray is very significant for the human observer.

173
00:10:54.805 --> 00:11:00.735
It's much more significant than the difference between the bright samples on the right.

174
00:11:00.735 --> 00:11:02.620
From this, we can make

175
00:11:02.620 --> 00:11:07.090
the following observation that it is ineffective to store a brightness linearly

176
00:11:07.090 --> 00:11:10.310
because our human eyes distinguish differences in

177
00:11:10.310 --> 00:11:13.995
dark areas much better than difference in bright areas.

178
00:11:13.995 --> 00:11:18.270
So we can use gamma transformation and store gamma-corrected values

179
00:11:18.270 --> 00:11:20.995
instead of linear RGB values.

180
00:11:20.995 --> 00:11:26.100
To store gamma-corrected values is the main idea behind the sRGB model.

181
00:11:26.100 --> 00:11:30.980
sRGB model is a standard RGB model used in high definition television,

182
00:11:30.980 --> 00:11:33.540
digital cameras, display, et cetera.

183
00:11:33.540 --> 00:11:37.565
To obtain values of this sRGB model from XYZ model,

184
00:11:37.565 --> 00:11:39.365
we need to do two steps.

185
00:11:39.365 --> 00:11:45.695
First step is linear transformation from XYZ coordinates to linear RGB coordinates.

186
00:11:45.695 --> 00:11:48.940
Then we apply per channel on non-linear transformation.

187
00:11:48.940 --> 00:11:53.585
If we want to estimate light intensity or brightness from sRGB model,

188
00:11:53.585 --> 00:11:56.640
we need to apply this two transformation in reverse.

189
00:11:56.640 --> 00:12:01.545
First, we apply non-linear transformation to obtain linear RGB values,

190
00:12:01.545 --> 00:12:06.520
and then reapply linear transformation from linear RGB values to

191
00:12:06.520 --> 00:12:12.450
XYZ values and the Y value will give us the brightness of this color.

192
00:12:12.450 --> 00:12:15.765
There are other type of color models.

193
00:12:15.765 --> 00:12:18.675
For example, the YIQ model.

194
00:12:18.675 --> 00:12:21.850
This model was first introduced for analog colored TV.

195
00:12:21.850 --> 00:12:26.920
This is also linear model with separated the brightness component.

196
00:12:26.920 --> 00:12:29.580
Y corresponds to brightness component,

197
00:12:29.580 --> 00:12:33.525
and I and Q correspond to chromaticity information.

198
00:12:33.525 --> 00:12:35.770
Because brightness is separated,

199
00:12:35.770 --> 00:12:38.775
we can transmit it on a grayscale channel

200
00:12:38.775 --> 00:12:42.380
and color and information can be transmitted on additional bandwidth.

201
00:12:42.380 --> 00:12:45.340
This allows us to simultaneously translate signal,

202
00:12:45.340 --> 00:12:49.510
which can be received by grayscale TV and colored TV.

203
00:12:49.510 --> 00:12:54.385
YIQ model is used in NTSC standard.

204
00:12:54.385 --> 00:12:57.940
In PAL standard, there is a bit different model.

205
00:12:57.940 --> 00:13:01.560
Now, we can understand how we can obtain colored images.

206
00:13:01.560 --> 00:13:03.125
To obtain colored images,

207
00:13:03.125 --> 00:13:04.440
we need to measure R,

208
00:13:04.440 --> 00:13:07.895
G, and B value in each point of optical image.

209
00:13:07.895 --> 00:13:11.410
This can be done for example by taking three pictures with red,

210
00:13:11.410 --> 00:13:14.400
green, and blue filter of the same scene.

211
00:13:14.400 --> 00:13:18.995
In Russia, the history of color photography is started by Sergei Prokudin-Gorsky.

212
00:13:18.995 --> 00:13:21.840
He build special projector to display color photographs

213
00:13:21.840 --> 00:13:24.850
on three separate images in red, green, and blue channels.

214
00:13:24.850 --> 00:13:27.770
He also received the grant from the last Russian emperor

215
00:13:27.770 --> 00:13:31.335
Nicholas II to make a color gallery of the Russian empire.

216
00:13:31.335 --> 00:13:34.570
You can see images reconstructed from photos of

217
00:13:34.570 --> 00:13:37.855
Sergei Prokudin-Gorsky on the link displayed on the slide.

218
00:13:37.855 --> 00:13:41.980
In digital photography, instead of taking three images with different filters,

219
00:13:41.980 --> 00:13:43.320
we can use another technique,

220
00:13:43.320 --> 00:13:44.915
which is called Bayer pattern.

221
00:13:44.915 --> 00:13:48.900
In this case, each pixel in a sensor are if it its own filter.

222
00:13:48.900 --> 00:13:52.655
So, in each pixel, we obtain value for only one color channel,

223
00:13:52.655 --> 00:13:55.685
and the values for other color channel are missing.

224
00:13:55.685 --> 00:13:57.940
So, they need to be reconstructed.

225
00:13:57.940 --> 00:14:03.675
We can interpolate values of missing channels using information from neighboring pixels.

226
00:14:03.675 --> 00:14:06.420
This procedure is called demosaicing.

227
00:14:06.420 --> 00:14:09.460
Demosaicing can lead to image artifacts,

228
00:14:09.460 --> 00:14:11.270
as demonstrated in the slide.

229
00:14:11.270 --> 00:14:16.115
For example, fine black and white details can be interpreted as changes in color,

230
00:14:16.115 --> 00:14:19.720
not a small details during demosaicing.

231
00:14:19.720 --> 00:14:22.785
And we will receive raw in colors in the image.

232
00:14:22.785 --> 00:14:24.235
To solve this problem,

233
00:14:24.235 --> 00:14:26.830
specific techniques of demosaicing should be used

234
00:14:26.830 --> 00:14:30.200
and implemented actually in most of the modern cameras.

235
00:14:30.200 --> 00:14:35.550
So even this simple procedure of taking color images is not very simple.

236
00:14:35.550 --> 00:14:39.290
Now, we can understand what the digital color image is.

237
00:14:39.290 --> 00:14:44.680
Digital color image is three dimensional array where each pixel is coordinate.

238
00:14:44.680 --> 00:14:50.710
X, Y is represented with color vector of lens C. C is the number of channels.

239
00:14:50.710 --> 00:14:52.970
Usually, the number of channels is three,

240
00:14:52.970 --> 00:14:57.760
for example for RGB model or YIQ model, or some other model.

241
00:14:57.760 --> 00:15:00.875
But the number of channels can be different, for example,

242
00:15:00.875 --> 00:15:06.360
we can try to store full description of spectrum so the vector will be very large.

243
00:15:06.360 --> 00:15:10.010
But usually, you we have only three channels.

244
00:15:10.010 --> 00:15:13.900
Usually, each component is discretized to the interval

245
00:15:13.900 --> 00:15:17.795
from zero to 255 and stored in one bit word.

246
00:15:17.795 --> 00:15:21.625
This is usually enough for the recognition purposes.

247
00:15:21.625 --> 00:15:25.370
What if you want to have more precision in each channel?

248
00:15:25.370 --> 00:15:28.220
You can use 10 bit or 16 bit words,

249
00:15:28.220 --> 00:15:33.675
and obtain better accuracy in color representation.

250
00:15:33.675 --> 00:15:35.760
But for the recognition,

251
00:15:35.760 --> 00:15:40.740
its rarely required so we will think that most

252
00:15:40.740 --> 00:15:46.370
of images that we're working these are three channels by eight-bit words.