{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "You can run this file to shuffle train, val and test dataset. Then you should repeat learning and test procedure. If model result doesn't change significant, it haven't overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import transform, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle as pickle\n",
    "from copy import copy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_count = 0\n",
    "\n",
    "def fold(n_fold):\n",
    "    global image_count\n",
    "    fnames, bboxes = [], []\n",
    "\n",
    "    with open(\"data/FDDB-folds/FDDB-fold-{n_fold:02d}-ellipseList.txt\".format(n_fold=n_fold), \"r\") as fin:\n",
    "        fin = iter(fin)\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                fnames.append(next(fin).strip())\n",
    "                shape = imread(\"data/originalPics/\" + fnames[-1] + \".jpg\").shape[:2]\n",
    "                \n",
    "                count = int(next(fin))\n",
    "                \n",
    "                for i in range(count):\n",
    "                    \n",
    "                    a, b, phi, center_x, center_y, _1 = (float(c) for c in next(fin).split())\n",
    "                    t_x = np.arctan2(-b * np.tan(phi), a )\n",
    "                    x_diff = np.abs(a * np.cos(t_x) * np.cos(phi) - b * np.sin(t_x) * np.sin(phi))\n",
    "                    t_y = np.arctan2(b, a * np.tan(phi))\n",
    "                    y_diff = np.abs(b * np.sin(t_y) * np.cos(phi) + a * np.cos(t_y) * np.sin(phi))\n",
    "\n",
    "                    \n",
    "\n",
    "                    bbox = [np.floor(center_y - y_diff), np.floor(center_x - x_diff), np.ceil(center_y + y_diff), np.ceil(center_x + x_diff)]\n",
    "                    bbox = [max((int(c), 0)) for c in bbox]\n",
    "                    bbox[::2] = (min((c, shape[0])) for c in bbox[::2])\n",
    "                    bbox[1::2] = (min((c, shape[1])) for c in bbox[1::2])\n",
    "                    bbox = [image_count, *bbox, *shape]\n",
    "                    \n",
    "                    bboxes.append(bbox)\n",
    "                \n",
    "                image_count += 1\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        \n",
    "        return fnames, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnames, bboxes = [], []\n",
    "image_count = 0\n",
    "\n",
    "for n_fold in range(1, 11):\n",
    "    _fnames, _bboxes = fold(n_fold)\n",
    "    fnames.extend(_fnames)\n",
    "    bboxes.extend(_bboxes)\n",
    "\n",
    "bboxes = np.array(bboxes, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_scales = []\n",
    "\n",
    "for image_index in set(bboxes[:, 0]):\n",
    "    image_bboxes = bboxes[bboxes[:, 0] == image_index]\n",
    "    bbox_sizes = image_bboxes[:, (3, 4)] - image_bboxes[:, (1, 2)]\n",
    "    avg_size = bbox_sizes.mean()\n",
    "    rescale = 32 / avg_size\n",
    "    \n",
    "    converted_bbox_sizes = bbox_sizes * rescale\n",
    "    converted_image_size = image_bboxes[0, -2:] * rescale\n",
    "    \n",
    "    TR = 8\n",
    "    if (converted_bbox_sizes.min() >= 32 - TR and\n",
    "        converted_bbox_sizes.max() <= 32 + TR and\n",
    "        converted_image_size.min() >= 40 and\n",
    "        converted_image_size.max() <= 176\n",
    "       ):\n",
    "        convert_scales.append([image_index, rescale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convert_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_bboxes = []\n",
    "\n",
    "for image_index, rescale in convert_scales:\n",
    "    image = imread(\"data/originalPics/\" + fnames[image_index] + \".jpg\")\n",
    "    image = transform.rescale(image, rescale, mode=\"reflect\")\n",
    "    if len(image.shape) == 2: # image is gray\n",
    "        image = color.gray2rgb(image)\n",
    "    converted_image = np.zeros((176, 176, 3))\n",
    "    converted_image[:image.shape[0], :image.shape[1]] = image\n",
    "    imsave(\"data/convertedPics/\" + str(image_index) + \".png\", converted_image)\n",
    "    # print(bboxes[bboxes[:, 0] == image_index, 1:], rescale)\n",
    "    convert_bboxes.append(bboxes[bboxes[:, 0] == image_index, 1:] * rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_bboxes = np.vstack([np.hstack([np.array([[image_index]]*len(bboxes)), bboxes]).astype(int)\n",
    "                            for bboxes, (image_index, rescale) in zip(convert_bboxes, convert_scales)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_indeces = sorted(set(convert_bboxes[:, 0]))\n",
    "\n",
    "trainval_indeces, test_indeces = train_test_split(image_indeces, test_size=0.2)\n",
    "train_indeces, val_indeces = train_test_split(trainval_indeces, test_size=0.25)\n",
    "\n",
    "def extract_images(image_indeces, convert_bboxes):\n",
    "    fnames = [\"convertedPics/{image_index}.png\".format(image_index=image_index) for image_index in image_indeces]\n",
    "    \n",
    "    result_bboxes = []\n",
    "    for i, image_index in enumerate(image_indeces):\n",
    "        part_bboxes = convert_bboxes[convert_bboxes[:, 0] == image_index]\n",
    "        part_bboxes[:, 0] = i\n",
    "        result_bboxes.append(part_bboxes)\n",
    "    \n",
    "    return fnames, np.vstack(result_bboxes)\n",
    "\n",
    "train_fnames, train_bboxes = extract_images(sorted(train_indeces), convert_bboxes)\n",
    "val_fnames, val_bboxes = extract_images(sorted(val_indeces), convert_bboxes)\n",
    "test_fnames, test_bboxes = extract_images(sorted(test_indeces), convert_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_indeces = sorted(set(bboxes[:, 0]) - set(image_indeces))\n",
    "original_bboxes = []\n",
    "original_fnames = []\n",
    "for image_index in original_indeces:\n",
    "    original_fnames.append(\"originalPics/\" + fnames[image_index] + \".jpg\")\n",
    "    original_bboxes.append(bboxes[bboxes[:, 0] == image_index, 1:])\n",
    "\n",
    "original_bboxes = np.vstack([np.hstack([np.array([[i]]*len(bboxes)), bboxes]).astype(int)\n",
    "                             for i, bboxes in enumerate(original_bboxes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/original_fnames.csv\", \"w\") as fout:\n",
    "    for fname in original_fnames:\n",
    "        print(fname, file=fout)\n",
    "with open(\"data/original_bboxes.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(original_bboxes.tolist(), fout, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/train_fnames.csv\", \"w\") as fout:\n",
    "    for fname in train_fnames:\n",
    "        print(fname, file=fout)\n",
    "with open(\"data/val_fnames.csv\", \"w\") as fout:\n",
    "    for fname in val_fnames:\n",
    "        print(fname, file=fout)\n",
    "with open(\"data/test_fnames.csv\", \"w\") as fout:\n",
    "    for fname in test_fnames:\n",
    "        print(fname, file=fout)\n",
    "        \n",
    "with open(\"data/train_bboxes.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(train_bboxes.tolist(), fout, protocol=2)\n",
    "with open(\"data/val_bboxes.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(val_bboxes.tolist(), fout, protocol=2)\n",
    "with open(\"data/test_bboxes.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(test_bboxes.tolist(), fout, protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
