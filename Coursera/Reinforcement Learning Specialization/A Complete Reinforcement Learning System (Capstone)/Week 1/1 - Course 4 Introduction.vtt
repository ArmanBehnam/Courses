WEBVTT

1
00:00:00.000 --> 00:00:02.970
In Course 3, we showed you how to

2
00:00:02.970 --> 00:00:05.565
use reinforcement learning
with function approximation.

3
00:00:05.565 --> 00:00:07.110
We covered how to approximate

4
00:00:07.110 --> 00:00:08.955
value functions and policies

5
00:00:08.955 --> 00:00:10.290
using neural networks and

6
00:00:10.290 --> 00:00:12.585
fixed basis approaches
like tell coding.

7
00:00:12.585 --> 00:00:15.020
We discussed how function
approximation allows for

8
00:00:15.020 --> 00:00:18.185
generalization which helps
the agent learn faster.

9
00:00:18.185 --> 00:00:20.780
But we might lose
some of the ability

10
00:00:20.780 --> 00:00:23.225
to discriminate between
the values of states.

11
00:00:23.225 --> 00:00:25.220
The function approximation
may no longer be

12
00:00:25.220 --> 00:00:27.490
able to get all the values right.

13
00:00:27.490 --> 00:00:29.570
The agent then has
to decide how to

14
00:00:29.570 --> 00:00:31.480
balance accuracy across states.

15
00:00:31.480 --> 00:00:34.535
How to allocate its limited
approximation resources.

16
00:00:34.535 --> 00:00:36.230
We introduced
subjective functions

17
00:00:36.230 --> 00:00:37.700
to specify how to balance

18
00:00:37.700 --> 00:00:39.680
approximation error and discuss

19
00:00:39.680 --> 00:00:43.265
gradient-based algorithms to
optimize those objectives.

20
00:00:43.265 --> 00:00:45.620
Using all this new knowledge,

21
00:00:45.620 --> 00:00:46.670
you are ready to implement

22
00:00:46.670 --> 00:00:49.355
a complete reinforcement
learning system.

23
00:00:49.355 --> 00:00:51.830
You will study a problem
that highlights some of

24
00:00:51.830 --> 00:00:53.270
the challenges you
might face when

25
00:00:53.270 --> 00:00:55.430
applying RL in the wild.

26
00:00:55.430 --> 00:00:57.370
In Course 4, you will be putting

27
00:00:57.370 --> 00:00:59.110
together your knowledge
from Courses 1,

28
00:00:59.110 --> 00:01:02.380
2, and 3 to land a lunar
module on the Moon.

29
00:01:02.380 --> 00:01:04.780
When Adam and I start
working on a new problem,

30
00:01:04.780 --> 00:01:07.030
we start by having meetings
to brainstorm about

31
00:01:07.030 --> 00:01:08.890
how to best frame the problem

32
00:01:08.890 --> 00:01:11.500
and gather ideas about
potential solutions.

33
00:01:11.500 --> 00:01:13.580
There's rarely one
right solution.

34
00:01:13.580 --> 00:01:15.820
Throughout, we will
reason with you how we

35
00:01:15.820 --> 00:01:19.000
might approach designing
an agent for this problem.

36
00:01:19.000 --> 00:01:21.190
We will start by
discussing how to

37
00:01:21.190 --> 00:01:23.275
formalize the problem as an MVP.

38
00:01:23.275 --> 00:01:25.005
If someone just told you,

39
00:01:25.005 --> 00:01:26.580
"Design an agent to land this

40
00:01:26.580 --> 00:01:28.270
lunar module," you would have to

41
00:01:28.270 --> 00:01:29.350
figure out how to turn

42
00:01:29.350 --> 00:01:31.945
that goal into a
problem formulation.

43
00:01:31.945 --> 00:01:34.180
So that, of course,
is where we begin.

44
00:01:34.180 --> 00:01:36.010
Then we'll think
about how to choose

45
00:01:36.010 --> 00:01:37.820
an appropriate
learning algorithm.

46
00:01:37.820 --> 00:01:39.800
An important part of this
is actually thinking

47
00:01:39.800 --> 00:01:42.455
about all the details of
the algorithms involved.

48
00:01:42.455 --> 00:01:44.959
This includes determining
how the agent explores,

49
00:01:44.959 --> 00:01:47.285
the type of function
approximation architecture,

50
00:01:47.285 --> 00:01:49.640
details inside the function
approximator such as

51
00:01:49.640 --> 00:01:53.280
the number of features it
produces, and the list goes on.

52
00:01:53.280 --> 00:01:55.385
A big part of this course is

53
00:01:55.385 --> 00:01:58.040
understand the importance
of all these details,

54
00:01:58.040 --> 00:02:00.560
and how to try to gain
some insight into how

55
00:02:00.560 --> 00:02:02.945
your algorithm behaves
with different choices.

56
00:02:02.945 --> 00:02:06.250
Practical implementation
begins with understanding.

57
00:02:06.250 --> 00:02:08.820
So let's not just sit
here talking about it,

58
00:02:08.820 --> 00:02:11.000
let's dive right in and
get our hands dirty.

59
00:02:11.000 --> 00:02:13.490
With Moon dirt, of course.