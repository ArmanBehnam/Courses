# Sequence Models by [Coursera](https://www.coursera.org/learn/nlp-sequence-models)

<p align="center"><img width="100" src="https://mindfieldconsulting.com/wp-content/uploads/2018/07/coursera-logo.png" />  </p>

Analysis and discussing [Sequence Models](http://www.armanbehnam.com/about-me/education/seq-models-coursera/) in my website


- [Week 1 Recurrent Neural Networks](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%201)

  1 - Why sequence models [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/1%20-%20Why%20sequence%20models.pdf).
  
  2 - Notation [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/2%20-%20Notation.pdf).
  
  3 - Recurrent Neural Network Model [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/3%20-%20Recurrent%20Neural%20Network%20Model.pdf).
  
  4 - Backpropagation through time [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/4%20-%20Backpropagation%20through%20time.pdf).
  
  5 - Different types of RNNs [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/5%20-%20Different%20types%20of%20RNNs.pdf).
  
  6 - Language model and sequence generation [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/6%20-%20Language%20model%20and%20sequence%20generation.pdf).
  
  7 - Sampling novel sequences [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/7%20-%20Sampling%20novel%20sequences.pdf). 
  
  8 - Vanishing gradients with RNNs [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/8%20-%20Vanishing%20gradients%20with%20RNNs.pdf). 
  
  9 - Gated Recurrent Unit (GRU) [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/9%20-%20Gated%20Recurrent%20Unit%20(GRU).pdf).
 
  10 - Bidirectional RNN [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/10%20-%20Bidirectional%20RNN.pdf). 
  
  11 - Deep RNNs [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%201/11%20-%20Deep%20RNNs.pdf).
  
  - [x] [Building a Recurrent Neural Network - Step by Step](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%201/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step)
  - [x] [Dinosaur Island -- Character-level language model](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%201/Dinosaur%20Island%20--%20Character-level%20language%20model)
  - [x] [Jazz improvisation with LSTM](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%201/Jazz%20improvisation%20with%20LSTM)
  
- [Week 2 Natural Language Processing & Word Embeddings](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%202)

  1 - Word Representation [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/12%20-%20Word%20Representation.pdf).
  
  2 - Using word embeddings [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/13%20-%20Using%20word%20embeddings.pdf).
  
  3 - Properties of word embeddings [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/14%20-%20Properties%20of%20word%20embeddings.pdf).
  
  4 -  Embedding matrix [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/15%20-%20Embedding%20matrix.pdf).
  
  5 - Learning word embeddings [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/16%20-%20Learning%20word%20embeddings.pdf).
  
  6 - Word2Vec [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/17%20-%20Word2Vec.pdf).
  
  7 - Negative Sampling [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/18%20-%20Negative%20Sampling.pdf). 
  
  8 - GloVe word vectors [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/19%20-%20GloVe%20word%20vectors.pdf). 
  
  9 - Sentiment Classification and [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/20%20-%20Sentiment%20Classification.pdf).
  
  10 - Example EM for discrete mixture, E step [video](https://www.youtube.com/watch?v=RPkI5qe2_8w&list=PLnyR92sanMAQ8VsEENbGTa8ptRds4FbHN&index=19).
 
  11 - Example EM for discrete mixture, M step [video](https://www.youtube.com/watch?v=9kOW8PjUGF0&list=PLnyR92sanMAQ8VsEENbGTa8ptRds4FbHN&index=20).
  
  12 - Debiasing word embeddings [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%202/21%20-%20Debiasing%20word%20embeddings.pdf).
  
  - [x] [Emojify](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%202/Emojify)
  - [x] [Word Vector Representation](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%202/Word%20Vector%20Representation)
  
- [Week 3 Sequence models & Attention mechanism](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%203)

  1 - Picking the most likely sentence [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/23%20-%20Picking%20the%20most%20likely%20sentence.pdf).
  
  2 - Beam Search [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/24%20-%20Beam%20Search.pdf).
  
  3 - Refinements to Beam Search [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/25%20-%20Refinements%20to%20Beam%20Search.pdf).
  
  4 - Bleu Score (optional) [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/26%20-%20Bleu%20Score%20(optional).pdf).
  
  5 - Attention Model Intuition [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/27%20-%20Attention%20Model%20Intuition.pdf).
  
  6 - Attention Model [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/28%20-%20Attention%20Model.pdf).
  
  7 - Speech recognition [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/29%20-%20Speech%20recognition.pdf).
  
  8 - Trigger Word Detection [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/30%20-%20Trigger%20Word%20Detection.pdf). 
  
  9 - Conclusion and thank you [slide](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Week%203/31%20-%20Conclusion%20and%20thank%20you.pdf). 
  

  - [x] [Neural Machine Translation with Attention](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%203/Neural%20Machine%20Translation%20with%20Attention)
  - [x] [Trigger word detection](https://github.com/ArmanBehnam/Courses/tree/master/Coursera/Sequence%20Models/Week%203/Trigger%20word%20detection)
  
My certificate is available [here](https://github.com/ArmanBehnam/Courses/blob/master/Coursera/Sequence%20Models/Coursera%20MFC297Q9JS65.png).

- 4.8 stars
- 25324 ratings
- 92,325 already enrolled

This course will teach you how to build models for natural language, audio, and other sequence data. Thanks to deep learning, sequence algorithms are working far better than just two years ago, and this is enabling numerous exciting applications in speech recognition, music synthesis, chatbots, machine translation, natural language understanding, and many others.

You will: - Understand how to build and train Recurrent Neural Networks (RNNs), and commonly-used variants such as GRUs and LSTMs. - Be able to apply sequence models to natural language problems, including text synthesis. - Be able to apply sequence models to audio applications, including speech recognition and music synthesis. This is the fifth and final course of the Deep Learning Specialization. deeplearning.ai is also partnering with the NVIDIA Deep Learning Institute (DLI) in Course 5, Sequence Models, to provide a programming assignment on Machine Translation with deep learning. You will have the opportunity to build a deep learning project with cutting-edge, industry-relevant content..

# THANK YOU
