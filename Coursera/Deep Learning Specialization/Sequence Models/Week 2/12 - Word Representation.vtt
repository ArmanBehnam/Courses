WEBVTT

1
00:00:00.790 --> 00:00:03.293
Hello, and welcome back.

2
00:00:03.293 --> 00:00:06.165
Last week, we learned about RNNs, GRUs, and LSTMs.

3
00:00:06.165 --> 00:00:11.240
In this week, you see how many of these ideas can be applied to NLP,

4
00:00:11.240 --> 00:00:13.105
to Natural Language Processing,

5
00:00:13.105 --> 00:00:14.810
which is one of the features of AI because it's

6
00:00:14.810 --> 00:00:17.820
really being revolutionized by deep learning.

7
00:00:17.820 --> 00:00:20.655
One of the key ideas you learn about is word embeddings,

8
00:00:20.655 --> 00:00:22.243
which is a way of representing words.

9
00:00:22.243 --> 00:00:26.150
The less your algorithms automatically understand analogies like that,

10
00:00:26.150 --> 00:00:28.090
man is to woman, as king is to queen,

11
00:00:28.090 --> 00:00:30.320
and many other examples.

12
00:00:30.320 --> 00:00:32.570
And through these ideas of word embeddings,

13
00:00:32.570 --> 00:00:35.060
you'll be able to build NPL applications,

14
00:00:35.060 --> 00:00:37.630
even with models the size of,

15
00:00:37.630 --> 00:00:40.550
usually of relatively small label training sets.

16
00:00:40.550 --> 00:00:41.945
Finally towards the end of the week,

17
00:00:41.945 --> 00:00:44.483
you'll see how to debias word embeddings.

18
00:00:44.483 --> 00:00:48.290
That's to reduce undesirable gender or

19
00:00:48.290 --> 00:00:52.778
ethnicity or other types of bias that learning algorithms can sometimes pick up.

20
00:00:52.778 --> 00:00:57.760
So with that, let's get started with a discussion on word representation.

21
00:00:57.760 --> 00:01:03.015
So far, we've been representing words using a vocabulary of words,

22
00:01:03.015 --> 00:01:08.700
and a vocabulary from the previous week might be say, 10,000 words.

23
00:01:08.700 --> 00:01:13.435
And we've been representing words using a one-hot vector.

24
00:01:13.435 --> 00:01:18.705
So for example, if man is word number 5391 in this dictionary,

25
00:01:18.705 --> 00:01:24.000
then you represent him with a vector with one in position 5391.

26
00:01:24.000 --> 00:01:31.315
And I'm also going to use O subscript 5391 to represent this factor,

27
00:01:31.315 --> 00:01:34.800
where O here stands for one-hot.

28
00:01:34.800 --> 00:01:38.890
And then, if woman is word number 9853,

29
00:01:38.890 --> 00:01:42.285
then you represent it with O subscript

30
00:01:42.285 --> 00:01:49.095
9853 which just has a one in position 9853 and zeros elsewhere.

31
00:01:49.095 --> 00:01:51.840
And then other words king, queen,

32
00:01:51.840 --> 00:01:56.730
apple, orange will be similarly represented with one-hot vector.

33
00:01:56.730 --> 00:02:00.600
One of the weaknesses of this representation is

34
00:02:00.600 --> 00:02:05.708
that it treats each word as a thing unto itself,

35
00:02:05.708 --> 00:02:10.210
and it doesn't allow an algorithm to easily generalize the cross words.

36
00:02:10.210 --> 00:02:13.970
For example, let's say you have a language model that has learned

37
00:02:13.970 --> 00:02:17.975
that when you see I want a glass of orange blank.

38
00:02:17.975 --> 00:02:19.665
Well, what do you think the next word will be?

39
00:02:19.665 --> 00:02:22.100
Very likely, it'll be juice.

40
00:02:22.100 --> 00:02:25.675
But even if the learning algorithm has learned that

41
00:02:25.675 --> 00:02:29.370
I want a glass of orange juice is a likely sentence,

42
00:02:29.370 --> 00:02:31.920
if it sees I want a glass of apple blank.

43
00:02:31.920 --> 00:02:35.160
As far as it knows the relationship between apple and

44
00:02:35.160 --> 00:02:40.555
orange is not any closer as the relationship between any of the other words man,

45
00:02:40.555 --> 00:02:42.220
woman, king, queen, and orange.

46
00:02:42.220 --> 00:02:45.630
And so, it's not easy for the learning algorithm to generalize

47
00:02:45.630 --> 00:02:49.161
from knowing that orange juice is a popular thing,

48
00:02:49.161 --> 00:02:55.515
to recognizing that apple juice might also be a popular thing or a popular phrase.

49
00:02:55.515 --> 00:03:02.210
And this is because the any product between any two different one-hot vector is zero.

50
00:03:02.210 --> 00:03:04.215
If you take any two vectors say,

51
00:03:04.215 --> 00:03:06.490
queen and king and any product of them,

52
00:03:06.490 --> 00:03:07.850
the end product is zero.

53
00:03:07.850 --> 00:03:12.335
If you take apple and orange and any product of them, the end product is zero.

54
00:03:12.335 --> 00:03:16.840
And you couldn't distance between any pair of these vectors is also the same.

55
00:03:16.840 --> 00:03:20.100
So it just doesn't know that somehow apple and orange are

56
00:03:20.100 --> 00:03:23.610
much more similar than king and orange or queen and orange.

57
00:03:23.610 --> 00:03:27.810
So, won't it be nice if instead of a one-hot presentation we

58
00:03:27.810 --> 00:03:32.100
can instead learn a featurized representation with each of these words,

59
00:03:32.100 --> 00:03:33.510
a man, woman, king, queen, apple,

60
00:03:33.510 --> 00:03:36.085
orange or really for every word in the dictionary,

61
00:03:36.085 --> 00:03:40.935
we could learn a set of features and values for each of them.

62
00:03:40.935 --> 00:03:43.455
So for example, each of these words,

63
00:03:43.455 --> 00:03:46.975
we want to know what is the gender associated with each of these things.

64
00:03:46.975 --> 00:03:51.915
So, if gender goes from minus one for male to plus one for female,

65
00:03:51.915 --> 00:03:54.925
then the gender associated with man might be minus one,

66
00:03:54.925 --> 00:03:57.090
for woman might be plus one.

67
00:03:57.090 --> 00:04:00.900
And then eventually, learning these things maybe for king you get minus 0.95,

68
00:04:00.900 --> 00:04:02.340
for queen plus 0.97,

69
00:04:02.340 --> 00:04:06.855
and for apple and orange sort of genderless.

70
00:04:06.855 --> 00:04:09.020
Another feature might be,

71
00:04:09.020 --> 00:04:11.095
well how royal are these things.

72
00:04:11.095 --> 00:04:12.690
And so the terms,

73
00:04:12.690 --> 00:04:15.750
man and woman are not really royal,

74
00:04:15.750 --> 00:04:18.650
so they might have feature values close to zero.

75
00:04:18.650 --> 00:04:21.930
Whereas king and queen are highly royal.

76
00:04:21.930 --> 00:04:25.230
And apple and orange are not really loyal.

77
00:04:25.230 --> 00:04:26.500
How about age?

78
00:04:26.500 --> 00:04:30.650
Well, man and woman doesn't connotes much about age.

79
00:04:30.650 --> 00:04:33.612
Maybe men and woman implies that they're adults,

80
00:04:33.612 --> 00:04:37.290
but maybe neither necessarily young nor old.

81
00:04:37.290 --> 00:04:40.005
So maybe values close to zero.

82
00:04:40.005 --> 00:04:44.415
Whereas kings and queens are always almost always adults.

83
00:04:44.415 --> 00:04:48.155
And apple and orange might be more neutral with respect to age.

84
00:04:48.155 --> 00:04:50.010
And then, another feature for here,

85
00:04:50.010 --> 00:04:51.565
is this is a food?

86
00:04:51.565 --> 00:04:53.689
Well, man is not a food,

87
00:04:53.689 --> 00:04:56.670
woman is not a food,

88
00:04:56.670 --> 00:04:58.480
neither are kings and queens,

89
00:04:58.480 --> 00:05:00.740
but apples and oranges are foods.

90
00:05:00.740 --> 00:05:04.670
And they can be many other features as well ranging from,

91
00:05:04.670 --> 00:05:06.915
what is the size of this?

92
00:05:06.915 --> 00:05:08.455
What is the cost?

93
00:05:08.455 --> 00:05:10.765
Is this something that is a live?

94
00:05:10.765 --> 00:05:12.544
Is this an action,

95
00:05:12.544 --> 00:05:14.725
or is this a noun, or is this a verb,

96
00:05:14.725 --> 00:05:16.050
or is it something else?

97
00:05:16.050 --> 00:05:20.290
And so on. So you can imagine coming up with many features.

98
00:05:20.290 --> 00:05:23.015
And for the sake of the illustration let's say,

99
00:05:23.015 --> 00:05:27.250
300 different features, and what that does is,

100
00:05:27.250 --> 00:05:29.885
it allows you to take this list of numbers,

101
00:05:29.885 --> 00:05:31.710
I've only written four here,

102
00:05:31.710 --> 00:05:34.942
but this could be a list of 300 numbers,

103
00:05:34.942 --> 00:05:40.505
that then becomes a 300 dimensional vector for representing the word man.

104
00:05:40.505 --> 00:05:45.100
And I'm going to use the notation e

105
00:05:45.100 --> 00:05:52.235
subscript 5391 to denote a representation like this.

106
00:05:52.235 --> 00:05:55.000
And similarly, this vector,

107
00:05:55.000 --> 00:05:58.290
this 300 dimensional vector or 300 dimensional vector like this,

108
00:05:58.290 --> 00:06:02.645
I would denote e9853

109
00:06:02.645 --> 00:06:07.210
to denote a 300 dimensional vector we could use to represent the word woman.

110
00:06:07.210 --> 00:06:11.060
And similarly, for the other examples here.

111
00:06:11.060 --> 00:06:17.200
Now, if you use this representation to represent the words orange and apple,

112
00:06:17.200 --> 00:06:23.335
then notice that the representations for orange and apple are now quite similar.

113
00:06:23.335 --> 00:06:27.280
Some of the features will differ because of the color of an orange,

114
00:06:27.280 --> 00:06:29.140
the color an apple, the taste,

115
00:06:29.140 --> 00:06:31.050
or some of the features would differ.

116
00:06:31.050 --> 00:06:32.200
But by a large,

117
00:06:32.200 --> 00:06:36.325
a lot of the features of apple and orange are actually the same,

118
00:06:36.325 --> 00:06:38.570
or take on very similar values.

119
00:06:38.570 --> 00:06:40.450
And so, this increases the odds of

120
00:06:40.450 --> 00:06:44.360
the learning algorithm that has figured out that orange juice is a thing,

121
00:06:44.360 --> 00:06:47.950
to also quickly figure out that apple juice is a thing.

122
00:06:47.950 --> 00:06:52.260
So this allows it to generalize better across different words.

123
00:06:52.260 --> 00:06:53.710
So over the next few videos,

124
00:06:53.710 --> 00:06:56.165
we'll find a way to learn words embeddings.

125
00:06:56.165 --> 00:06:59.495
We just need you to learn high dimensional feature vectors like these,

126
00:06:59.495 --> 00:07:05.515
that gives a better representation than one-hot vectors for representing different words.

127
00:07:05.515 --> 00:07:07.784
And the features we'll end up learning,

128
00:07:07.784 --> 00:07:13.720
won't have a easy to interpret interpretation like that component one is gender,

129
00:07:13.720 --> 00:07:14.820
component two is royal,

130
00:07:14.820 --> 00:07:16.870
component three is age and so on.

131
00:07:16.870 --> 00:07:20.900
Exactly what they're representing will be a bit harder to figure out.

132
00:07:20.900 --> 00:07:24.600
But nonetheless, the featurized representations we will learn,

133
00:07:24.600 --> 00:07:27.325
will allow an algorithm to quickly figure out that

134
00:07:27.325 --> 00:07:30.580
apple and orange are more similar than say,

135
00:07:30.580 --> 00:07:33.520
king and orange or queen and orange.

136
00:07:33.520 --> 00:07:35.530
If we're able to learn

137
00:07:35.530 --> 00:07:42.385
a 300 dimensional feature vector or 300 dimensional embedding for each words,

138
00:07:42.385 --> 00:07:44.830
one of the popular things to do is also to

139
00:07:44.830 --> 00:07:48.760
take this 300 dimensional data and embed it say,

140
00:07:48.760 --> 00:07:52.855
in a two dimensional space so that you can visualize them.

141
00:07:52.855 --> 00:07:55.900
And so, one common algorithm for doing this is

142
00:07:55.900 --> 00:08:02.100
the t-SNE algorithm due to Laurens van der Maaten and Geoff Hinton.

143
00:08:02.100 --> 00:08:04.950
And if you look at one of these embeddings,

144
00:08:04.950 --> 00:08:06.130
one of these representations,

145
00:08:06.130 --> 00:08:11.135
you find that words like man and woman tend to get grouped together,

146
00:08:11.135 --> 00:08:13.431
king and queen tend to get grouped together,

147
00:08:13.431 --> 00:08:17.125
and these are the people which tends to get grouped together.

148
00:08:17.125 --> 00:08:20.515
Those are animals who can get grouped together.

149
00:08:20.515 --> 00:08:21.670
Fruits will tend to be close to each other.

150
00:08:21.670 --> 00:08:23.080
Numbers like one, two, three, four,

151
00:08:23.080 --> 00:08:25.310
will be close to each other.

152
00:08:25.310 --> 00:08:31.720
And then, maybe the animate objects as whole will also tend to be grouped together.

153
00:08:31.720 --> 00:08:35.360
But you see plots like these sometimes on the internet to visualize

154
00:08:35.360 --> 00:08:40.020
some of these 300 or higher dimensional embeddings.

155
00:08:40.020 --> 00:08:42.945
And maybe this gives you a sense that,

156
00:08:42.945 --> 00:08:46.810
word embeddings algorithms like this can learn

157
00:08:46.810 --> 00:08:51.895
similar features for concepts that feel like they should be more related,

158
00:08:51.895 --> 00:08:56.860
as visualized by that concept that seem to you and me like they should be more similar,

159
00:08:56.860 --> 00:09:01.290
end up getting mapped to a more similar feature vectors.

160
00:09:01.290 --> 00:09:04.820
And these representations will use these sort of

161
00:09:04.820 --> 00:09:08.865
featurized representations in maybe a 300 dimensional space,

162
00:09:08.865 --> 00:09:10.565
these are called embeddings.

163
00:09:10.565 --> 00:09:13.125
And the reason we call them embeddings is,

164
00:09:13.125 --> 00:09:16.240
you can think of a 300 dimensional space.

165
00:09:16.240 --> 00:09:20.210
And again, they can't draw out here in two dimensional space because it's a 3D one.

166
00:09:20.210 --> 00:09:22.895
And what you do is you take every words like orange,

167
00:09:22.895 --> 00:09:26.795
and have a three dimensional feature vector so that word

168
00:09:26.795 --> 00:09:32.045
orange gets embedded to a point in this 300 dimensional space.

169
00:09:32.045 --> 00:09:38.015
And the word apple, gets embedded to a different point in this 300 dimensional space.

170
00:09:38.015 --> 00:09:41.000
And of course to visualize it, algorithms like t-SNE,

171
00:09:41.000 --> 00:09:43.040
map this to a much lower dimensional space,

172
00:09:43.040 --> 00:09:47.770
you can actually plot the 2D data and look at it.

173
00:09:47.770 --> 00:09:50.525
But that's what the term embedding comes from.

174
00:09:50.525 --> 00:09:54.425
Word embeddings has been one of the most important ideas in NLP,

175
00:09:54.425 --> 00:09:56.080
in Natural Language Processing.

176
00:09:56.080 --> 00:10:01.070
In this video, you saw why you might want to learn or use word embeddings.

177
00:10:01.070 --> 00:10:04.190
In the next video, let's take a deeper look at how you'll be able

178
00:10:04.190 --> 00:10:07.180
to use these algorithms, to build NLP algorithims.