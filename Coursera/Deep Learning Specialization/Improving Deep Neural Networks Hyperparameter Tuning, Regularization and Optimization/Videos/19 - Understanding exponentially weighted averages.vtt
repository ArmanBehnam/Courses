WEBVTT

1
00:00:00.000 --> 00:00:03.900
In the last video, we talked about exponentially weighted averages.

2
00:00:03.900 --> 00:00:06.345
This will turn out to be a key component of

3
00:00:06.345 --> 00:00:09.910
several optimization algorithms that you used to train your neural networks.

4
00:00:09.910 --> 00:00:12.330
So, in this video, I want to delve a little bit deeper

5
00:00:12.330 --> 00:00:15.930
into intuitions for what this algorithm is really doing.

6
00:00:15.930 --> 00:00:21.305
Recall that this is a key equation for implementing exponentially weighted averages.

7
00:00:21.305 --> 00:00:24.755
And so, if beta equals 0.9 you got the red line.

8
00:00:24.755 --> 00:00:26.390
If it was much closer to one,

9
00:00:26.390 --> 00:00:29.700
if it was 0.98, you get the green line.

10
00:00:29.700 --> 00:00:31.200
And it it's much smaller,

11
00:00:31.200 --> 00:00:34.470
maybe 0.5, you get the yellow line.

12
00:00:34.470 --> 00:00:37.110
Let's look a bit more than that to understand how

13
00:00:37.110 --> 00:00:40.220
this is computing averages of the daily temperature.

14
00:00:40.220 --> 00:00:41.935
So here's that equation again,

15
00:00:41.935 --> 00:00:48.330
and let's set beta equals 0.9 and write out a few equations that this corresponds to.

16
00:00:48.330 --> 00:00:50.970
So whereas, when you're implementing it you have T

17
00:00:50.970 --> 00:00:54.105
going from zero to one, to two to three,

18
00:00:54.105 --> 00:00:56.760
increasing values of T. To analyze it,

19
00:00:56.760 --> 00:01:00.740
I've written it with decreasing values of T. And this goes on.

20
00:01:00.740 --> 00:01:03.055
So let's take this first equation here,

21
00:01:03.055 --> 00:01:06.750
and understand what V100 really is.

22
00:01:06.750 --> 00:01:09.795
So V100 is going to be,

23
00:01:09.795 --> 00:01:11.850
let me reverse these two terms,

24
00:01:11.850 --> 00:01:15.195
it's going to be 0.1 times theta 100,

25
00:01:15.195 --> 00:01:19.620
plus 0.9 times whatever the value was on the previous day.

26
00:01:19.620 --> 00:01:21.055
Now, but what is V99?

27
00:01:21.055 --> 00:01:25.075
Well, we'll just plug it in from this equation.

28
00:01:25.075 --> 00:01:30.390
So this is just going to be 0.1 times theta 99,

29
00:01:30.390 --> 00:01:33.215
and again I've reversed these two terms,

30
00:01:33.215 --> 00:01:38.030
plus 0.9 times V98.

31
00:01:38.030 --> 00:01:39.485
But then what is V98?

32
00:01:39.485 --> 00:01:41.765
Well, you just get that from here.

33
00:01:41.765 --> 00:01:44.220
So you can just plug in here,

34
00:01:44.220 --> 00:01:47.875
0.1 times theta 98,

35
00:01:47.875 --> 00:01:52.560
plus 0.9 times V97, and so on.

36
00:01:52.560 --> 00:01:54.405
And if you multiply all of these terms out,

37
00:01:54.405 --> 00:02:00.060
you can show that V100 is 0.1 times theta 100 plus.

38
00:02:00.060 --> 00:02:02.552
Now, let's look at coefficient on theta 99,

39
00:02:02.552 --> 00:02:09.030
it's going to be 0.1 times 0.9, times theta 99.

40
00:02:09.030 --> 00:02:12.160
Now, let's look at the coefficient on theta 98,

41
00:02:12.160 --> 00:02:16.880
there's a 0.1 here times 0.9, times 0.9.

42
00:02:16.880 --> 00:02:18.565
So if we expand out the Algebra,

43
00:02:18.565 --> 00:02:26.295
this become 0.1 times 0.9 squared, times theta 98.

44
00:02:26.295 --> 00:02:28.260
And, if you keep expanding this out,

45
00:02:28.260 --> 00:02:32.315
you find that this becomes 0.1 times 0.9 cubed,

46
00:02:32.315 --> 00:02:34.920
theta 97 plus 0.1,

47
00:02:34.920 --> 00:02:37.440
times 0.9 to the fourth,

48
00:02:37.440 --> 00:02:41.800
times theta 96, plus dot dot dot.

49
00:02:41.800 --> 00:02:47.010
So this is really a way to sum and that's a weighted average of theta 100,

50
00:02:47.010 --> 00:02:49.680
which is the current days temperature and we're looking for

51
00:02:49.680 --> 00:02:53.730
a perspective of V100 which you calculate on the 100th day of the year.

52
00:02:53.730 --> 00:02:56.870
But those are sum of your theta 100,

53
00:02:56.870 --> 00:02:58.865
theta 99, theta 98,

54
00:02:58.865 --> 00:03:02.175
theta 97, theta 96, and so on.

55
00:03:02.175 --> 00:03:05.250
So one way to draw this in pictures would be if,

56
00:03:05.250 --> 00:03:08.880
let's say we have some number of days of temperature.

57
00:03:08.880 --> 00:03:14.610
So this is theta and this is T. So theta 100 will be sum value,

58
00:03:14.610 --> 00:03:17.095
then theta 99 will be sum value,

59
00:03:17.095 --> 00:03:19.360
theta 98, so these are,

60
00:03:19.360 --> 00:03:21.255
so this is T equals 100,

61
00:03:21.255 --> 00:03:23.070
99, 98, and so on,

62
00:03:23.070 --> 00:03:26.360
ratio of sum number of days of temperature.

63
00:03:26.360 --> 00:03:31.015
And what we have is then an exponentially decaying function.

64
00:03:31.015 --> 00:03:37.140
So starting from 0.1 to 0.9,

65
00:03:37.140 --> 00:03:41.630
times 0.1 to 0.9 squared,

66
00:03:41.630 --> 00:03:44.555
times 0.1, to and so on.

67
00:03:44.555 --> 00:03:47.150
So you have this exponentially decaying function.

68
00:03:47.150 --> 00:03:50.600
And the way you compute V100,

69
00:03:50.600 --> 00:03:55.760
is you take the element wise product between these two functions and sum it up.

70
00:03:55.760 --> 00:03:56.985
So you take this value,

71
00:03:56.985 --> 00:03:59.165
theta 100 times 0.1,

72
00:03:59.165 --> 00:04:05.770
times this value of theta 99 times 0.1 times 0.9,

73
00:04:05.770 --> 00:04:07.995
that's the second term and so on.

74
00:04:07.995 --> 00:04:10.170
So it's really taking the daily temperature,

75
00:04:10.170 --> 00:04:14.610
multiply with this exponentially decaying function, and then summing it up.

76
00:04:14.610 --> 00:04:17.390
And this becomes your V100.

77
00:04:17.390 --> 00:04:19.165
It turns out that,

78
00:04:19.165 --> 00:04:21.090
up to details that are for later.

79
00:04:21.090 --> 00:04:22.655
But all of these coefficients,

80
00:04:22.655 --> 00:04:27.335
add up to one or add up to very close to one,

81
00:04:27.335 --> 00:04:31.670
up to a detail called bias correction which we'll talk about in the next video.

82
00:04:31.670 --> 00:04:35.225
But because of that, this really is an exponentially weighted average.

83
00:04:35.225 --> 00:04:37.595
And finally, you might wonder,

84
00:04:37.595 --> 00:04:41.210
how many days temperature is this averaging over.

85
00:04:41.210 --> 00:04:46.400
Well, it turns out that 0.9 to the power of 10,

86
00:04:46.400 --> 00:04:52.085
is about 0.35 and this turns out to be about one over E,

87
00:04:52.085 --> 00:04:54.410
one of the base of natural algorithms.

88
00:04:54.410 --> 00:04:59.030
And, more generally, if you have one minus epsilon,

89
00:04:59.030 --> 00:05:00.200
so in this example,

90
00:05:00.200 --> 00:05:01.880
epsilon would be 0.1,

91
00:05:01.880 --> 00:05:07.250
so if this was 0.9, then one minus epsilon to the one over epsilon.

92
00:05:07.250 --> 00:05:08.720
This is about one over E,

93
00:05:08.720 --> 00:05:12.065
this about 0.34, 0.35.

94
00:05:12.065 --> 00:05:14.735
And so, in other words,

95
00:05:14.735 --> 00:05:19.610
it takes about 10 days for the height of this to

96
00:05:19.610 --> 00:05:24.680
decay to around 1/3 already one over E of the peak.

97
00:05:24.680 --> 00:05:25.915
So it's because of this,

98
00:05:25.915 --> 00:05:31.325
that when beta equals 0.9, we say that,

99
00:05:31.325 --> 00:05:35.090
this is as if you're computing

100
00:05:35.090 --> 00:05:40.355
an exponentially weighted average that focuses on just the last 10 days temperature.

101
00:05:40.355 --> 00:05:43.940
Because it's after 10 days that the weight decays

102
00:05:43.940 --> 00:05:48.380
to less than about a third of the weight of the current day.

103
00:05:48.380 --> 00:05:53.300
Whereas, in contrast, if beta was equal to 0.98,

104
00:05:53.300 --> 00:05:59.320
then, well, what do you need 0.98 to the power of in order for this to really small?

105
00:05:59.320 --> 00:06:04.310
Turns out that 0.98 to the power of 50 will be approximately

106
00:06:04.310 --> 00:06:06.710
equal to one over E. So the way to be pretty

107
00:06:06.710 --> 00:06:09.380
big will be bigger than one over E for the first 50 days,

108
00:06:09.380 --> 00:06:11.840
and then they'll decay quite rapidly over that.

109
00:06:11.840 --> 00:06:14.780
So intuitively, this is the hard and fast thing,

110
00:06:14.780 --> 00:06:18.860
you can think of this as averaging over about 50 days temperature.

111
00:06:18.860 --> 00:06:20.335
Because, in this example,

112
00:06:20.335 --> 00:06:22.290
to use the notation here on the left,

113
00:06:22.290 --> 00:06:25.530
it's as if epsilon is equal to 0.02,

114
00:06:25.530 --> 00:06:27.750
so one over epsilon is 50.

115
00:06:27.750 --> 00:06:30.080
And this, by the way, is how we got the formula,

116
00:06:30.080 --> 00:06:35.150
that we're averaging over one over one minus beta or so days.

117
00:06:35.150 --> 00:06:39.915
Right here, epsilon replace a row of 1 minus beta.

118
00:06:39.915 --> 00:06:42.350
It tells you, up to some constant roughly how

119
00:06:42.350 --> 00:06:45.148
many days temperature you should think of this as averaging over.

120
00:06:45.148 --> 00:06:48.175
But this is just a rule of thumb for how to think about it,

121
00:06:48.175 --> 00:06:51.290
and it isn't a formal mathematical statement.

122
00:06:51.290 --> 00:06:54.290
Finally, let's talk about how you actually implement this.

123
00:06:54.290 --> 00:06:57.760
Recall that we start over V0 initialized as zero,

124
00:06:57.760 --> 00:06:59.570
then compute V one on the first day,

125
00:06:59.570 --> 00:07:01.605
V2, and so on.

126
00:07:01.605 --> 00:07:02.630
Now, to explain the algorithm,

127
00:07:02.630 --> 00:07:05.990
it was useful to write down V0,

128
00:07:05.990 --> 00:07:09.480
V1, V2, and so on as distinct variables.

129
00:07:09.480 --> 00:07:11.835
But if you're implementing this in practice,

130
00:07:11.835 --> 00:07:15.774
this is what you do: you initialize V to be called to zero,

131
00:07:15.774 --> 00:07:17.555
and then on day one,

132
00:07:17.555 --> 00:07:21.105
you would set V equals beta,

133
00:07:21.105 --> 00:07:25.405
times V, plus one minus beta, times theta one.

134
00:07:25.405 --> 00:07:27.780
And then on the next day, you add update V,

135
00:07:27.780 --> 00:07:31.805
to be called to beta V,

136
00:07:31.805 --> 00:07:33.820
plus 1 minus beta,

137
00:07:33.820 --> 00:07:35.985
theta 2, and so on.

138
00:07:35.985 --> 00:07:41.282
And some of it uses notation V subscript theta to denote

139
00:07:41.282 --> 00:07:47.115
that V is computing this exponentially weighted average of the parameter theta.

140
00:07:47.115 --> 00:07:49.690
So just to say this again but for a new format,

141
00:07:49.690 --> 00:07:52.095
you set V theta equals zero,

142
00:07:52.095 --> 00:07:55.715
and then, repeatedly, have one each day,

143
00:07:55.715 --> 00:08:02.314
you would get next theta T, and then set to V,

144
00:08:02.314 --> 00:08:05.140
theta gets updated as beta,

145
00:08:05.140 --> 00:08:07.210
times the old value of V theta,

146
00:08:07.210 --> 00:08:08.750
plus one minus beta,

147
00:08:08.750 --> 00:08:12.045
times the current value of V theta.

148
00:08:12.045 --> 00:08:15.440
So one of the advantages of this exponentially weighted average formula,

149
00:08:15.440 --> 00:08:17.140
is that it takes very little memory.

150
00:08:17.140 --> 00:08:21.175
You just need to keep just one row number in computer memory,

151
00:08:21.175 --> 00:08:26.965
and you keep on overwriting it with this formula based on the latest values that you got.

152
00:08:26.965 --> 00:08:29.590
And it's really this reason, the efficiency,

153
00:08:29.590 --> 00:08:33.340
it just takes up one line of code basically and just

154
00:08:33.340 --> 00:08:34.690
storage and memory for

155
00:08:34.690 --> 00:08:38.320
a single row number to compute this exponentially weighted average.

156
00:08:38.320 --> 00:08:40.195
It's really not the best way,

157
00:08:40.195 --> 00:08:42.805
not the most accurate way to compute an average.

158
00:08:42.805 --> 00:08:44.920
If you were to compute a moving window,

159
00:08:44.920 --> 00:08:47.770
where you explicitly sum over the last 10 days,

160
00:08:47.770 --> 00:08:51.550
the last 50 days temperature and just divide by 10 or divide by 50,

161
00:08:51.550 --> 00:08:53.320
that usually gives you a better estimate.

162
00:08:53.320 --> 00:08:55.265
But the disadvantage of that,

163
00:08:55.265 --> 00:08:57.550
of explicitly keeping all the temperatures around and

164
00:08:57.550 --> 00:09:00.190
sum of the last 10 days is it requires more memory,

165
00:09:00.190 --> 00:09:03.990
and it's just more complicated to implement and is computationally more expensive.

166
00:09:03.990 --> 00:09:07.885
So for things, we'll see some examples on the next few videos,

167
00:09:07.885 --> 00:09:12.130
where you need to compute averages of a lot of variables.

168
00:09:12.130 --> 00:09:15.625
This is a very efficient way to do so both from computation

169
00:09:15.625 --> 00:09:19.840
and memory efficiency point of view which is why it's used in a lot of machine learning.

170
00:09:19.840 --> 00:09:24.280
Not to mention that there's just one line of code which is, maybe, another advantage.

171
00:09:24.280 --> 00:09:28.570
So, now, you know how to implement exponentially weighted averages.

172
00:09:28.570 --> 00:09:30.160
There's one more technical detail that's worth for you knowing

173
00:09:30.160 --> 00:09:32.965
about called bias correction.

174
00:09:32.965 --> 00:09:35.365
Let's see that in the next video, and then after that,

175
00:09:35.365 --> 00:09:37.420
you will use this to build

176
00:09:37.420 --> 00:09:41.450
a better optimization algorithm than the straight forward create