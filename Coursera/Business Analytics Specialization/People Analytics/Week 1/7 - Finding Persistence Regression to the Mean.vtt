WEBVTT

1
00:00:00.520 --> 00:00:03.270
In that extended example we saw

2
00:00:03.270 --> 00:00:06.800
the value of doing good analytics
with these performance measures.

3
00:00:06.800 --> 00:00:10.650
What first appeared to be significant
differences in skill turned out to be

4
00:00:10.650 --> 00:00:12.160
purely chance.

5
00:00:12.160 --> 00:00:15.120
And, that really emphasises
the importance of persistence.

6
00:00:15.120 --> 00:00:18.090
You need to find ways of testing for
persistence.

7
00:00:18.090 --> 00:00:21.030
So, in that case,
we just looked at split sample.

8
00:00:21.030 --> 00:00:26.230
How performance varied in one year, and
then how it varied in the next year.

9
00:00:26.230 --> 00:00:29.210
Finding ways to do that is
one of the most fundamental

10
00:00:29.210 --> 00:00:32.560
ways you can parse signal from noise.

11
00:00:32.560 --> 00:00:37.400
We're gonna focus on four additional
issues for the rest of the module.

12
00:00:37.400 --> 00:00:40.910
Regression to the mean, sample size,
signal independence, and

13
00:00:40.910 --> 00:00:42.560
process versus outcome.

14
00:00:42.560 --> 00:00:46.310
These are all important concepts to
have in mind as you dig into your data.

15
00:00:46.310 --> 00:00:47.570
And they are also

16
00:00:48.580 --> 00:00:52.710
issues that we tend to have if we
only reason about data intuitively.

17
00:00:52.710 --> 00:00:57.350
So there are issues that data can improve,
analytics can improve.

18
00:00:57.350 --> 00:01:01.500
But analytics aren't apparent, you can
still make these mistakes, even with data.

19
00:01:01.500 --> 00:01:03.270
So let's drop into them.

20
00:01:03.270 --> 00:01:08.310
The first is regression to the mean,
and want to start that

21
00:01:08.310 --> 00:01:14.340
with a very simple model of performance
where you can think of performance terms

22
00:01:14.340 --> 00:01:19.100
of real tendency plus luck, and we've
been talking about this a little bit.

23
00:01:19.100 --> 00:01:23.890
We can formalize it, and don't get
too put off by the baby math here but

24
00:01:23.890 --> 00:01:25.140
in formal terms.

25
00:01:25.140 --> 00:01:30.930
You can think of performance,
y as a function of x true ability and

26
00:01:30.930 --> 00:01:35.360
e some error,
some randomly distributed error around 0.

27
00:01:35.360 --> 00:01:39.720
Now what does that mean for
when we sample on extreme performance?

28
00:01:39.720 --> 00:01:42.819
What underlies extreme success and
failure?

29
00:01:43.900 --> 00:01:46.660
What is that, if that's the model of
the world and everything that we've been

30
00:01:46.660 --> 00:01:51.000
saying so far says it is, that there's
some noise in these performance measures,

31
00:01:51.000 --> 00:01:53.970
what does it mean when we
sample on extreme performance?

32
00:01:53.970 --> 00:01:59.190
Well it means that extreme success
suggests that the person might

33
00:01:59.190 --> 00:02:03.130
in fact have superior ability or tried
very hard but also that they got lucky.

34
00:02:03.130 --> 00:02:05.160
The error was positive.

35
00:02:05.160 --> 00:02:09.180
And conversely extreme failure
perhaps means inferior ability or

36
00:02:09.180 --> 00:02:14.100
that they did not try very ord, but also
negative era or that they got unlucky.

37
00:02:14.100 --> 00:02:18.270
We can be sure that as we sample very
extremely on performance measure.

38
00:02:18.270 --> 00:02:20.700
A noisy performance measure,
and they're all noisy

39
00:02:20.700 --> 00:02:25.540
we can be sure that when they go to
the extremes we get extreme error as well.

40
00:02:25.540 --> 00:02:27.650
So what are the consequences of that?

41
00:02:27.650 --> 00:02:29.600
There's one very important consequence and

42
00:02:29.600 --> 00:02:33.650
that is in subsequence periods,
error won't be negative again.

43
00:02:33.650 --> 00:02:35.050
It will regress to the mean.

44
00:02:35.050 --> 00:02:36.210
You'd expect it to be zero.

45
00:02:36.210 --> 00:02:37.840
Error is by definition zero.

46
00:02:37.840 --> 00:02:40.920
And if you've got very
positive error in one period,

47
00:02:40.920 --> 00:02:43.570
you would expect less error
in the following period.

48
00:02:43.570 --> 00:02:46.170
This is a notion called
regression to the mean and

49
00:02:46.170 --> 00:02:50.150
it's one of the most important
notions in performance evaluation.

50
00:02:50.150 --> 00:02:51.700
So, an example,

51
00:02:51.700 --> 00:02:57.280
there was a study a few years ago of
mutual fund performance in the 1990s.

52
00:02:57.280 --> 00:03:02.985
So the study divided the 1990s
into two halves, 1990-1994 and

53
00:03:02.985 --> 00:03:07.920
then 1995-1999 and they looked at the top
ten performing funds from the first

54
00:03:07.920 --> 00:03:13.340
half of the decade and here I'll show
them to you, we anonimized them,

55
00:03:13.340 --> 00:03:19.790
this is just supposed funds a through j,
and their performance in the early 1990s.

56
00:03:19.790 --> 00:03:25.560
There were 283 funds in this study, these
are only the top 10 performing funds.

57
00:03:25.560 --> 00:03:30.720
Then they did two things they go and
ask how do these

58
00:03:30.720 --> 00:03:35.260
funds perform in subsequent years, and
they did an interesting thing in between,

59
00:03:35.260 --> 00:03:40.530
they ask people what do they predict
happened in the new few years.

60
00:03:40.530 --> 00:03:45.100
What do they think performance will be
realized in the second half of the decade.

61
00:03:45.100 --> 00:03:48.220
So here are the predictions,
the estimations,

62
00:03:48.220 --> 00:03:49.279
from the people that they asked.

63
00:03:51.550 --> 00:03:55.910
They didn't think the top performing firm,
A would again be the top performing firm,

64
00:03:55.910 --> 00:03:57.530
they though maybe 10th.

65
00:03:57.530 --> 00:03:59.500
And so on down the list.

66
00:03:59.500 --> 00:04:03.500
E, which is the 5th performing firm
they thought well, maybe 44th.

67
00:04:03.500 --> 00:04:07.790
And so you can see that they didn't
expect the firms to be as good, but

68
00:04:07.790 --> 00:04:09.579
they expected some regression to the mean.

69
00:04:11.130 --> 00:04:13.840
Then they looked at
what actually happened.

70
00:04:14.950 --> 00:04:16.180
What actually happened?

71
00:04:16.180 --> 00:04:17.650
It ranged from 129th, 21st, 54th.

72
00:04:17.650 --> 00:04:21.320
The interesting thing is that on average,

73
00:04:21.320 --> 00:04:26.730
the firms performed, their rank was 142.5.

74
00:04:26.730 --> 00:04:29.070
What is the significance of 142.5?

75
00:04:29.070 --> 00:04:33.270
It's half of the total number
of firms in the study.

76
00:04:33.270 --> 00:04:39.010
In other words, the average performance of
the top ten firms in the second period,

77
00:04:39.010 --> 00:04:43.260
the second half of the 90s,
was perfectly average for this sample.

78
00:04:43.260 --> 00:04:44.820
They regressed entirely.

79
00:04:44.820 --> 00:04:47.140
The top ten mutual funds
in the top half of the 90s,

80
00:04:47.140 --> 00:04:52.780
the early 90s, regressed entirely to
the mean in the second half of the 90s.

81
00:04:52.780 --> 00:04:57.260
If that's the case,
what does that say about how much skill

82
00:04:57.260 --> 00:05:01.809
versus luck was involved in how those
firms did, in the first half of the 90s?

83
00:05:03.090 --> 00:05:05.100
If they regress all the way to
the mean in the second period,

84
00:05:05.100 --> 00:05:07.470
it suggests that there was no skill.

85
00:05:07.470 --> 00:05:08.730
That the differences that we saw,

86
00:05:08.730 --> 00:05:13.250
and there are huge consequences to those
differences because we know that new fund

87
00:05:13.250 --> 00:05:18.710
flow to successful funds,
were in fact entirely based on luck.

88
00:05:18.710 --> 00:05:20.320
So, there are many other examples.

89
00:05:20.320 --> 00:05:22.350
Danny Conium the Nobel
prize winner Danny Conium,

90
00:05:22.350 --> 00:05:25.319
it gives a famous example of being
an officer in the Israeli Air Force.

91
00:05:26.360 --> 00:05:28.970
He was studying the officer
in the Israeli Air Force.

92
00:05:28.970 --> 00:05:30.920
This was early in Common's career.

93
00:05:30.920 --> 00:05:33.920
And the officer told him,
"Punishment is more effective than praise.

94
00:05:33.920 --> 00:05:36.330
Whenever I punish a pilot
after a really poor flight,

95
00:05:36.330 --> 00:05:38.250
I see better performance the next time.

96
00:05:38.250 --> 00:05:40.560
Whenever I praise a pilot
after an excellent flight,

97
00:05:40.560 --> 00:05:42.640
I see worse performance the next time.

98
00:05:42.640 --> 00:05:45.590
Therefore, it must be that punishment
is more effective than praise.

99
00:05:45.590 --> 00:05:47.576
What's a more parsimonious explanation?

100
00:05:47.576 --> 00:05:51.890
The more parts explanations that there's
a little chance involved with whether

101
00:05:51.890 --> 00:05:55.000
a pilot has a good performance
a good flight, or a bad flight.

102
00:05:56.180 --> 00:05:59.690
And after a good flight if there's some
chance involved there you would expect

103
00:05:59.690 --> 00:06:02.700
that the following flight wouldn't
be as good and conversely.

104
00:06:02.700 --> 00:06:05.760
After a bad flight, if there is some
chance involved, you would expect,

105
00:06:05.760 --> 00:06:09.970
you would predict that the next flight,
would on average be better.

106
00:06:09.970 --> 00:06:13.780
This is exactly why we have to be so
careful about regression to the mean.

107
00:06:13.780 --> 00:06:18.110
We have the wrong model of the world if we
don't appreciate regression to the mean.

108
00:06:18.110 --> 00:06:22.400
We walk around like the Israeli Airforce
Officer who believe that it was all about

109
00:06:22.400 --> 00:06:27.320
praise and punishment, as opposed to
merely statistical regression to the mean.

110
00:06:27.320 --> 00:06:28.450
There's another example.

111
00:06:28.450 --> 00:06:31.370
We're not gonna pick on
Israeli Air Force officers.

112
00:06:31.370 --> 00:06:35.760
One comes from Tom Peters,
from the original business book.

113
00:06:35.760 --> 00:06:39.400
Peters and Waterman were
McKinsey consultants, no less.

114
00:06:39.400 --> 00:06:40.220
And they did a study.

115
00:06:40.220 --> 00:06:41.730
And it began as an internal study.

116
00:06:41.730 --> 00:06:45.410
And they eventually published
it as a hugely best selling book

117
00:06:45.410 --> 00:06:49.890
on what determines
excellence in companies.

118
00:06:49.890 --> 00:06:54.450
They selected 43 high performing firms and
tried to learn what they could

119
00:06:54.450 --> 00:06:58.029
about business practices
from these top 43 firms.

120
00:06:59.110 --> 00:07:04.170
But subsequently if you folks evaluated
the performance of those 43 firms and

121
00:07:04.170 --> 00:07:05.310
what do they find?

122
00:07:05.310 --> 00:07:09.440
Five years later, there were still
some excellent companies and

123
00:07:09.440 --> 00:07:13.880
there were some that were solid but
not exactly the top of their industries.

124
00:07:13.880 --> 00:07:16.850
And then there were quite a few in
weakened positions and there were even

125
00:07:16.850 --> 00:07:21.830
some from the supposed 43 excellent
companies who were fully troubled.

126
00:07:21.830 --> 00:07:26.880
Now this is exactly what you'd expect from
regression to the mean and that suggests

127
00:07:26.880 --> 00:07:31.540
that sample that Peters and Waterman had
grabbed as supposedly excellent firms.

128
00:07:31.540 --> 00:07:35.450
They grabbed them perhaps they were
on average a little bit better, but

129
00:07:35.450 --> 00:07:39.040
they had necessarily been lucky
to make it into that sample.

130
00:07:39.040 --> 00:07:42.930
To be called the most successful of
43 firms in the world essentially.

131
00:07:42.930 --> 00:07:45.480
They were necessarily lucky and
in subsequent periods,

132
00:07:45.480 --> 00:07:47.530
they're not gonna have luck
break their direction.

133
00:07:48.740 --> 00:07:53.590
So this is something that you'll see any
time you sample based on extreme values.

134
00:07:53.590 --> 00:07:57.380
That if you sample on one attribute,
any other attribute that's not

135
00:07:57.380 --> 00:08:00.620
perfectly related will tend to
be closer to the mean value.

136
00:08:00.620 --> 00:08:02.840
So we've been talking about
performance at points in time.

137
00:08:02.840 --> 00:08:05.750
If you sample on extreme
performance at one time period.

138
00:08:05.750 --> 00:08:07.560
The subsequent time period
won't be as extreme,

139
00:08:07.560 --> 00:08:10.830
whether you sample an extremely good or
extremely bad.

140
00:08:10.830 --> 00:08:15.490
But it can also be attributes within
an individual or within an organization.

141
00:08:15.490 --> 00:08:19.020
If you sample, say,
a person's running speed, and

142
00:08:19.020 --> 00:08:21.130
then look at what their
language ability is.

143
00:08:21.130 --> 00:08:22.860
These things are imperfectly related,
right?

144
00:08:22.860 --> 00:08:25.730
So if you ever looked
at the fastest runners

145
00:08:25.730 --> 00:08:28.640
how would you expect them to perform
on some language ability test?

146
00:08:28.640 --> 00:08:30.280
They wouldn't be as high.

147
00:08:30.280 --> 00:08:33.240
The fastest runners will,
almost by definition,

148
00:08:33.240 --> 00:08:36.940
will not necessarily be the people
with the best language ability.

149
00:08:36.940 --> 00:08:39.830
But that's not because there's some
inverse relationship between language and

150
00:08:39.830 --> 00:08:40.820
running ability.

151
00:08:40.820 --> 00:08:44.830
It's that these two traits are simply
imperfectly correlated, and so

152
00:08:44.830 --> 00:08:48.460
when you sample on the extreme you
have to expect regression to the mean

153
00:08:48.460 --> 00:08:49.340
on any other attribute.

154
00:08:50.420 --> 00:08:54.820
So we could spend a day on
regression to the mean effect.

155
00:08:54.820 --> 00:08:58.870
There aren't many concepts that are more
important in understanding the world,

156
00:08:58.870 --> 00:09:00.260
than regression to the mean.

157
00:09:00.260 --> 00:09:02.280
We could spend hours on this.

158
00:09:02.280 --> 00:09:05.900
And I would be very happy if you walked
away from this course with only two or

159
00:09:05.900 --> 00:09:07.820
three ideas, if this is one of them.

160
00:09:07.820 --> 00:09:11.330
Because it's gonna help your
reasoning about the world.

161
00:09:11.330 --> 00:09:12.350
Why is this so hard?

162
00:09:12.350 --> 00:09:14.200
Why is this such a hard concept to stay?

163
00:09:14.200 --> 00:09:15.470
To live?

164
00:09:15.470 --> 00:09:17.210
Well there are a few things
that get in the way.

165
00:09:17.210 --> 00:09:19.450
Among others, we have this outcome bias.

166
00:09:19.450 --> 00:09:22.290
I mentioned it with Hershey and
Barron, referenced Hershey and Barron.

167
00:09:22.290 --> 00:09:24.530
They're the ones that came up
with this study originally.

168
00:09:24.530 --> 00:09:28.280
We tend to believe that good things
happen to people who worked hard.

169
00:09:28.280 --> 00:09:30.660
Bad things happen to
people that worked badly.

170
00:09:30.660 --> 00:09:33.020
And we draw too strong
an inference based on this.

171
00:09:33.020 --> 00:09:38.520
We tend to judge decisions and
people by outcomes and not by process.

172
00:09:38.520 --> 00:09:43.260
This is a real problem and
it gets in the way of our

173
00:09:43.260 --> 00:09:47.750
understanding of this regression to
the mean framework for the world.

174
00:09:47.750 --> 00:09:48.310
Two others.

175
00:09:48.310 --> 00:09:49.860
One is hindsight bias.

176
00:09:49.860 --> 00:09:53.600
Once we've seen something
occur we have a hard time

177
00:09:53.600 --> 00:09:56.230
appreciating that we didn't
anticipate it occurring.

178
00:09:56.230 --> 00:09:57.570
We, in fact,

179
00:09:57.570 --> 00:10:01.750
often misbelieve that we anticipated
that that's exactly what would happen.

180
00:10:01.750 --> 00:10:03.720
We show hindsight bias and again,

181
00:10:03.720 --> 00:10:08.360
if that's the way we reason about
what happens, then we're not gonna

182
00:10:08.360 --> 00:10:12.960
appreciate that what happens next could
possibly be just regression to the mean.

183
00:10:14.370 --> 00:10:15.930
And finally narrative seeking.

184
00:10:15.930 --> 00:10:18.940
We want to make sense of the world,
we want to connect the dots,

185
00:10:18.940 --> 00:10:24.350
we came to believe things better
we can tell a causal story between

186
00:10:24.350 --> 00:10:27.720
what took place at time one and
what took place at time two.

187
00:10:27.720 --> 00:10:30.300
And if we can tell a causal story, then

188
00:10:30.300 --> 00:10:34.210
we actually have a great confidence in
our ability to predict what happens next.

189
00:10:34.210 --> 00:10:38.140
We seek these stories as opposed to what
I've been telling you which is this dry,

190
00:10:38.140 --> 00:10:40.380
statistical reason for why things happen.

191
00:10:40.380 --> 00:10:41.640
We seek stories.

192
00:10:41.640 --> 00:10:44.800
And that again gets in the way
of our understanding of

193
00:10:44.800 --> 00:10:48.630
the statistical processes that
actually drive what's going on.

194
00:10:48.630 --> 00:10:50.670
So in short we make sense of the past.

195
00:10:50.670 --> 00:10:53.500
We are sense making animals and
we make sense of the past.

196
00:10:53.500 --> 00:10:58.010
And there's not a lot sense to be had for
merely regression to the mean, but

197
00:10:58.010 --> 00:11:01.040
it's going to get in our way of
predicting what happens next.

198
00:11:01.040 --> 00:11:03.510
We try to find stories
that connect all the dots.

199
00:11:03.510 --> 00:11:09.490
And we, by doing that, give chance
too small a role in those stories.

200
00:11:09.490 --> 00:11:14.370
So there was an internet mean that
captures this well a year or two ago

201
00:11:14.370 --> 00:11:18.110
where, if this is knowledge distributed
in your experience in the past.

202
00:11:18.110 --> 00:11:19.820
This is knowledge you might have.

203
00:11:19.820 --> 00:11:23.900
And with that knowledge, perhaps you can
add some experience and start connecting

204
00:11:23.900 --> 00:11:27.290
the dots, drawing some lines,
create something from that knowledge.

205
00:11:27.290 --> 00:11:27.790
That's good.

206
00:11:27.790 --> 00:11:29.500
That's what we want experience to do.

207
00:11:29.500 --> 00:11:34.270
But then, sometimes we're inclined to do
this which is get a little too creative

208
00:11:34.270 --> 00:11:40.680
and over fit those lines, and we turn what
should be a pretty straight grid, pretty

209
00:11:40.680 --> 00:11:45.880
parsimonious connections into something
that is unlikely to replicate in the future.

210
00:11:45.880 --> 00:11:49.630
It might be a very satisfying
interpretation of the past but

211
00:11:49.630 --> 00:11:52.830
it's over fit, and
an over fit interpretation of the past is

212
00:11:52.830 --> 00:11:55.200
going to make very bad
predictions about the future.