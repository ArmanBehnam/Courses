WEBVTT

1
00:00:00.810 --> 00:00:05.570
We've talked a lot about analytics in this
course and that's the nature of it and

2
00:00:05.570 --> 00:00:08.130
that's the heart of it and
that's what we wanted to emphasize.

3
00:00:08.130 --> 00:00:13.150
But it would be silly and
unwise of us to not emphasize

4
00:00:13.150 --> 00:00:16.070
the organizational challenges
associated with analytics.

5
00:00:16.070 --> 00:00:19.689
I'd go even farther and
claim that effective people analytics.

6
00:00:21.020 --> 00:00:24.695
Is more of an organizational challenge
than an analytics challenge.

7
00:00:24.695 --> 00:00:26.720
So while we emphasize techniques and

8
00:00:26.720 --> 00:00:31.430
principles associated with analytics,
let's leave you with some techniques and

9
00:00:31.430 --> 00:00:34.990
principles associated with
the organizational challenge.

10
00:00:34.990 --> 00:00:39.550
So the main prescription will flow
from the simple idea, one dominant

11
00:00:39.550 --> 00:00:43.750
theme in talking with firms and talking
with the analyst in firms, and that theme

12
00:00:43.750 --> 00:00:47.820
is no black boxes, but we're going to
unpack that and tell you what we mean.

13
00:00:47.820 --> 00:00:51.970
The specific prescriptions that
come from that no black boxes theme

14
00:00:51.970 --> 00:00:56.730
are to be transparent,
to embed yourself, and to share control.

15
00:00:56.730 --> 00:01:01.270
So, we'll unpack each of those to send you
out with some tools you can use on making

16
00:01:01.270 --> 00:01:05.760
sure that you're not just a good analyst
that you're an effective analyst.

17
00:01:05.760 --> 00:01:08.290
So, first be transparent.

18
00:01:08.290 --> 00:01:11.450
So we know quite a bit about the way

19
00:01:11.450 --> 00:01:14.820
decision making is received by those
who are affected by decisions.

20
00:01:14.820 --> 00:01:17.320
There's a long literature
now on procedural fairness,

21
00:01:17.320 --> 00:01:20.300
Joel Brockner has been one of
the leading researchers on that.

22
00:01:20.300 --> 00:01:21.520
And this article, for example,

23
00:01:21.520 --> 00:01:24.890
in the Harvard Business Review
he covers the elements

24
00:01:24.890 --> 00:01:29.300
involved with procedural fairness, and
transparency is one of the main themes.

25
00:01:29.300 --> 00:01:34.620
People are more comfortable with processes
when it is transparent, what is going on.

26
00:01:34.620 --> 00:01:37.920
An organization that's taken
that to heart is Google.

27
00:01:37.920 --> 00:01:40.920
It's one of the main themes in
a recent book by Laszlo Bock,

28
00:01:40.920 --> 00:01:44.980
the head of people operations at Google,
who emphasizes it throughout And

29
00:01:44.980 --> 00:01:47.580
it's critical to their
work on Google Analytics.

30
00:01:47.580 --> 00:01:52.820
An example of the extent to which Google
takes transparency seriously is their

31
00:01:52.820 --> 00:01:58.040
TGIF, their weekly TGIF, which oddly takes
place on Thursday, in a very Google way.

32
00:01:58.040 --> 00:02:01.120
But every Thursday they have a gathering,

33
00:02:01.120 --> 00:02:05.120
originally it was with the two founders,
and often the founders are still there.

34
00:02:05.120 --> 00:02:06.700
Sometimes it's the CEO.

35
00:02:06.700 --> 00:02:09.950
When those guys can't make it at
some very senior executive and

36
00:02:09.950 --> 00:02:13.450
all the employees that can make it
are crowded into one of their cafeterias,

37
00:02:13.450 --> 00:02:18.340
they watch by remotes around the world.

38
00:02:18.340 --> 00:02:20.250
And they can ask the CEOs, the founders,

39
00:02:20.250 --> 00:02:22.030
the senior executives,
anything they want to.

40
00:02:22.030 --> 00:02:25.960
And they do ask all kinds of things,
and the guys stand there,

41
00:02:25.960 --> 00:02:29.460
the women stand there, and they take those
questions, and they give responses, and

42
00:02:29.460 --> 00:02:32.160
it breeds a culture of transparency.

43
00:02:32.160 --> 00:02:37.268
And it emphasizes
the importance the organization

44
00:02:37.268 --> 00:02:44.110
places on transparency and that is
something they believe has helped them

45
00:02:44.110 --> 00:02:47.860
to use analytics more successfully in the
organization because people trust them.

46
00:02:47.860 --> 00:02:49.330
They understand what's going on.

47
00:02:49.330 --> 00:02:54.740
They're more willing to embrace the
analytics that drive the people decisions.

48
00:02:56.530 --> 00:03:01.570
A second prescription that comes
out in this no black boxes theme

49
00:03:01.570 --> 00:03:03.930
is to embed yourself.

50
00:03:03.930 --> 00:03:09.460
And to illustrate this, I wanna start
first with the research of Bob Cialdini

51
00:03:09.460 --> 00:03:16.770
on Influence where he unpack the six
principles that make people persuasive.

52
00:03:16.770 --> 00:03:20.360
And one of those,
one of the most important is liking.

53
00:03:20.360 --> 00:03:25.620
And he decomposed that
further to similarity and

54
00:03:25.620 --> 00:03:29.370
ultimately finding that a fundamental
driver of liking is similarity and

55
00:03:29.370 --> 00:03:30.990
then liking drives influence.

56
00:03:30.990 --> 00:03:34.500
The key point is that people
are more readily influenced by

57
00:03:34.500 --> 00:03:36.040
people they're more similar to.

58
00:03:36.040 --> 00:03:39.940
We may like this, we may dislike this, but
this is human nature and it's an important

59
00:03:39.940 --> 00:03:43.560
lever to pull if you're trying to
influence others in organizations.

60
00:03:43.560 --> 00:03:48.730
So, Chaldini suggests find or
create sources of similarity.

61
00:03:48.730 --> 00:03:52.560
And, an important way to go about that is
to embed yourself in organization you're

62
00:03:52.560 --> 00:03:53.680
trying to influence.

63
00:03:53.680 --> 00:03:57.500
You don't want to be seen as other,
someone on the other side of the wall.

64
00:03:57.500 --> 00:04:01.450
You want to be seen as one of
the people you're trying to influence.

65
00:04:01.450 --> 00:04:03.850
Alec Scheiner is the president
of the Cleveland Browns.

66
00:04:03.850 --> 00:04:05.370
Before that,
he was with the Dallas Cowboys.

67
00:04:05.370 --> 00:04:08.570
He's one of the most influential
executives in professional sports,

68
00:04:08.570 --> 00:04:11.010
certainly within
the National Football League.

69
00:04:11.010 --> 00:04:14.950
Long an advocate of analytics,
he has been fighting the battle of

70
00:04:14.950 --> 00:04:18.350
influencing organizations
through analytics for years now.

71
00:04:18.350 --> 00:04:19.550
And this is how he put it.

72
00:04:19.550 --> 00:04:21.180
He said, embed yourself.

73
00:04:21.180 --> 00:04:24.670
He gave the example,
we hired an analytics guy, Ken Kovash.

74
00:04:24.670 --> 00:04:27.420
He's in the audience here,
I'll show you a picture in a second and

75
00:04:27.420 --> 00:04:31.360
I always tease him because he wears
Browns t-shirts everyday to work and

76
00:04:31.360 --> 00:04:33.985
I'm like you didn't do that at
your old job at Mozilla did you?

77
00:04:33.985 --> 00:04:37.550
You just like wearing t-shirts
to work everyday and pullovers?

78
00:04:37.550 --> 00:04:41.060
But there's a point to it, he's dressing
like our coaches and our scouts and

79
00:04:41.060 --> 00:04:42.620
they feel more comfortable with him.

80
00:04:42.620 --> 00:04:46.760
If he came in everyday in a suit and tie
he'd be like a foreigner in their land,

81
00:04:46.760 --> 00:04:48.260
and I'm gonna hit on this again and again.

82
00:04:48.260 --> 00:04:51.120
If people don't trust you then
they're not gonna listen to you.

83
00:04:51.120 --> 00:04:53.900
They might act like their
listening to you, but they're not.

84
00:04:53.900 --> 00:04:57.420
First you have to build their trust,
and one way to do that is really learn

85
00:04:57.420 --> 00:05:00.850
what they do, and to do that you
just have to embed yourself.

86
00:05:00.850 --> 00:05:03.740
Work near them, go out with them,
see what their day to day is,

87
00:05:03.740 --> 00:05:05.450
see what their challenges are.

88
00:05:05.450 --> 00:05:09.090
That's really what we spend most
of our time worrying about.

89
00:05:09.090 --> 00:05:13.590
So later I got a picture of Kovash and
there he is in his Browns sweatshirt.

90
00:05:13.590 --> 00:05:16.660
Sure enough, being like the coaches,
being like the players.

91
00:05:18.680 --> 00:05:22.220
Right after Shiner gave this comment,
I walked, this was at a conference,

92
00:05:22.220 --> 00:05:25.580
I walked out of the conference and I was
walking alongside another analyst for

93
00:05:25.580 --> 00:05:28.860
another team, and I asked him what
he thought about the session.

94
00:05:28.860 --> 00:05:31.010
And he thought the session was okay.

95
00:05:31.010 --> 00:05:34.340
But he called out exactly this comment.

96
00:05:34.340 --> 00:05:38.470
And this analyst told me, lately
when I've been going from the office

97
00:05:38.470 --> 00:05:41.300
to the playing field to watch practice,
I don't change.

98
00:05:41.300 --> 00:05:43.910
If I change I have to go to the locker
room, it takes me ten minutes,

99
00:05:43.910 --> 00:05:45.800
it slows down my day.

100
00:05:45.800 --> 00:05:48.350
But walking out of that meeting he said,
I'm gonna start changing clothes.

101
00:05:48.350 --> 00:05:49.880
I'm gonna start putting on the sweatshirt,

102
00:05:49.880 --> 00:05:52.560
because it's gonna make me
a more influential analyst.

103
00:05:52.560 --> 00:05:54.190
There's some version of this.

104
00:05:54.190 --> 00:05:55.810
We don't all work for football teams.

105
00:05:55.810 --> 00:05:57.360
We don't all put on sweatshirts.

106
00:05:57.360 --> 00:06:00.100
But there's some version of this that will
make you a better analyst if you figure

107
00:06:00.100 --> 00:06:03.440
out ways to embed yourself with
the size of the organization

108
00:06:03.440 --> 00:06:05.210
you're trying to influence.

109
00:06:05.210 --> 00:06:07.330
Finally, share control.

110
00:06:07.330 --> 00:06:09.090
This is a big one and a hard one for

111
00:06:09.090 --> 00:06:12.230
us especially when you know you have the
right answer because of your analytics,

112
00:06:12.230 --> 00:06:16.150
you still somehow have to
find a way to share control.

113
00:06:16.150 --> 00:06:19.850
On some research I've done with Berkley
Depvorced, a PhD student here at Wharton

114
00:06:19.850 --> 00:06:23.270
and Joseph Simmons, a long time friend and
colleague here at Wharton.

115
00:06:23.270 --> 00:06:28.110
We've found this notion of algorithm
aversion, that people are averse to using

116
00:06:28.110 --> 00:06:31.300
algorithms so often from analytics,
that's what we've come up with,

117
00:06:31.300 --> 00:06:36.250
especially when they see the algorithm's
error which inevitably they will.

118
00:06:36.250 --> 00:06:38.820
So we've done a little bit of research
on this to try to figure out how we can

119
00:06:38.820 --> 00:06:39.920
break it down.

120
00:06:39.920 --> 00:06:42.300
And we find that across
a wide range of tasks,

121
00:06:42.300 --> 00:06:46.830
people prefer judgement, human judgement,
to algorithmic judgement.

122
00:06:46.830 --> 00:06:50.700
This is even true when
algorithms are better.

123
00:06:50.700 --> 00:06:53.890
Even when they know they're better,
they prefer human judgement.

124
00:06:53.890 --> 00:06:57.160
And the main reason for this is that
they're more forgiving of error

125
00:06:57.160 --> 00:07:00.120
by humans than by algorithms,
all of this is challenging.

126
00:07:00.120 --> 00:07:03.430
This is a big challenge for those of us
who are trying to do better analytics,

127
00:07:03.430 --> 00:07:06.300
which inevitably leads to
algorithmic judgement.

128
00:07:06.300 --> 00:07:07.100
So what do you do?

129
00:07:07.100 --> 00:07:08.750
This is the last thing we find.

130
00:07:08.750 --> 00:07:12.720
People are more tolerant of algorithmic
judgement when they have some input,

131
00:07:12.720 --> 00:07:14.800
even when that input is minor.

132
00:07:14.800 --> 00:07:17.980
So we ran a study, I'll show you
quick results from our study,

133
00:07:17.980 --> 00:07:21.620
where we asked people you can
either use a model, algorithm

134
00:07:21.620 --> 00:07:25.420
based on some analytics that have been
done, or you can use human judgement.

135
00:07:25.420 --> 00:07:27.870
But we gave them four
different conditions.

136
00:07:27.870 --> 00:07:32.020
The first, they had to choose
between the model unaltered,

137
00:07:32.020 --> 00:07:35.910
the model as is, as provided by
the analyst or human judgement and

138
00:07:35.910 --> 00:07:38.540
we found that about 47%
wanted to use the model.

139
00:07:38.540 --> 00:07:41.430
This was in a predicted task, the details
of which don't matter right now.

140
00:07:42.490 --> 00:07:45.830
The other three conditions,
we allowed them to take the model and

141
00:07:45.830 --> 00:07:51.000
adjust it a little bit and in every
other respect the study was the same.

142
00:07:51.000 --> 00:07:56.100
So in one of those conditions we
allowed them to adjust it by 10%.

143
00:07:56.100 --> 00:07:57.430
And what happened?

144
00:07:57.430 --> 00:07:59.086
The input, the intake of the model,

145
00:07:59.086 --> 00:08:02.412
the uptake of the model, the interest
in the model went up almost 50%.

146
00:08:02.412 --> 00:08:09.930
From 47% it increased 24
percentage points, to 71%.

147
00:08:09.930 --> 00:08:13.700
Interestingly, so big update by
letting them have participation and

148
00:08:13.700 --> 00:08:15.650
by giving up some control.

149
00:08:15.650 --> 00:08:18.110
Interestingly, we looked
at two other conditions.

150
00:08:18.110 --> 00:08:22.640
Reducing the amount of control that
they had what difference would it make?

151
00:08:22.640 --> 00:08:25.520
If we allowed them to just pay
only five percent what happens?

152
00:08:25.520 --> 00:08:27.280
Still 71% uptake.

153
00:08:27.280 --> 00:08:32.190
What if we restrict their input to
just 2% so they can move the model but

154
00:08:32.190 --> 00:08:35.350
just barely,
what does that do to their intake, uptake?

155
00:08:35.350 --> 00:08:36.640
It doesn't change it.

156
00:08:36.640 --> 00:08:39.770
What we find is as long as
we give them some control,

157
00:08:39.770 --> 00:08:42.380
some input into the final decision,

158
00:08:42.380 --> 00:08:46.440
they're much more willing to lean on
the algorithm, to lean on the model.

159
00:08:46.440 --> 00:08:50.180
This is underscoring this idea of
giving up a little big of control.

160
00:08:50.180 --> 00:08:53.100
Now it might make the algorithm
a little bit worse.

161
00:08:53.100 --> 00:08:56.790
But maybe that's a price we're
paying if it gets the interest in

162
00:08:56.790 --> 00:08:57.920
the algorithm higher.

163
00:08:57.920 --> 00:09:00.430
That's definitely what we've
found in our studies so far.

164
00:09:00.430 --> 00:09:03.450
And we're beginning to use this technique
in our work with organizations.

165
00:09:05.520 --> 00:09:07.950
One example: a local
graduate admissions office,

166
00:09:07.950 --> 00:09:10.680
where we blend experts and analytics.

167
00:09:10.680 --> 00:09:11.880
Three stage process.

168
00:09:11.880 --> 00:09:14.950
And the first stage,
experts evaluate each applicant.

169
00:09:14.950 --> 00:09:16.200
So this is selective judgement.

170
00:09:16.200 --> 00:09:19.250
But in the middle stage we
use the decision model.

171
00:09:19.250 --> 00:09:22.510
Algorithms, we use analytics
to crunch those evaluations

172
00:09:22.510 --> 00:09:24.040
to recommend the optimal class.

173
00:09:25.150 --> 00:09:28.760
That might be where we'd stop, but because
of what we've learned on giving up some

174
00:09:28.760 --> 00:09:31.630
control, we knew there needed
to be a third stage and

175
00:09:31.630 --> 00:09:35.970
in that stage the experts get to review
and revise those recommendations.

176
00:09:35.970 --> 00:09:40.910
So the algorithm doesn't get the final
say, the experts get the final say.

177
00:09:40.910 --> 00:09:43.630
And even if they don't change very
many of those recommendations,

178
00:09:43.630 --> 00:09:47.720
the ability to change, the leeway we give
them makes them much more open and much

179
00:09:47.720 --> 00:09:52.100
more interested in the analytics and the
algorithm that comes from the analytics.

180
00:09:52.100 --> 00:09:54.320
So to wrap up.

181
00:09:54.320 --> 00:09:58.230
On the organizational challenge side, the
major theme is don't make it a black box.

182
00:09:58.230 --> 00:10:02.720
No black boxes and in particular
be transparent, embed yourself in

183
00:10:02.720 --> 00:10:07.040
the organizations and as much as it
might hurt you to do so, share control.

184
00:10:07.040 --> 00:10:08.797
You'll be a more effective
analyst if you do.