WEBVTT

1
00:00:04.279 --> 00:00:08.080
So, we've covered the four challenges
that form the heart of this module.

2
00:00:08.080 --> 00:00:11.140
The four challenges of dealing
with talent analytics and

3
00:00:11.140 --> 00:00:14.260
drawing correct inferences from
the data that you're crunching.

4
00:00:14.260 --> 00:00:17.750
We have one special topic, we wanna cover
before drop into the prescriptions.

5
00:00:17.750 --> 00:00:19.470
The special topic is Test and

6
00:00:19.470 --> 00:00:22.670
Algorithms, which are receiving
a great deal of attention lately.

7
00:00:22.670 --> 00:00:23.860
So, for example,

8
00:00:23.860 --> 00:00:28.580
the cover story on Time magazine
this summer was How High Is Your XQ?

9
00:00:29.850 --> 00:00:33.440
And XQ is intended to be your
personality quotient, and

10
00:00:33.440 --> 00:00:38.840
this comes from the rise
in firms promising to help

11
00:00:38.840 --> 00:00:44.160
companies hire more effectively by
giving tests to the potential hires.

12
00:00:44.160 --> 00:00:48.680
So, a real cottage industry has grown up
around this and it's related to big data.

13
00:00:48.680 --> 00:00:53.100
It's related to the increase in
computing power and the quest,

14
00:00:53.100 --> 00:00:55.970
the never-ending quest for
a better way to hire employees.

15
00:00:55.970 --> 00:00:58.220
So, we're going to talk
about this separately.

16
00:00:58.220 --> 00:01:01.320
Matthew's going to talk about this
separately in a hiring module, but

17
00:01:01.320 --> 00:01:02.830
I want to say a quick few words about it,

18
00:01:02.830 --> 00:01:06.260
especially because it's related to
other news that's been covered lately.

19
00:01:06.260 --> 00:01:07.680
So, another front page story,

20
00:01:07.680 --> 00:01:11.490
this time the New York Times, on can
an algorithm hire better than a human?

21
00:01:11.490 --> 00:01:13.809
Again, something that's
arisen in recent years.

22
00:01:15.200 --> 00:01:18.860
Fostering the people on the next
topic we're here talking about, but

23
00:01:18.860 --> 00:01:22.760
a few comments on these very important and
relatively new topics.

24
00:01:22.760 --> 00:01:25.140
The first is, let's understand
some of the pros and cons,

25
00:01:25.140 --> 00:01:28.020
because there are pros undoubtedly,
but there are also cons.

26
00:01:28.020 --> 00:01:32.470
So, clearly you can process more
efficiently through these test and

27
00:01:32.470 --> 00:01:35.330
through these algorithms,
you can process many more candidates.

28
00:01:35.330 --> 00:01:41.550
You can aggregate them much more easily
than doing so manually or intuitively.

29
00:01:41.550 --> 00:01:44.680
So, processing efficiency is a plus,
so is broad search.

30
00:01:44.680 --> 00:01:47.710
Because you've got this efficiency,
you can bring many more people

31
00:01:47.710 --> 00:01:51.030
into the filter, into the funnel
that you're trying to process.

32
00:01:51.030 --> 00:01:52.960
And this can be very helpful.

33
00:01:52.960 --> 00:01:56.440
We, in general, think that people
search too narrowly, they're too

34
00:01:56.440 --> 00:02:00.180
confident in being able to identify,
and so broad search is a good thing.

35
00:02:00.180 --> 00:02:02.680
Finally, done well this is unbiased.

36
00:02:02.680 --> 00:02:06.950
The machines that are programmed don't
have the kinds of biases we worry about.

37
00:02:06.950 --> 00:02:08.465
Don't have the human kinds of stereotypes,

38
00:02:08.465 --> 00:02:11.350
self-fulfilling issues that we talked
about in our previous segment.

39
00:02:12.400 --> 00:02:14.210
Now, that's once their programmed.

40
00:02:14.210 --> 00:02:16.500
The programming itself can be biased or

41
00:02:16.500 --> 00:02:19.400
the historical data they're
based on can be biased.

42
00:02:19.400 --> 00:02:21.200
But the machines themselves were unbiased.

43
00:02:21.200 --> 00:02:23.650
And this can be a real advantage for us.

44
00:02:23.650 --> 00:02:25.220
Downsides though, and this is important.

45
00:02:25.220 --> 00:02:30.160
And this is what gets lost in
these glossy articles, or in so

46
00:02:30.160 --> 00:02:35.460
many sales people pushing for
these new tools is that there's some cons.

47
00:02:35.460 --> 00:02:38.720
One is they're hyper-focused.

48
00:02:38.720 --> 00:02:39.570
These algorithms and

49
00:02:39.570 --> 00:02:43.320
these tests will do exactly what they're
programmed to do and nothing else.

50
00:02:43.320 --> 00:02:47.320
They don't have the sense to balance
it in the way that humans would, so

51
00:02:47.320 --> 00:02:51.670
if you go out, and tell them you want X
they're gonna focus exclusively on X and

52
00:02:51.670 --> 00:02:53.900
if you just forgot to
put Y in the algorithm,

53
00:02:53.900 --> 00:02:57.100
you're not gonna get it, you're not
get any Y, it's gonna get exactly.

54
00:02:57.100 --> 00:02:58.380
And this can be dangerous.

55
00:02:58.380 --> 00:03:00.380
It can be very powerful, but
it can be very dangerous.

56
00:03:00.380 --> 00:03:03.750
It's not that they don't work well enough,
the problem is they work too well.

57
00:03:03.750 --> 00:03:05.770
And it's a very sharp tool for
us to be working with.

58
00:03:07.360 --> 00:03:10.380
Second is most of these tools have
relatively low explanatory power.

59
00:03:10.380 --> 00:03:14.260
Meaning, there might be a little signal,
they might be picking up on something.

60
00:03:14.260 --> 00:03:19.420
But they're not in most cases explaining
a lot of the variance downstream.

61
00:03:19.420 --> 00:03:23.260
They're not helping us really understand
that much of what's going on.

62
00:03:23.260 --> 00:03:26.920
And so, we might draw on them, but you
don't wanna put too much weight on them,

63
00:03:26.920 --> 00:03:29.529
if they're not really explaining
much of the downstream variance.

64
00:03:30.810 --> 00:03:34.350
Some prescriptions that come from
using these because by all means we

65
00:03:34.350 --> 00:03:37.710
need to be developing new ones,
we need to be trying to take advantage of

66
00:03:37.710 --> 00:03:40.940
the ones that are good out there, but
they need to come with some prescriptions.

67
00:03:40.940 --> 00:03:44.610
So, one, do the science,
do the rigorous testing and importantly,

68
00:03:44.610 --> 00:03:48.950
identify what works best in your setting,
very few of these are general,

69
00:03:48.950 --> 00:03:52.530
very few of these are tests or
algorithms that are gonna work everywhere.

70
00:03:52.530 --> 00:03:55.970
Even something as fundamental as GPA,
you can think of it as an algorithm even

71
00:03:55.970 --> 00:04:01.150
though it's been widely available for
a long time, even something like GPA can,

72
00:04:01.150 --> 00:04:03.430
the applicability varies
across organizations.

73
00:04:03.430 --> 00:04:06.680
I was at a conference a few months ago,
where someone from Google stood up and

74
00:04:06.680 --> 00:04:10.330
said, we've crunched the numbers,
and we've established once and for

75
00:04:10.330 --> 00:04:14.140
all that G.P.A. is not a valid predictor
for performance inside our firm.

76
00:04:15.350 --> 00:04:15.990
Interesting, right?

77
00:04:15.990 --> 00:04:17.080
Very interesting.

78
00:04:17.080 --> 00:04:20.580
But, Goldman Sachs stands up and
says, we've crunched the numbers and

79
00:04:20.580 --> 00:04:22.720
we've established definitively that G.P.A.

80
00:04:22.720 --> 00:04:25.870
is a valid predictor for
performance inside our firm.

81
00:04:25.870 --> 00:04:29.560
Same numbers, different environments,
different validity.

82
00:04:29.560 --> 00:04:31.870
You've got to run the numbers
inside your organization and

83
00:04:31.870 --> 00:04:35.300
take with a big grain of salt anything
that somebody tells you about

84
00:04:35.300 --> 00:04:38.280
the generality of a particular task or
a particular algorithm.

85
00:04:39.950 --> 00:04:41.770
Second is provide human oversight.

86
00:04:41.770 --> 00:04:46.230
These are very sharp tools, and
they need to be carefully used.

87
00:04:46.230 --> 00:04:46.820
And sadly,

88
00:04:46.820 --> 00:04:50.390
I speak from experience in that, you could
design a very good algorithm, and then

89
00:04:50.390 --> 00:04:55.520
once you start using it you start sawing
off edges of furniture here and there.

90
00:04:55.520 --> 00:04:57.510
You need human oversight of this.

91
00:04:57.510 --> 00:04:59.990
You need humans to be
the once programming.

92
00:04:59.990 --> 00:05:02.500
You need humans testing these things,

93
00:05:02.500 --> 00:05:05.360
very importantly,
you need humans error checking.

94
00:05:05.360 --> 00:05:09.030
You gotta make sure that the output
on the other end makes sense and

95
00:05:09.030 --> 00:05:11.430
broadly corroborates what you expect.

96
00:05:11.430 --> 00:05:14.915
And until you've got a lot of
experience with a particular algorithm,

97
00:05:14.915 --> 00:05:16.940
you've gotta be careful.

98
00:05:16.940 --> 00:05:18.900
Finally, use multiple tools.

99
00:05:18.900 --> 00:05:20.770
This is one of the best
prescriptions we can give.

100
00:05:20.770 --> 00:05:24.600
It kind of licenses
sampling these new tools,

101
00:05:24.600 --> 00:05:29.050
it licenses using them if used in
conjunction with many other tools.

102
00:05:29.050 --> 00:05:33.300
So, by all means, take advantage of new
technology, bring the new test in, drop

103
00:05:33.300 --> 00:05:37.650
them into the, see what they relate to,
just don't put too much stock in any one

104
00:05:37.650 --> 00:05:41.950
of them, any one test or any one algorithm
until you've really proven it up.

105
00:05:41.950 --> 00:05:45.500
But really, in general, with performance
evaluation and talent evaluation,

106
00:05:45.500 --> 00:05:47.870
we want as many diverse
signals as possible.

107
00:05:47.870 --> 00:05:49.660
So, this is a great new role for us.

108
00:05:49.660 --> 00:05:52.970
It brings in some new signals from some
new places and we want that diversity.

109
00:05:52.970 --> 00:05:55.910
But it should only be a complement to
the other more traditional measures.