WEBVTT

1
00:00:00.570 --> 00:00:04.740
More specifically, there are a variety
of different approaches that people

2
00:00:04.740 --> 00:00:06.970
use to address this causality issue.

3
00:00:06.970 --> 00:00:10.810
Kind of arrayed them here on a chart.

4
00:00:10.810 --> 00:00:14.710
Because there's a real tradeoff here,
I think, between difficulty and

5
00:00:14.710 --> 00:00:16.290
effectiveness.

6
00:00:16.290 --> 00:00:18.680
The things where we really think, yep.

7
00:00:18.680 --> 00:00:22.100
We absolutely are convinced that
this is what's driving performance.

8
00:00:22.100 --> 00:00:23.080
Tend to be quite hard to do.

9
00:00:23.080 --> 00:00:27.380
There are a lot of easier things that give
us more comfort, but can't be definitive.

10
00:00:27.380 --> 00:00:31.770
And so the simplest thing, if we're
using some sort of regression framework,

11
00:00:31.770 --> 00:00:35.070
is this idea of measuring and
controlling the omitted variables.

12
00:00:35.070 --> 00:00:38.370
If we believe that there's
some other factor,

13
00:00:38.370 --> 00:00:43.760
that's driving our predictor,
that's a potential omitted variable.

14
00:00:43.760 --> 00:00:46.720
If we can include that in our
regressions and control for it, or

15
00:00:46.720 --> 00:00:50.800
if we can make sure that people,
the high and the low performers,

16
00:00:50.800 --> 00:00:53.960
have same levels of that omitted variable.

17
00:00:53.960 --> 00:00:56.140
Then we can say,
no that's not what's going on.

18
00:00:56.140 --> 00:00:58.950
And so that's your first strategy.

19
00:00:58.950 --> 00:01:03.230
Kind of a variant of that, is trying
to hold the person constant, and so

20
00:01:03.230 --> 00:01:08.140
sometimes looking at changes in
performance of the same individual before

21
00:01:08.140 --> 00:01:11.240
and after some kind of intervention,
training or

22
00:01:11.240 --> 00:01:16.600
something like that, can be a way to
avoid a lot of these omitted variables.

23
00:01:16.600 --> 00:01:19.300
It's not perfect because as we
saw in the example, of kind of

24
00:01:19.300 --> 00:01:24.280
people improving in training because it's
people are experiencing a dip who go in.

25
00:01:24.280 --> 00:01:27.070
There are also some things,
even with the same person,

26
00:01:27.070 --> 00:01:29.530
but change at the same
time as our intervention.

27
00:01:29.530 --> 00:01:32.640
But this is kind of
the first thing that we do.

28
00:01:32.640 --> 00:01:36.780
The reason why this doesn't always work
is that there are a lot of things that we

29
00:01:36.780 --> 00:01:39.130
can't measure with the precision
that we would like to.

30
00:01:39.130 --> 00:01:42.040
And so
a lot of the early work on this was done

31
00:01:42.040 --> 00:01:46.080
looking at the question of
the value of education, you know?

32
00:01:46.080 --> 00:01:49.200
How much money do we get from
each extra year of education.

33
00:01:49.200 --> 00:01:51.080
And people are always worried about.

34
00:01:51.080 --> 00:01:53.970
Well, is that driven by the effect
of what we're learning, or

35
00:01:53.970 --> 00:01:57.440
is that driven by smarter
people getting more education.

36
00:01:57.440 --> 00:02:00.910
Obviously, as a PhD, I'm deeply
wedded to that second explanation.

37
00:02:00.910 --> 00:02:04.760
The question was can we control for
ability?

38
00:02:04.760 --> 00:02:08.020
Obviously, you can throw in
things like GPA and so on, but

39
00:02:08.020 --> 00:02:13.150
we always know GPA and grades are not
the same thing as being smart.

40
00:02:13.150 --> 00:02:16.290
And so
a big challenge was always how do we

41
00:02:16.290 --> 00:02:19.310
really feel comfortable that
we have measured ability.

42
00:02:19.310 --> 00:02:22.880
Because there's always gonna be a lot of
things that you haven't measured, and

43
00:02:22.880 --> 00:02:24.560
that's gonna compromise this approach.

44
00:02:27.140 --> 00:02:30.730
The second thing that you can
do that's on the easier side is

45
00:02:30.730 --> 00:02:33.960
What's evidence that you can
use to rule out alternatives?

46
00:02:33.960 --> 00:02:37.250
If you think there's another reason why
you might be seeing the same pattern,

47
00:02:37.250 --> 00:02:38.380
what can you do to address this?

48
00:02:38.380 --> 00:02:43.110
So I talked a little earlier about some
work that I did where I was trying to

49
00:02:43.110 --> 00:02:50.040
understand whether promotion or hiring was
more likely to lead to high performance.

50
00:02:50.040 --> 00:02:54.510
One of the challenges with that work is I
was using performance evaluations and so

51
00:02:54.510 --> 00:02:57.950
I find that people who
are promoted perform more highly.

52
00:02:57.950 --> 00:03:01.240
Well, couldn't that just be that
their evaluation's more biased?

53
00:03:01.240 --> 00:03:02.290
The man just know them better,

54
00:03:02.290 --> 00:03:04.730
they like them better they
give them better evaluations.

55
00:03:04.730 --> 00:03:06.150
It's hard to rule that out.

56
00:03:06.150 --> 00:03:07.990
One thing that I could look at,
is at least say.

57
00:03:07.990 --> 00:03:10.980
Well, sometimes these evaluations
are more objective and

58
00:03:10.980 --> 00:03:12.770
sometimes they are more subjective.

59
00:03:12.770 --> 00:03:15.940
So, you're going to be more
objective when you're thinking about

60
00:03:16.980 --> 00:03:18.870
evaluations that are tied to results.

61
00:03:18.870 --> 00:03:20.570
Did they achieve results and

62
00:03:20.570 --> 00:03:22.440
less objective when you're
thinking about competence.

63
00:03:22.440 --> 00:03:25.310
They're going to be more objective
when your looking at a job like sales,

64
00:03:25.310 --> 00:03:28.080
with this hard number
at the end of the year.

65
00:03:28.080 --> 00:03:32.380
Less objective when you're looking
at something like advisory business.

66
00:03:32.380 --> 00:03:36.010
And so what I did was I at least compared
what the effects look like when they're

67
00:03:36.010 --> 00:03:38.150
more objective versus less objective.

68
00:03:38.150 --> 00:03:41.410
The effects were stronger on
measures that were more objective,

69
00:03:41.410 --> 00:03:44.080
which gave me some comfort
that this wasn't a bias story.

70
00:03:44.080 --> 00:03:46.570
So always think about, okay, what other

71
00:03:46.570 --> 00:03:50.260
things do those alternative explanations
suggest and can I find evidence for

72
00:03:50.260 --> 00:03:54.850
them in the data is another way to at
least get some comfort around causality.

73
00:03:56.530 --> 00:04:00.060
Ultimately, to really feel confident here,

74
00:04:00.060 --> 00:04:03.690
what you need is something that
looks more like an experiment.

75
00:04:03.690 --> 00:04:08.210
In an experiment what we do is randomly
assign people to a treatment condition and

76
00:04:08.210 --> 00:04:09.660
then we have controls.

77
00:04:09.660 --> 00:04:12.340
We compare the difference between them.

78
00:04:12.340 --> 00:04:14.130
One way to do this, is look for

79
00:04:14.130 --> 00:04:16.800
places where the experiment has
already been done with yes.

80
00:04:16.800 --> 00:04:19.640
So people describe this
as natural experiments.

81
00:04:19.640 --> 00:04:25.210
Weather conditions under which
randomly assigned to the treatment or

82
00:04:25.210 --> 00:04:28.740
is there an assignment to getting
treatment has nothing to do

83
00:04:28.740 --> 00:04:32.690
with performance, a famous example
of this in a different setting.

84
00:04:32.690 --> 00:04:34.530
Again, this is a question
people are interested in.

85
00:04:34.530 --> 00:04:37.450
How much does education affect earnings?

86
00:04:37.450 --> 00:04:40.460
Well, it turned out,
during the Vietnam War in the U.S.,

87
00:04:40.460 --> 00:04:43.640
there was conscription and
there was a draft, and

88
00:04:43.640 --> 00:04:47.310
how likely you were to be drafted
depended on a lottery number.

89
00:04:47.310 --> 00:04:48.600
That you've got.

90
00:04:48.600 --> 00:04:52.780
One way to get out of military service
was through going to university.

91
00:04:52.780 --> 00:04:56.060
And so
depending on the draft number people got,

92
00:04:56.060 --> 00:04:59.310
they were more versus less likely
to actually go to university.

93
00:04:59.310 --> 00:05:02.700
And so people have just been
randomly assigned a higher versus

94
00:05:02.700 --> 00:05:04.850
lower probability of going to university.

95
00:05:04.850 --> 00:05:07.190
And this was used to try and
estimate, okay,

96
00:05:07.190 --> 00:05:10.750
if they're being randomly assigned this,
then we have more confidence that we can

97
00:05:10.750 --> 00:05:14.640
get a sense of what the effect of
going to university on pay is.

98
00:05:14.640 --> 00:05:18.050
Because we know there is some component
of this that has nothing to do

99
00:05:18.050 --> 00:05:22.000
with our underlying ability,
ability to learn, or anything like that.

100
00:05:22.000 --> 00:05:24.790
And so looking for those kinds of trials,

101
00:05:24.790 --> 00:05:28.530
those natural experiments where we know
something is being randomly assigned,

102
00:05:28.530 --> 00:05:30.840
Is a great way to be more
confident about causality.

103
00:05:32.330 --> 00:05:35.510
The big challenge here, obviously,
is you need to be lucky.

104
00:05:35.510 --> 00:05:37.020
Not everything is randomly assigned.

105
00:05:37.020 --> 00:05:40.000
Chances are your training was
not randomly assigned and

106
00:05:40.000 --> 00:05:43.300
if it isn't,
you cannot use this kind of approach.

107
00:05:43.300 --> 00:05:46.700
In that case,
what you can do is conduct an experiment.

108
00:05:46.700 --> 00:05:51.090
If this is something that matters enough
for you then persuade people that you want

109
00:05:51.090 --> 00:05:54.590
to randomly assign training,
and see what the impact is.

110
00:05:54.590 --> 00:05:57.850
And that way you really can have
a decent control and treatment group.

111
00:05:57.850 --> 00:06:01.570
You can even make sure that those groups
are really balanced in terms of some of

112
00:06:01.570 --> 00:06:05.910
the other characteristics of individuals
that you think might effect the outcome.

113
00:06:05.910 --> 00:06:07.400
This is kind of the gold standards.

114
00:06:07.400 --> 00:06:08.650
When we do medical trials,

115
00:06:08.650 --> 00:06:11.520
we really wanna know the answer,
it's the right thing to do.

116
00:06:11.520 --> 00:06:13.920
Obviously, the challenge here
is it's expensive, right?

117
00:06:13.920 --> 00:06:16.500
You need to persuade people
to let you do the experiment.

118
00:06:16.500 --> 00:06:19.470
It's gonna take you time
to set up the experiment.

119
00:06:19.470 --> 00:06:23.430
It's gonna take time to run in
a way that often archival data,

120
00:06:23.430 --> 00:06:25.580
it's all already there, okay?

121
00:06:25.580 --> 00:06:27.340
And so that's the tradeoff here.

122
00:06:27.340 --> 00:06:30.120
But always something that you
kind of want to think about

123
00:06:30.120 --> 00:06:35.330
as you look at these studies is why am
I seeing the results that I'm seeing?

124
00:06:35.330 --> 00:06:40.030
And if this really matters, what can I do
to be absolutely sure that my predictor

125
00:06:40.030 --> 00:06:45.050
variable is driving this performance
in the way I think it is?

126
00:06:45.050 --> 00:06:47.230
How much am I willing to
invest in finding that out?